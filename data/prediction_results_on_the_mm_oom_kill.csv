commit ID;text;author name;commit date;predicted_decision;predicted_rationale
C_kwDOACN7MtoAKDc5OThkZjBiNjQwN2RhNjVhMGZlODMyNWQ2ZmYyMzljNGUxNGZmN2Q;memory: remove the now superfluous sentinel element from ctl_table array;Joel Granados;2024-03-28;1;0
C_kwDOACN7MtoAKDc5OThkZjBiNjQwN2RhNjVhMGZlODMyNWQ2ZmYyMzljNGUxNGZmN2Q;"This commit comes at the tail end of a greater effort to remove the empty
elements at the end of the ctl_table arrays (sentinels) which will reduce
the overall build time size of the kernel and run time memory bloat by ~64
bytes per sentinel (further information Link ";Joel Granados;2024-03-28;0;1
C_kwDOACN7MtoAKDc5OThkZjBiNjQwN2RhNjVhMGZlODMyNWQ2ZmYyMzljNGUxNGZmN2Q;Remove sentinel from all files under mm/ that register a sysctl table.;Joel Granados;2024-03-28;1;1
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;mm: update mark_victim tracepoints fields;Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"The current implementation of the mark_victim tracepoint provides only the
process ID (pid) of the victim process";Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;" This limitation poses challenges
for userspace tools requiring real-time OOM analysis and intervention";Carlos Galo;2024-02-23;1;1
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"
Although this information is available from the kernel logs, itâ€™s not
the appropriate format to provide OOM notifications";Carlos Galo;2024-02-23;0;1
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;" In Android, BPF
programs are used with the mark_victim trace events to notify userspace of
an OOM kill";Carlos Galo;2024-02-23;0;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;" For consistency, update the trace event to include the same
information about the OOMed victim as the kernel logs";Carlos Galo;2024-02-23;1;1
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"- UID
   In Android each installed application has a unique UID";Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"Including
   the `uid` assists in correlating OOM events with specific apps";Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"- Process Name (comm)
   Enables identification of the affected process";Carlos Galo;2024-02-23;0;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"- OOM Score
  Will allow userspace to get additional insight of the relative kill
  priority of the OOM victim";Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"In Android, the oom_score_adj is used to
  categorize app state (foreground, background, etc.), which aids in
  analyzing user-perceptible impacts of OOM events [1]";Carlos Galo;2024-02-23;1;0
C_kwDOACN7MtoAKDcyYmExNGRlYjQwYTllOTY2OGVjNWU2NmEzNDFlZDY1N2U1MjE1YzI;"- Total VM, RSS Stats, and pgtables
  Amount of memory used by the victim that will, potentially, be freed up
  by killing it.";Carlos Galo;2024-02-23;0;1
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;mm, oom:dump_tasks add rss detailed information printing;Yong Wang;2023-11-23;1;0
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;"When the system is under oom, it prints out the RSS information of each
process";Yong Wang;2023-11-23;0;0
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;" However, we don't know the size of rss_anon, rss_file, and
rss_shmem";Yong Wang;2023-11-23;1;0
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;"To distinguish the memory occupied by anonymous or file mappings
or shmem, could help us identify the root cause of the oom";Yong Wang;2023-11-23;0;1
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;So this patch adds RSS details, which refers to the /proc/<pid>/status[1];Yong Wang;2023-11-23;1;1
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;It can help us know more about process memory usage;Yong Wang;2023-11-23;0;1
C_kwDOACN7MtoAKDI3ODczMTkyYWM1OTM4YmZhOWQyNzM0OGQ3OWI5MzFlNWI0MzhiYTY;Example of oom including the new rss_* fields:;Yong Wang;2023-11-23;0;0
C_kwDOACN7MtoAKDFmNGY3ZjBmODg0NWRiYWM0MDI4OWNjM2Q1MGI4MTMxNGM1YTEyYjg;mm/oom_killer: simplify OOM killer info dump helper;Kairui Song;2023-10-16;1;1
C_kwDOACN7MtoAKDFmNGY3ZjBmODg0NWRiYWM0MDI4OWNjM2Q1MGI4MTMxNGM1YTEyYjg;"There is only one caller wants to dump the kill victim info, so just let
it call the standalone helper, no need to make the generic info dump
helper take an extra argument for that";Kairui Song;2023-10-16;1;1
C_kwDOACN7MtoAKDFmNGY3ZjBmODg0NWRiYWM0MDI4OWNjM2Q1MGI4MTMxNGM1YTEyYjg;Result of bloat-o-meter;Kairui Song;2023-10-16;0;1
C_kwDOACN7MtoAKDFmNGY3ZjBmODg0NWRiYWM0MDI4OWNjM2Q1MGI4MTMxNGM1YTEyYjg;"./scripts/bloat-o-meter ./mm/oom_kill.old.o ./mm/oom_kill.o
add/remove: 0/0 grow/shrink: 1/2 up/down: 131/-142 (-11)
Function                                     old     new   delta
oom_kill_process                             412     543    +131
out_of_memory                               1422    1418      -4
dump_header                                  562     424    -138
Total: Before=21514, After=21503, chg -0.05%";Kairui Song;2023-10-16;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;mm: remove redundant K() macro definition;ZhangPeng;2023-08-04;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;"Patch series ""cleanup with helper macro K()""";ZhangPeng;2023-08-04;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;Use helper macro K() to improve code readability;ZhangPeng;2023-08-04;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;" No functional
modification involved";ZhangPeng;2023-08-04;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU; Remove redundant K() macro definition;ZhangPeng;2023-08-04;1;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;This patch (of 7);ZhangPeng;2023-08-04;0;0
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;"Since commit eb8589b4f8c1 (""mm: move mem_init_print_info() to mm_init.c""),
the K() macro definition has been moved to mm/internal.h";ZhangPeng;2023-08-04;0;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU;" Therefore, the
definitions in mm/memcontrol.c, mm/backing-dev.c and mm/oom_kill.c are
redundant";ZhangPeng;2023-08-04;0;1
C_kwDOACN7MtoAKDYxZjI5NzM4MDExODA2MGE3MDg4OGUwYzFmNWM1MzRiNzRhYjc4ZmU; Drop redundant definitions.;ZhangPeng;2023-08-04;0;1
C_kwDOACN7MtoAKDQ4MjJhY2IxMzY5NjM3OTM4YzEyNTJkNTM0ZDMzNTZjNWUzMTNjZGU;mm, oom: do not check 0 mask in out_of_memory();Haifeng Xu;2023-05-08;1;0
C_kwDOACN7MtoAKDQ4MjJhY2IxMzY5NjM3OTM4YzEyNTJkNTM0ZDMzNTZjNWUzMTNjZGU;"Since commit 60e2793d440a (""mm, oom: do not trigger out_of_memory from the
#PF""), no user sets gfp_mask to 0";Haifeng Xu;2023-05-08;0;0
C_kwDOACN7MtoAKDQ4MjJhY2IxMzY5NjM3OTM4YzEyNTJkNTM0ZDMzNTZjNWUzMTNjZGU;" Remove the 0 mask check and update the
comments.";Haifeng Xu;2023-05-08;1;0
C_kwDOACN7MtoAKDdkNGE4YmUwYzRiMmI3ZmZiMzY3OTI5ZDJiMzUyNjUxZjA4MzgwNmI;mm/mmu_notifier: remove unused mmu_notifier_range_update_to_read_only export;Alistair Popple;2023-01-10;1;1
C_kwDOACN7MtoAKDdkNGE4YmUwYzRiMmI3ZmZiMzY3OTI5ZDJiMzUyNjUxZjA4MzgwNmI;"mmu_notifier_range_update_to_read_only() was originally introduced in
commit c6d23413f81b (""mm/mmu_notifier";Alistair Popple;2023-01-10;0;0
C_kwDOACN7MtoAKDdkNGE4YmUwYzRiMmI3ZmZiMzY3OTI5ZDJiMzUyNjUxZjA4MzgwNmI;"mmu_notifier_range_update_to_read_only() helper"") as an optimisation for
device drivers that know a range has only been mapped read-only";Alistair Popple;2023-01-10;0;1
C_kwDOACN7MtoAKDdkNGE4YmUwYzRiMmI3ZmZiMzY3OTI5ZDJiMzUyNjUxZjA4MzgwNmI;" However
there are no users of this feature so remove it";Alistair Popple;2023-01-10;1;0
C_kwDOACN7MtoAKDdkNGE4YmUwYzRiMmI3ZmZiMzY3OTI5ZDJiMzUyNjUxZjA4MzgwNmI;" As it is the only user
of the struct mmu_notifier_range.vma field remove that also.";Alistair Popple;2023-01-10;1;0
C_kwDOACN7MtoAKDk3NGY0MzY3ZGQzMTVhY2MxNWFkNGE2NDUzZjgzMDRhZWE2MGRmYmQ;mm: reduce noise in show_mem for lowmem allocations;Michal Hocko;2022-08-23;1;1
C_kwDOACN7MtoAKDk3NGY0MzY3ZGQzMTVhY2MxNWFkNGE2NDUzZjgzMDRhZWE2MGRmYmQ;"While discussing early DMA pool pre-allocation failure with Christoph [1]
I have realized that the allocation failure warning is rather noisy for
constrained allocations like GFP_DMA{32}";Michal Hocko;2022-08-23;0;1
C_kwDOACN7MtoAKDk3NGY0MzY3ZGQzMTVhY2MxNWFkNGE2NDUzZjgzMDRhZWE2MGRmYmQ;" Those zones are usually not
populated on all nodes very often as their memory ranges are constrained";Michal Hocko;2022-08-23;0;0
C_kwDOACN7MtoAKDk3NGY0MzY3ZGQzMTVhY2MxNWFkNGE2NDUzZjgzMDRhZWE2MGRmYmQ;"This is an attempt to reduce the ballast that doesn't provide any relevant
information for those allocation failures investigation";Michal Hocko;2022-08-23;1;1
C_kwDOACN7MtoAKDk3NGY0MzY3ZGQzMTVhY2MxNWFkNGE2NDUzZjgzMDRhZWE2MGRmYmQ;" Please note that
I have only compile tested it (in my default config setup) and I am
throwing it mostly to see what people think about it.";Michal Hocko;2022-08-23;1;1
C_kwDOACN7MtoAKGIzNTQxZDkxMmE4NGRjNDBjYWJiNTE2ZjJkZWVhYzlhZTZmYTMwZGE;mm: delete unused MMF_OOM_VICTIM flag;Suren Baghdasaryan;2022-05-31;1;1
C_kwDOACN7MtoAKGIzNTQxZDkxMmE4NGRjNDBjYWJiNTE2ZjJkZWVhYzlhZTZmYTMwZGE;"With the last usage of MMF_OOM_VICTIM in exit_mmap gone, this flag is now
unused and can be removed.";Suren Baghdasaryan;2022-05-31;0;1
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;mm: drop oom code from exit_mmap;Suren Baghdasaryan;2022-05-31;1;0
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;"The primary reason to invoke the oom reaper from the exit_mmap path used
to be a prevention of an excessive oom killing if the oom victim exit
races with the oom reaper (see [1] for more details)";Suren Baghdasaryan;2022-05-31;0;0
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;" The invocation has
moved around since then because of the interaction with the munlock logic
but the underlying reason has remained the same (see [2])";Suren Baghdasaryan;2022-05-31;0;0
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;"Munlock code is no longer a problem since [3] and there shouldn't be any
blocking operation before the memory is unmapped by exit_mmap so the oom
reaper invocation can be dropped";Suren Baghdasaryan;2022-05-31;1;1
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;" The unmapping part can be done with the
non-exclusive mmap_sem and the exclusive one is only required when page
tables are freed";Suren Baghdasaryan;2022-05-31;1;0
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;"Remove the oom_reaper from exit_mmap which will make the code easier to
read";Suren Baghdasaryan;2022-05-31;1;1
C_kwDOACN7MtoAKGJmMzk4MGM4NTIxMmZjNzE1MTJkMjdhNDZmNWFhYjY2ZjQ2Y2EyODQ;" This is really unlikely to make any observable difference although
some microbenchmarks could benefit from one less branch that needs to be
evaluated even though it almost never is true.";Suren Baghdasaryan;2022-05-31;1;1
C_kwDOACN7MtoAKGUxYzJjNzc1ZDQ0OGJlMDUwM2EzYWM5MDY4MWQ4Njk4MDkxOWJhZDA;mm/oom_kill: use vma iterators instead of vma linked list;Liam R. Howlett;2022-09-06;1;0
C_kwDOACN7MtoAKGUxYzJjNzc1ZDQ0OGJlMDUwM2EzYWM5MDY4MWQ4Njk4MDkxOWJhZDA;Use vma iterator in preparation of removing the linked list.;Liam R. Howlett;2022-09-06;1;1
C_kwDOACN7MtoAKGExOWNhZDA2OTE1OTdlYjc5YzEyM2I4YTE5YTlmYWJhNWFiN2Q5MGU;mm/oom_kill.c: fix vm_oom_kill_table[] ifdeffery;Andrew Morton;2022-06-01;1;1
C_kwDOACN7MtoAKGExOWNhZDA2OTE1OTdlYjc5YzEyM2I4YTE5YTlmYWJhNWFiN2Q5MGU;arm allnoconfig;Andrew Morton;2022-06-01;0;1
C_kwDOACN7MtoAKGExOWNhZDA2OTE1OTdlYjc5YzEyM2I4YTE5YTlmYWJhNWFiN2Q5MGU;"mm/oom_kill.c:60:25: warning: 'vm_oom_kill_table' defined but not used [-Wunused-variable]
   60 | static struct ctl_table vm_oom_kill_table[] = {";Andrew Morton;2022-06-01;1;0
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;oom_kill.c: futex: delay the OOM reaper to allow time for proper futex cleanup;Nico Pache;2022-04-21;1;0
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;"The pthread struct is allocated on PRIVATE|ANONYMOUS memory [1] which
can be targeted by the oom reaper";Nico Pache;2022-04-21;1;1
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;" This mapping is used to store the
futex robust list head; the kernel does not keep a copy of the robust
list and instead references a userspace address to maintain the
robustness during a process death";Nico Pache;2022-04-21;1;0
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;"A race can occur between exit_mm and the oom reaper that allows the oom
reaper to free the memory of the futex robust list before the exit path
has handled the futex death";Nico Pache;2022-04-21;0;0
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;"    CPU1                               CPU2
    page_fault
    do_exit ""signal""
    wake_oom_reaper
                                        oom_reaper
                                        oom_reap_task_mm (invalidates mm)
    exit_mm
    exit_mm_release
    futex_exit_release
    futex_cleanup
    exit_robust_list
    get_user (EFAULT- can't access memory)
If the get_user EFAULT's, the kernel will be unable to recover the
waiters on the robust_list, leaving userspace mutexes hung indefinitely";Nico Pache;2022-04-21;0;1
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;"Delay the OOM reaper, allowing more time for the exit path to perform
the futex cleanup";Nico Pache;2022-04-21;0;0
C_kwDOACN7MtoAKGU0YTM4NDAyYzM2ZTQyZGYyOGViMWE1Mzk0YmU4N2U2NTcxZmI0OGE;"Reproducer: 
Based on a patch by Michal Hocko.";Nico Pache;2022-04-21;0;0
C_kwDOACN7MtoAKDQzZmUyMTlhYTU2YTJmZGQ4ZjA2MjNjOTQ3MGEzMmIxNGIwNjE3YTU;mm: move oom_kill sysctls to their own file;sujiaxun;2022-02-18;1;0
C_kwDOACN7MtoAKDQzZmUyMTlhYTU2YTJmZGQ4ZjA2MjNjOTQ3MGEzMmIxNGIwNjE3YTU;"kernel/sysctl.c is a kitchen sink where everyone leaves their dirty
dishes, this makes it very difficult to maintain";sujiaxun;2022-02-18;0;1
C_kwDOACN7MtoAKDQzZmUyMTlhYTU2YTJmZGQ4ZjA2MjNjOTQ3MGEzMmIxNGIwNjE3YTU;"To help with this maintenance let's start by moving sysctls to places
where they actually belong";sujiaxun;2022-02-18;1;1
C_kwDOACN7MtoAKDQzZmUyMTlhYTU2YTJmZGQ4ZjA2MjNjOTQ3MGEzMmIxNGIwNjE3YTU;" The proc sysctl maintainers do not want to
know what sysctl knobs you wish to add for your own piece of code, we just
care about the core logic";sujiaxun;2022-02-18;1;1
C_kwDOACN7MtoAKDQzZmUyMTlhYTU2YTJmZGQ4ZjA2MjNjOTQ3MGEzMmIxNGIwNjE3YTU;So move the oom_kill sysctls to their own file, mm/oom_kill.c;sujiaxun;2022-02-18;1;0
C_kwDOACN7MtoAKGJkOGI3N2Q2NTNlODRjZjEzODdiODA0NmM2MTMxNWFmOGI3NTEzZmI;mm/oom_kill: remove unneeded is_memcg_oom check;Miaohe Lin;2022-03-22;1;1
C_kwDOACN7MtoAKGJkOGI3N2Q2NTNlODRjZjEzODdiODA0NmM2MTMxNWFmOGI3NTEzZmI;oom_cpuset_eligible() is always called when !is_memcg_oom();Miaohe Lin;2022-03-22;0;0
C_kwDOACN7MtoAKGJkOGI3N2Q2NTNlODRjZjEzODdiODA0NmM2MTMxNWFmOGI3NTEzZmI;" Remove this
unnecessary check.";Miaohe Lin;2022-03-22;1;1
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;mm/munlock: delete munlock_vma_pages_all(), allow oomreap;Hugh Dickins;2022-02-15;1;0
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;"munlock_vma_pages_range() will still be required, when munlocking but
not munmapping a set of pages; but when unmapping a pte, the mlock count
will be maintained in much the same way as it will be maintained when
mapping in the pte";Hugh Dickins;2022-02-15;1;0
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;" Which removes the need for munlock_vma_pages_all()
on mlocked vmas when munmapping or exiting: eliminating the catastrophic
contention on i_mmap_rwsem, and the need for page lock on the pages";Hugh Dickins;2022-02-15;1;1
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;"There is still a need to update locked_vm accounting according to the
munmapped vmas when munmapping: do that in detach_vmas_to_be_unmapped()";Hugh Dickins;2022-02-15;1;1
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;exit_mmap() does not need locked_vm updates, so delete unlock_range();Hugh Dickins;2022-02-15;1;1
C_kwDOACN7MtoAKGEyMTNlNWNmNzFjYmNlYTRiMjNjYWVkY2I4ZmU2NjI5YTMzM2IyNzU;"And wasn't I the one who forbade the OOM reaper to attack mlocked vmas,
because of the uncertainty in blocking on all those page locks?
No fear of that now, so permit the OOM reaper on mlocked vmas.";Hugh Dickins;2022-02-15;1;1
C_kwDOACN7MtoAKGY1MzAyNDNhMTcyZDJmZjAzZjg4ZDAwNTZmODM4OTI4ZDY0NDVjNmQ;mm, oom: OOM sysrq should always kill a process;Jann Horn;2022-01-14;1;1
C_kwDOACN7MtoAKGY1MzAyNDNhMTcyZDJmZjAzZjg4ZDAwNTZmODM4OTI4ZDY0NDVjNmQ;"The OOM kill sysrq (alt+sysrq+F) should allow the user to kill the
process with the highest OOM badness with a single execution";Jann Horn;2022-01-14;1;0
C_kwDOACN7MtoAKGY1MzAyNDNhMTcyZDJmZjAzZjg4ZDAwNTZmODM4OTI4ZDY0NDVjNmQ;"However, at the moment, the OOM kill can bail out if an OOM notifier
(e.g";Jann Horn;2022-01-14;0;0
C_kwDOACN7MtoAKGY1MzAyNDNhMTcyZDJmZjAzZjg4ZDAwNTZmODM4OTI4ZDY0NDVjNmQ;" the i915 one) says that it reclaimed a tiny amount of memory from
somewhere";Jann Horn;2022-01-14;1;0
C_kwDOACN7MtoAKGY1MzAyNDNhMTcyZDJmZjAzZjg4ZDAwNTZmODM4OTI4ZDY0NDVjNmQ;" That's probably not what the user wants, so skip the bailout
if the OOM was triggered via sysrq.";Jann Horn;2022-01-14;1;0
C_kwDOACN7MtoAKGJhNTM1YzFjYWYzZWU3OGFhNzcxOWU5ZTRiMDdhMGRjMWQxNTNiOWU;mm/oom_kill: allow process_mrelease to run under mmap_lock protection;Suren Baghdasaryan;2022-01-14;1;0
C_kwDOACN7MtoAKGJhNTM1YzFjYWYzZWU3OGFhNzcxOWU5ZTRiMDdhMGRjMWQxNTNiOWU;"With exit_mmap holding mmap_write_lock during free_pgtables call,
process_mrelease does not need to elevate mm->mm_users in order to
prevent exit_mmap from destrying pagetables while __oom_reap_task_mm is
walking the VMA tree";Suren Baghdasaryan;2022-01-14;0;1
C_kwDOACN7MtoAKGJhNTM1YzFjYWYzZWU3OGFhNzcxOWU5ZTRiMDdhMGRjMWQxNTNiOWU;" The change prevents process_mrelease from calling
the last mmput, which can lead to waiting for IO completion in exit_aio.";Suren Baghdasaryan;2022-01-14;1;1
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;mm/memcg: add oom_group_kill memory event;Dan Schatzberg;2022-01-14;1;0
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;"Our container agent wants to know when a container exits if it was OOM
killed or not to report to the user";Dan Schatzberg;2022-01-14;1;1
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;" We use memory.oom.group = 1 to
ensure that OOM kills within the container's cgroup kill everything";Dan Schatzberg;2022-01-14;0;0
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;Existing memory.events are insufficient for knowing if this triggered;Dan Schatzberg;2022-01-14;0;1
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;"1) Our current approach reads memory.events oom_kill and reports the
   container was killed if the value is non-zero";Dan Schatzberg;2022-01-14;1;0
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;"This is erroneous in
   some cases where containers create their children cgroups with
   memory.oom.group=1 as such OOM kills will get counted against the
   container cgroup's oom_kill counter despite not actually OOM killing
   the entire container";Dan Schatzberg;2022-01-14;1;1
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;"2) Reading memory.events.local will fail to identify OOM kills in leaf
   cgroups (that don't set memory.oom.group) within the container
   cgroup";Dan Schatzberg;2022-01-14;0;1
C_kwDOACN7MtoAKGI2YmY5YWJiMGFhNDRlNTNmZmU5YzFlNmUxZDMyNTY4ZjViMjVlNGE;"This patch adds a new oom_group_kill event when memory.oom.group
triggers to allow userspace to cleanly identify when an entire cgroup is
oom killed.";Dan Schatzberg;2022-01-14;1;1
C_kwDOACN7MtoAKDk4YjI0YjE2YjJhZWJmZmFiZjViODY3MGY0NGYxOTY2NmMxZTAyOWY;signal: Have the oom killer detect coredumps using signal->core_state;Eric W. Biederman;2021-11-19;1;0
C_kwDOACN7MtoAKDk4YjI0YjE2YjJhZWJmZmFiZjViODY3MGY0NGYxOTY2NmMxZTAyOWY;"In preparation for removing the flag SIGNAL_GROUP_COREDUMP, change
__task_will_free_mem to test signal->core_state instead of the flag
SIGNAL_GROUP_COREDUMP";Eric W. Biederman;2021-11-19;1;1
C_kwDOACN7MtoAKDk4YjI0YjE2YjJhZWJmZmFiZjViODY3MGY0NGYxOTY2NmMxZTAyOWY;"Both fields are protected by siglock and both live in signal_struct so
there are no real tradeoffs here, just a change to which field is
being tested.";Eric W. Biederman;2021-11-19;1;0
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;mm: mark the OOM reaper thread as freezable;Sultan Alsawaf;2021-11-05;1;0
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;"The OOM reaper alters user address space which might theoretically alter
the snapshot if reaping is allowed to happen after the freezer quiescent
state";Sultan Alsawaf;2021-11-05;0;0
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;" To this end, the reaper kthread uses wait_event_freezable()
while waiting for any work so that it cannot run while the system
freezes";Sultan Alsawaf;2021-11-05;0;0
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;"However, the current implementation doesn't respect the freezer because
all kernel threads are created with the PF_NOFREEZE flag, so they are
automatically excluded from freezing operations";Sultan Alsawaf;2021-11-05;0;1
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;" This means that the
OOM reaper can race with system snapshotting if it has work to do while
the system is being frozen";Sultan Alsawaf;2021-11-05;0;1
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;"Fix this by adding a set_freezable() call which will clear the
PF_NOFREEZE flag and thus make the OOM reaper visible to the freezer";Sultan Alsawaf;2021-11-05;1;1
C_kwDOACN7MtoAKDM3MjM5MjllYjBmNTBlMjEwMWRlNzM5Y2RiNjY0NThhNGYxZjRiMjc;"Please note that the OOM reaper altering the snapshot this way is mostly
a theoretical concern and has not been observed in practice.";Sultan Alsawaf;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;mm, oom: do not trigger out_of_memory from the #PF;Michal Hocko;2021-11-05;1;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;"Any allocation failure during the #PF path will return with VM_FAULT_OOM
which in turn results in pagefault_out_of_memory";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" This can happen for 2
different reasons";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" a) Memcg is out of memory and we rely on
mem_cgroup_oom_synchronize to perform the memcg OOM handling or b)
normal allocation fails";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;"The latter is quite problematic because allocation paths already trigger
out_of_memory and the page allocator tries really hard to not fail
allocations";Michal Hocko;2021-11-05;0;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" Anyway, if the OOM killer has been already invoked there
is no reason to invoke it again from the #PF path";Michal Hocko;2021-11-05;1;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" Especially when the
OOM condition might be gone by that time and we have no way to find out
other than allocate";Michal Hocko;2021-11-05;0;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;"Moreover if the allocation failed and the OOM killer hasn't been invoked
then we are unlikely to do the right thing from the #PF context because
we have already lost the allocation context and restictions and
therefore might oom kill a task from a different NUMA domain";Michal Hocko;2021-11-05;0;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;"This all suggests that there is no legitimate reason to trigger
out_of_memory from pagefault_out_of_memory so drop it";Michal Hocko;2021-11-05;1;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" Just to be sure
that no #PF path returns with VM_FAULT_OOM without allocation print a
warning that this is happening before we restart the #PF";Michal Hocko;2021-11-05;1;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;[VvS: #PF allocation can hit into limit of cgroup v1 kmem controller;Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;"This is a local problem related to memcg, however, it causes unnecessary
global OOM kills that are repeated over and over again and escalate into a
real disaster";Michal Hocko;2021-11-05;0;1
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" This has been broken since kmem accounting has been
introduced for cgroup v1 (3.8)";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" There was no kmem specific reclaim for
the separate limit so the only way to handle kmem hard limit was to return
with ENOMEM";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" In upstream the problem will be fixed by removing the
outdated kmem limit, however stable and LTS kernels cannot do it and are
still affected";Michal Hocko;2021-11-05;0;0
C_kwDOACN7MtoAKDYwZTI3OTNkNDQwYTNlYzk1YWJiNWQ2ZDRmYzAzNGE0YjQ4MDQ3MmQ;" This patch fixes the problem and should be backported
into stable/LTS.]";Michal Hocko;2021-11-05;1;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;mm, oom: pagefault_out_of_memory: don't force global OOM for dying tasks;Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;"Patch series ""memcg: prohibit unconditional exceeding the limit of dying tasks"", v3";Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;"Memory cgroup charging allows killed or exiting tasks to exceed the hard
limit";Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" It can be misused and allowed to trigger global OOM from inside
a memcg-limited container";Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" On the other hand if memcg fails allocation,
called from inside #PF handler it triggers global OOM from inside
pagefault_out_of_memory()";Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;To prevent these problems this patchset;Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" (a) removes execution of out_of_memory() from
     pagefault_out_of_memory(), becasue nobody can explain why it is
     necessary";Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I; (b) allow memcg to fail allocation of dying/killed tasks;Vasily Averin;2021-11-05;1;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;This patch (of 3);Vasily Averin;2021-11-05;1;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;"Any allocation failure during the #PF path will return with VM_FAULT_OOM
which in turn results in pagefault_out_of_memory which in turn executes
out_out_memory() and can kill a random task";Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;"An allocation might fail when the current task is the oom victim and
there are no memory reserves left";Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" The OOM killer is already handled at
the page allocator level for the global OOM and at the charging level
for the memcg one";Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" Both have much more information about the scope of
allocation/charge request";Vasily Averin;2021-11-05;0;0
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" This means that either the OOM killer has
been invoked properly and didn't lead to the allocation success or it
has been skipped because it couldn't have been invoked";Vasily Averin;2021-11-05;0;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;" In both cases
triggering it from here is pointless and even harmful";Vasily Averin;2021-11-05;1;1
C_kwDOACN7MtoAKDBiMjgxNzlhNjEzOGE1ZWRkOWQ4MmFkMjY4N2MwNWIzNzczYzM4N2I;"It makes much more sense to let the killed task die rather than to wake
up an eternally hungry oom-killer and send him to choose a fatter victim
for breakfast.";Vasily Averin;2021-11-05;1;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;mm/oom_kill.c: prevent a race between process_mrelease and exit_mmap;Suren Baghdasaryan;2021-10-28;1;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;"Race between process_mrelease and exit_mmap, where free_pgtables is
called while __oom_reap_task_mm is in progress, leads to kernel crash
during pte_offset_map_lock call";Suren Baghdasaryan;2021-10-28;0;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;" oom-reaper avoids this race by setting
MMF_OOM_VICTIM flag and causing exit_mmap to take and release
mmap_write_lock, blocking it until oom-reaper releases mmap_read_lock";Suren Baghdasaryan;2021-10-28;0;0
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;"Reusing MMF_OOM_VICTIM for process_mrelease would be the simplest way to
fix this race, however that would be considered a hack";Suren Baghdasaryan;2021-10-28;1;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;" Fix this race
by elevating mm->mm_users and preventing exit_mmap from executing until
process_mrelease is finished";Suren Baghdasaryan;2021-10-28;1;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;" Patch slightly refactors the code to
adapt for a possible mmget_not_zero failure";Suren Baghdasaryan;2021-10-28;1;1
C_kwDOACN7MtoAKDMzNzU0NmU4M2ZjN2U1MDkxN2Y0NDg0NmJlZWU5MzZhYmI5YzlmMWY;"This fix has considerable negative impact on process_mrelease
performance and will likely need later optimization.";Suren Baghdasaryan;2021-10-28;1;1
C_kwDOACN7MtoAKGVlOTk1NWQ2MWEwYTc3MDE1MmY5YzNhZjQ3MGJkMTY4OWYwMzRjNzQ;mm: use pidfd_get_task();Christian Brauner;2021-10-11;1;1
C_kwDOACN7MtoAKGVlOTk1NWQ2MWEwYTc3MDE1MmY5YzNhZjQ3MGJkMTY4OWYwMzRjNzQ;"Instead of duplicating the same code in two places use the newly added
pidfd_get_task() helper";Christian Brauner;2021-10-11;1;1
C_kwDOACN7MtoAKGVlOTk1NWQ2MWEwYTc3MDE1MmY5YzNhZjQ3MGJkMTY4OWYwMzRjNzQ;"This fixes an (unimportant for now) bug where
PIDTYPE_PID is used whereas PIDTYPE_TGID should have been used.";Christian Brauner;2021-10-11;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;coredump:  Don't perform any cleanups before dumping core;Eric W. Biederman;2021-09-01;1;0
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"Rename coredump_exit_mm to coredump_task_exit and call it from do_exit
before PTRACE_EVENT_EXIT, and before any cleanup work for a task
happens";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;" This ensures that an accurate copy of the process can be
captured in the coredump as no cleanup for the process happens before
the coredump completes";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;" This also ensures that PTRACE_EVENT_EXIT
will not be visited by any thread until the coredump is complete";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"Add a new flag PF_POSTCOREDUMP so that tasks that have passed through
coredump_task_exit can be recognized and ignored in zap_process";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"Now that all of the coredumping happens before exit_mm remove code to
test for a coredump in progress from mm_release";Eric W. Biederman;2021-09-01;1;0
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"Replace ""may_ptrace_stop()"" with a simple test of ""current->ptrace""";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"The other tests in may_ptrace_stop all concern avoiding stopping
during a coredump";Eric W. Biederman;2021-09-01;0;0
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;" These tests are no longer necessary as it is now
guaranteed that fatal_signal_pending will be set if the code enters
ptrace_stop during a coredump";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;" The code in ptrace_stop is guaranteed
not to stop if fatal_signal_pending returns true";Eric W. Biederman;2021-09-01;0;0
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;"Until this change ""ptrace_event(PTRACE_EVENT_EXIT)"" could call
ptrace_stop without fatal_signal_pending being true, as signals are
dequeued in get_signal before calling do_exit";Eric W. Biederman;2021-09-01;0;0
C_kwDOACN7MtoAKDkyMzA3MzgzMDgyZGFmZjVkZjg4NGEyNWRmOWUyODNlZmI3ZWYyNjE;" This is no longer
an issue as ""ptrace_event(PTRACE_EVENT_EXIT)"" is no longer reached
until after the coredump completes.";Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKGQ2N2UwM2UzNjE2MTliMjBjNTFhYWVmM2I3ZGQxNDk3NjE3YzM3MWQ;exit: Factor coredump_exit_mm out of exit_mm;Eric W. Biederman;2021-09-01;1;1
C_kwDOACN7MtoAKGQ2N2UwM2UzNjE2MTliMjBjNTFhYWVmM2I3ZGQxNDk3NjE3YzM3MWQ;"Separate the coredump logic from the ordinary exit_mm logic
by moving the coredump logic out of exit_mm into it's own
function coredump_exit_mm.";Eric W. Biederman;2021-09-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;mm: introduce process_mrelease system call;Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"In modern systems it's not unusual to have a system component monitoring
memory conditions of the system and tasked with keeping system memory
pressure under control";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" One way to accomplish that is to kill
non-essential processes to free up memory for more important ones";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"Examples of this are Facebook's OOM killer daemon called oomd and
Android's low memory killer daemon called lmkd";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"For such system component it's important to be able to free memory quickly
and efficiently";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" Unfortunately the time process takes to free up its
memory after receiving a SIGKILL might vary based on the state of the
process (uninterruptible sleep), size and OPP level of the core the
process is running";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" A mechanism to free resources of the target process
in a more predictable way would improve system's ability to control its
memory pressure";Suren Baghdasaryan;2021-09-02;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"Introduce process_mrelease system call that releases memory of a dying
process from the context of the caller";Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" This way the memory is freed in a
more controllable way with CPU affinity and priority of the caller";Suren Baghdasaryan;2021-09-02;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" The
workload of freeing the memory will also be charged to the caller";Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;" The
operation is allowed only on a dying process";Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"After previous discussions [1, 2, 3] the decision was made [4] to
introduce a dedicated system call to cover this use case";Suren Baghdasaryan;2021-09-02;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"The API is as follows,
        DESCRIPTION
          The process_mrelease() system call is used to free the memory of
          an exiting process";Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          The pidfd selects the process referred to by the PID file
          descriptor";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          (See pidfd_open(2) for further information)
          The flags argument is reserved for future use; currently, this
          argument must be specified as 0";Suren Baghdasaryan;2021-09-02;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"        RETURN VALUE
          On success, process_mrelease() returns 0";Suren Baghdasaryan;2021-09-02;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"On error, -1 is
          returned and errno is set to indicate the error";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"        ERRORS
          EBADF  pidfd is not a valid PID file descriptor";Suren Baghdasaryan;2021-09-02;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;          EAGAIN Failed to release part of the address space;Suren Baghdasaryan;2021-09-02;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          EINTR  The call was interrupted by a signal; see signal(7)";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;          EINVAL flags is not 0;Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          EINVAL The memory of the task cannot be released because the
                 process is not exiting, the address space is shared
                 with another live process or there is a core dump in
                 progress";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          ENOSYS This system call is not supported, for example, without
                 MMU support built into Linux";Suren Baghdasaryan;2021-09-02;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ODRhN2U1OTY0ZTA2ZWQ5M2M3NzcxYzBkN2NmMTljMDlhODk0NmYx;"          ESRCH  The target process does not exist (i.e., it has terminated
                 and been waited on).";Suren Baghdasaryan;2021-09-02;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;mm/mempolicy: cleanup nodemask intersection check for oom;Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;"Patch series ""mm/mempolicy: some fix and semantics cleanup"", v4";Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;"Current memory policy code has some confusing and ambiguous part about
MPOL_LOCAL policy, as it is handled as a faked MPOL_PREFERRED one, and
there are many places having to distinguish them";Feng Tang;2021-07-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;" Also the nodemask
intersection check needs cleanup to be more explicit for OOM use, and
handle MPOL_INTERLEAVE correctly";Feng Tang;2021-07-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;" This patchset cleans up these and
unifies the parameter sanity check for mbind() and set_mempolicy()";Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;This patch (of 3);Feng Tang;2021-07-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;"mempolicy_nodemask_intersects seem to be a general purpose mempolicy
function";Feng Tang;2021-07-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;" In fact it is partially tailored for the OOM purpose
instead";Feng Tang;2021-07-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;" The oom proper is the only existing user so rename the
function to make that purpose explicit";Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;"While at it drop the MPOL_INTERLEAVE as those allocations never has a
nodemask defined (see alloc_page_interleave) so this is a dead code and
a confusing one because MPOL_INTERLEAVE is a hint rather than a hard
requirement so it shouldn't be considered during the OOM";Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMjZlNTE3YTA1OGJkNDBjNzkwYTFkOTg2OGM4OTY4NDJmMmU0MTU1;"The final code can be reduced to a check for MPOL_BIND which is the
only memory policy that is a hard requirement and thus relevant to a
constrained OOM logic.";Feng Tang;2021-07-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YzljMzgwOWFlMmVjZmNlY2U5YWNiM2Y1MTQyN2U2MTdkMjFmYWZi;rcu: Fix typo in comment: kthead -> kthread;Rolf Eike Beer;2021-03-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YzljMzgwOWFlMmVjZmNlY2U5YWNiM2Y1MTQyN2U2MTdkMjFmYWZi;;Rolf Eike Beer;2021-03-17;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMDk1M2ExYmJhY2E3MWUxZWJiY2I5ODY0ZWIxYjI3MzE1NjE1N2Vk;mm: fix typos in comments;Ingo Molnar;2021-05-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMDk1M2ExYmJhY2E3MWUxZWJiY2I5ODY0ZWIxYjI3MzE1NjE1N2Vk;"Fix ~94 single-word typos in locking code comments, plus a few
very obvious grammar mistakes.";Ingo Molnar;2021-05-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo2OGQ2OGZmNmViYmY2OWQwMjUxMWRkNDhmMTZiMzc5NTY3MWM5YjBi;mm/mempool: minor coding style tweaks;Zhiyuan Dai;2021-05-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo2OGQ2OGZmNmViYmY2OWQwMjUxMWRkNDhmMTZiMzc5NTY3MWM5YjBi;Various coding style tweaks to various files under mm/;Zhiyuan Dai;2021-05-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;"mm: eliminate ""expecting prototype"" kernel-doc warnings";Randy Dunlap;2021-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;"Fix stray kernel-doc warnings in mm/ due to mis-typed or missing function
names";Randy Dunlap;2021-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;Quietens these kernel-doc warnings;Randy Dunlap;2021-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;  mm/mmu_gather.c:264: warning: expecting prototype for tlb_gather_mmu();Randy Dunlap;2021-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;"Prototype was for __tlb_gather_mmu() instead
  mm/oom_kill.c:180: warning: expecting prototype for Check whether unreclaimable slab amount is greater than()";Randy Dunlap;2021-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;"Prototype was for should_dump_unreclaim_slab() instead
  mm/shuffle.c:155: warning: expecting prototype for shuffle_free_memory()";Randy Dunlap;2021-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDViZTFjZDM0NDY0NjIwODYxYjQ1N2I4MDhlNWZiMjExNWQwNmIw;Prototype was for __shuffle_free_memory() instead;Randy Dunlap;2021-04-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpmODE1OWMxMzkwNWJiYTI2ZjNlMTc4MmE1MjFkYWNmN2E2NmZjMWNl;mm, oom: fix a comment in dump_task();Tang Yizhou;2021-02-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpmODE1OWMxMzkwNWJiYTI2ZjNlMTc4MmE1MjFkYWNmN2E2NmZjMWNl;"If p is a kthread, it will be checked in oom_unkillable_task() so
we can delete the corresponding comment.";Tang Yizhou;2021-02-24;1;1
MDY6Q29tbWl0MjMyNTI5ODphNzJhZmQ4NzMwODljNjk3MDUzZTlkYWE4NWZmMzQzYjMxNDBkMmU3;tlb: mmu_gather: Remove start/end arguments from tlb_gather_mmu();Will Deacon;2021-01-27;1;0
MDY6Q29tbWl0MjMyNTI5ODphNzJhZmQ4NzMwODljNjk3MDUzZTlkYWE4NWZmMzQzYjMxNDBkMmU3;"The 'start' and 'end' arguments to tlb_gather_mmu() are no longer
needed now that there is a separate function for 'fullmm' flushing";Will Deacon;2021-01-27;0;1
MDY6Q29tbWl0MjMyNTI5ODphNzJhZmQ4NzMwODljNjk3MDUzZTlkYWE4NWZmMzQzYjMxNDBkMmU3;Remove the unused arguments and update all callers.;Will Deacon;2021-01-27;1;1
MDY6Q29tbWl0MjMyNTI5ODphZThlYmE4YjVkNzIzYTRjYTU0MzAyNGI2ZTUxZjRkMGY0ZmI2YjZi;tlb: mmu_gather: Remove unused start/end arguments from tlb_finish_mmu();Will Deacon;2021-01-27;1;1
MDY6Q29tbWl0MjMyNTI5ODphZThlYmE4YjVkNzIzYTRjYTU0MzAyNGI2ZTUxZjRkMGY0ZmI2YjZi;"Since commit 7a30df49f63a (""mm: mmu_gather: remove __tlb_reset_range()
are no longer used, since we flush the whole mm in case of a nested
invalidation";Will Deacon;2021-01-27;0;1
MDY6Q29tbWl0MjMyNTI5ODphZThlYmE4YjVkNzIzYTRjYTU0MzAyNGI2ZTUxZjRkMGY0ZmI2YjZi;Remove the unused arguments and update all callers.;Will Deacon;2021-01-27;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNTliMzYzM2U3OGQ2MjczNTNkNDliMWViMjI2ZDcyYjJhYzU4OGRh;mm/oom_kill: change comment and rename is_dump_unreclaim_slabs();Hui Su;2020-12-15;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNTliMzYzM2U3OGQ2MjczNTNkNDliMWViMjI2ZDcyYjJhYzU4OGRh;"Change the comment of is_dump_unreclaim_slabs(), it just check whether
nr_unreclaimable slabs amount is greater than user memory, and explain why
we dump unreclaim slabs";Hui Su;2020-12-15;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNTliMzYzM2U3OGQ2MjczNTNkNDliMWViMjI2ZDcyYjJhYzU4OGRh;Rename it to should_dump_unreclaim_slab() maybe better.;Hui Su;2020-12-15;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;mm, oom_adj: don't loop through tasks in __set_oom_adj when not necessary;Suren Baghdasaryan;2020-10-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"Currently __set_oom_adj loops through all processes in the system to keep
oom_score_adj and oom_score_adj_min in sync between processes sharing
their mm";Suren Baghdasaryan;2020-10-13;0;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" This is done for any task with more that one mm_users, which
includes processes with multiple threads (sharing mm and signals)";Suren Baghdasaryan;2020-10-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"However for such processes the loop is unnecessary because their signal
structure is shared as well";Suren Baghdasaryan;2020-10-13;0;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"Android updates oom_score_adj whenever a tasks changes its role
(background/foreground/...) or binds to/unbinds from a service, making it
more/less important";Suren Baghdasaryan;2020-10-13;0;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4; Such operation can happen frequently;Suren Baghdasaryan;2020-10-13;0;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" We noticed
that updates to oom_score_adj became more expensive and after further
investigation found out that the patch mentioned in ""Fixes"" introduced a
regression";Suren Baghdasaryan;2020-10-13;0;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" Using Pixel 4 with a typical Android workload, write time to
oom_score_adj increased from ~3.57us to ~362us";Suren Baghdasaryan;2020-10-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" Moreover this regression
linearly depends on the number of multi-threaded processes running on the
system";Suren Baghdasaryan;2020-10-13;0;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"Mark the mm with a new MMF_MULTIPROCESS flag bit when task is created with
(CLONE_VM && !CLONE_THREAD && !CLONE_VFORK)";Suren Baghdasaryan;2020-10-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" Change __set_oom_adj to use
MMF_MULTIPROCESS instead of mm_users to decide whether oom_score_adj
update should be synchronized between multiple processes";Suren Baghdasaryan;2020-10-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" To prevent
races between clone() and __set_oom_adj(), when oom_score_adj of the
process being cloned might be modified from userspace, we use
oom_adj_mutex";Suren Baghdasaryan;2020-10-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4; Its scope is changed to global;Suren Baghdasaryan;2020-10-13;0;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"The combination of (CLONE_VM && !CLONE_THREAD) is rarely used except for
the case of vfork()";Suren Baghdasaryan;2020-10-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" To prevent performance regressions of vfork(), we
skip taking oom_adj_mutex and setting MMF_MULTIPROCESS when CLONE_VFORK is
specified";Suren Baghdasaryan;2020-10-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" Clearing the MMF_MULTIPROCESS flag (when the last process
sharing the mm exits) is left out of this patch to keep it simple and
because it is believed that this threading model is rare";Suren Baghdasaryan;2020-10-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;" Should there
ever be a need for optimizing that case as well, it can be done by hooking
into the exit path, likely following the mm_update_next_owner pattern";Suren Baghdasaryan;2020-10-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NzE5N2E0ZjI4ZDI4ZDBiMDczYWIwNDI3YjAzY2IyZWU1MzgyNTc4;"With the combination of (CLONE_VM && !CLONE_THREAD && !CLONE_VFORK) being
quite rare, the regression is gone after the change is applied.";Suren Baghdasaryan;2020-10-13;0;0
MDY6Q29tbWl0MjMyNTI5ODo2MTliNWI0NjliY2FiODRlYTNiZWUxZDhkMDQ0NTFjNzgxZDIzZmVi;mm, oom: show process exiting information in __oom_kill_process();Yafang Shao;2020-08-12;1;0
MDY6Q29tbWl0MjMyNTI5ODo2MTliNWI0NjliY2FiODRlYTNiZWUxZDhkMDQ0NTFjNzgxZDIzZmVi;"When the OOM killer finds a victim and tryies to kill it, if the victim is
already exiting, the task mm will be NULL and no process will be killed";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2MTliNWI0NjliY2FiODRlYTNiZWUxZDhkMDQ0NTFjNzgxZDIzZmVi;"But the dump_header() has been already executed, so it will be strange to
dump so much information without killing a process";Yafang Shao;2020-08-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo2MTliNWI0NjliY2FiODRlYTNiZWUxZDhkMDQ0NTFjNzgxZDIzZmVi;" We'd better show some
helpful information to indicate why this happens.";Yafang Shao;2020-08-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;mm, oom: make the calculation of oom badness more accurate;Yafang Shao;2020-08-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;"Recently we found an issue on our production environment that when memcg
oom is triggered the oom killer doesn't chose the process with largest
resident memory but chose the first scanned process";Yafang Shao;2020-08-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;" Note that all
processes in this memcg have the same oom_score_adj, so the oom killer
should chose the process with largest resident memory";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;Bellow is part of the oom info, which is enough to analyze this issue;Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;"We can find that the first scanned process 5740 (pause) was killed, but
its rss is only one page";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;" That is because, when we calculate the oom
badness in oom_badness(), we always ignore the negtive point and convert
all of these negtive points to 1";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;" Now as oom_score_adj of all the
processes in this targeted memcg have the same value -998, the points of
these processes are all negtive value";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;" As a result, the first scanned
process will be killed";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;"The oom_socre_adj (-998) in this memcg is set by kubelet, because it is a
a Guaranteed pod, which has higher priority to prevent from being killed
by system oom";Yafang Shao;2020-08-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;"To fix this issue, we should make the calculation of oom point more
accurate";Yafang Shao;2020-08-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MDY2ZTVjZmI3M2NkYmNkYmI0OWU4Nzk5OTQ4MmFiNjE1ZTlmYzc2;" We can achieve it by convert the chosen_point from 'unsigned
long' to 'long'.";Yafang Shao;2020-08-12;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;mm: memcg: convert vmstat slab counters to bytes;Roman Gushchin;2020-08-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;"In order to prepare for per-object slab memory accounting, convert
NR_SLAB_RECLAIMABLE and NR_SLAB_UNRECLAIMABLE vmstat items to bytes";Roman Gushchin;2020-08-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;"To make it obvious, rename them to NR_SLAB_RECLAIMABLE_B and
NR_SLAB_UNRECLAIMABLE_B (similar to NR_KERNEL_STACK_KB)";Roman Gushchin;2020-08-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;"Internally global and per-node counters are stored in pages, however memcg
and lruvec counters are stored in bytes";Roman Gushchin;2020-08-07;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;" This scheme may look weird, but
only for now";Roman Gushchin;2020-08-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;" As soon as slab pages will be shared between multiple
cgroups, global and node counters will reflect the total number of slab
pages";Roman Gushchin;2020-08-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;" However memcg and lruvec counters will be used for per-memcg slab
memory tracking, which will take separate kernel objects in the account";Roman Gushchin;2020-08-07;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;"Keeping global and node counters in pages helps to avoid additional
overhead";Roman Gushchin;2020-08-07;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNDJmMzI0NWM3ZTI5OWUwMTcyMTNmYTAyOGMzMTkzMTZiY2RiN2Y0;"The size of slab memory shouldn't exceed 4Gb on 32-bit machines, so it
will fit into atomic_long_t we use for vmstats.";Roman Gushchin;2020-08-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNTY3OGU3ZjJhYzMxYzI3MDMzNGI5MzYzNTJmMGVmMmZlN2RkMmIz;kernel: better document the use_mm/unuse_mm API contract;Christoph Hellwig;2020-06-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNTY3OGU3ZjJhYzMxYzI3MDMzNGI5MzYzNTJmMGVmMmZlN2RkMmIz;"Switch the function documentation to kerneldoc comments, and add
WARN_ON_ONCE asserts that the calling thread is a kernel thread and does
not have ->mm set (or has ->mm set in the case of unuse_mm)";Christoph Hellwig;2020-06-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNTY3OGU3ZjJhYzMxYzI3MDMzNGI5MzYzNTJmMGVmMmZlN2RkMmIz;Also give the functions a kthread_ prefix to better document the use case.;Christoph Hellwig;2020-06-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMWU4ZDdjNmE3YTY4MmUxNDA1ZTNlMjQyZDMyZmMzNzdmZDE5NmZm;mmap locking API: convert mmap_sem comments;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMWU4ZDdjNmE3YTY4MmUxNDA1ZTNlMjQyZDMyZmMzNzdmZDE5NmZm;Convert comments that reference mmap_sem to reference mmap_lock instead.;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODozZTRlMjhjNWE4ZjAxZWU0MTc0ZDYzOWUzNmVkMTU1YWRlNDg5YTZm;mmap locking API: convert mmap_sem API comments;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODozZTRlMjhjNWE4ZjAxZWU0MTc0ZDYzOWUzNmVkMTU1YWRlNDg5YTZm;"Convert comments that reference old mmap_sem APIs to reference
corresponding new mmap locking APIs instead.";Michel Lespinasse;2020-06-09;1;1
MDY6Q29tbWl0MjMyNTI5ODpkOGVkNDVjNWRjZDQ1NWZjNTg0OGQ0N2Y4Njg4M2ExYjg3MmFjMGQw;mmap locking API: use coccinelle to convert mmap_sem rwsem call sites;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODpkOGVkNDVjNWRjZDQ1NWZjNTg0OGQ0N2Y4Njg4M2ExYjg3MmFjMGQw;"This change converts the existing mmap_sem rwsem calls to use the new mmap
locking API instead";Michel Lespinasse;2020-06-09;1;1
MDY6Q29tbWl0MjMyNTI5ODpkOGVkNDVjNWRjZDQ1NWZjNTg0OGQ0N2Y4Njg4M2ExYjg3MmFjMGQw;The change is generated using coccinelle with the following rule;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODpkOGVkNDVjNWRjZDQ1NWZjNTg0OGQ0N2Y4Njg4M2ExYjg3MmFjMGQw;// spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir ;Michel Lespinasse;2020-06-09;1;0
MDY6Q29tbWl0MjMyNTI5ODpkOGVkNDVjNWRjZDQ1NWZjNTg0OGQ0N2Y4Njg4M2ExYjg3MmFjMGQw;"-init_rwsem
+mmap_init_lock
-down_write
+mmap_write_lock
-down_write_killable
+mmap_write_lock_killable
-down_write_trylock
+mmap_write_trylock
-up_write
+mmap_write_unlock
-downgrade_write
+mmap_write_downgrade
-down_read
+mmap_read_lock
-down_read_killable
+mmap_read_lock_killable
-down_read_trylock
+mmap_read_trylock
-up_read
+mmap_read_unlock
-(&mm->mmap_sem)
+(mm)";Michel Lespinasse;2020-06-09;0;1
MDY6Q29tbWl0MjMyNTI5ODo5N2EyMjVlNjlhMWY4ODA4ODZmMzNkMmU2NWE3YWNlMTNmMTUyY2Fh;mm/page_alloc: integrate classzone_idx and high_zoneidx;Joonsoo Kim;2020-06-03;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2EyMjVlNjlhMWY4ODA4ODZmMzNkMmU2NWE3YWNlMTNmMTUyY2Fh;classzone_idx is just different name for high_zoneidx now;Joonsoo Kim;2020-06-03;0;1
MDY6Q29tbWl0MjMyNTI5ODo5N2EyMjVlNjlhMWY4ODA4ODZmMzNkMmU2NWE3YWNlMTNmMTUyY2Fh;" So, integrate
them and add some comment to struct alloc_context in order to reduce
future confusion about the meaning of this variable";Joonsoo Kim;2020-06-03;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2EyMjVlNjlhMWY4ODA4ODZmMzNkMmU2NWE3YWNlMTNmMTUyY2Fh;"The accessor, ac_classzone_idx() is also removed since it isn't needed
after integration";Joonsoo Kim;2020-06-03;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2EyMjVlNjlhMWY4ODA4ODZmMzNkMmU2NWE3YWNlMTNmMTUyY2Fh;"In addition to integration, this patch also renames high_zoneidx to
highest_zoneidx since it represents more precise meaning.";Joonsoo Kim;2020-06-03;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YTdmZjAyYWNhYmJkODc3NjY5ZmVjYjBhMmU3NWQwOTMwYjYyYzg1;mm, oom: dump stack of victim when reaping failed;David Rientjes;2020-01-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YTdmZjAyYWNhYmJkODc3NjY5ZmVjYjBhMmU3NWQwOTMwYjYyYzg1;"When a process cannot be oom reaped, for whatever reason, currently the
list of locks that are held is currently dumped to the kernel log";David Rientjes;2020-01-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YTdmZjAyYWNhYmJkODc3NjY5ZmVjYjBhMmU3NWQwOTMwYjYyYzg1;"Much more interesting is the stack trace of the victim that cannot be
reaped";David Rientjes;2020-01-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YTdmZjAyYWNhYmJkODc3NjY5ZmVjYjBhMmU3NWQwOTMwYjYyYzg1;" If the stack trace is dumped, we have the ability to find
related occurrences in the same kernel code and hopefully solve the
issue that is making it wedged";David Rientjes;2020-01-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YTdmZjAyYWNhYmJkODc3NjY5ZmVjYjBhMmU3NWQwOTMwYjYyYzg1;Dump the stack trace when a process fails to be oom reaped.;David Rientjes;2020-01-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;mm/oom: fix pgtables units mismatch in Killed process message;Ilya Dryomov;2020-01-04;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;pr_err() expects kB, but mm_pgtables_bytes() returns the number of bytes;Ilya Dryomov;2020-01-04;0;1
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;"As everything else is printed in kB, I chose to fix the value rather than
the string";Ilya Dryomov;2020-01-04;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;Before;Ilya Dryomov;2020-01-04;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;"[  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
[   1878]  1000  1878   217253   151144  1269760        0             0 python
Out of memory: Killed process 1878 (python) total-vm:869012kB, anon-rss:604572kB, file-rss:4kB, shmem-rss:0kB, UID:1000 pgtables:1269760kB oom_score_adj:0
After";Ilya Dryomov;2020-01-04;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NDFmNzYyYmNiMjc2MjU5YTc4ZTc5MzE2NzQ2Njg4NzRjY2JkYTU5;"[  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
[   1436]  1000  1436   217253   151890  1294336        0             0 python
Out of memory: Killed process 1436 (python) total-vm:869012kB, anon-rss:607516kB, file-rss:44kB, shmem-rss:0kB, UID:1000 pgtables:1264kB oom_score_adj:0";Ilya Dryomov;2020-01-04;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;mm: introduce MADV_COLD;Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"Patch series ""Introduce MADV_COLD and MADV_PAGEOUT"", v7";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"- Background
The Android terminology used for forking a new process and starting an app
from scratch is a cold start, while resuming an existing app is a hot
start";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" While we continually try to improve the performance of cold
starts, hot starts will always be significantly less power hungry as well
as faster so we are trying to make hot start more likely than cold start";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"To increase hot start, Android userspace manages the order that apps
should be killed in a process called ActivityManagerService";Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"ActivityManagerService tracks every Android app or service that the user
could be interacting with at any time and translates that into a ranked
list for lmkd(low memory killer daemon)";Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" They are likely to be killed by
lmkd if the system has to reclaim memory";Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" In that sense they are similar
to entries in any other cache";Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Those apps are kept alive for
opportunistic performance improvements but those performance improvements
will vary based on the memory requirements of individual workloads";Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"- Problem
Naturally, cached apps were dominant consumers of memory on the system";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"However, they were not significant consumers of swap even though they are
good candidate for swap";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Under investigation, swapping out only begins
once the low zone watermark is hit and kswapd wakes up, but the overall
allocation rate in the system might trip lmkd thresholds and cause a
cached process to be killed(we measured performance swapping out vs";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;zapping the memory by killing a process;Minchan Kim;2019-09-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Unsurprisingly, zapping is 10x
times faster even though we use zram which is much faster than real
storage) so kill from lmkd will often satisfy the high zone watermark,
resulting in very few pages actually being moved to swap";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"- Approach
The approach we chose was to use a new interface to allow userspace to
proactively reclaim entire processes by leveraging platform information";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"This allowed us to bypass the inaccuracy of the kernelâ€™s LRUs for pages
that are known to be cold from userspace and to avoid races with lmkd by
reclaiming apps as soon as they entered the cached state";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Additionally,
it could provide many chances for platform to use much information to
optimize memory efficiency";Minchan Kim;2019-09-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;To achieve the goal, the patchset introduce two new options for madvise;Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"One is MADV_COLD which will deactivate activated pages and the other is
MADV_PAGEOUT which will reclaim private pages instantly";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" These new
options complement MADV_DONTNEED and MADV_FREE by adding non-destructive
ways to gain some free memory space";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" MADV_PAGEOUT is similar to
MADV_DONTNEED in a way that it hints the kernel that memory region is not
currently needed and should be reclaimed immediately; MADV_COLD is similar
to MADV_FREE in a way that it hints the kernel that memory region is not
currently needed and should be reclaimed when memory pressure rises";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;This patch (of 5);Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"When a process expects no accesses to a certain memory range, it could
give a hint to kernel that the pages can be reclaimed when memory pressure
happens but data should be preserved for future use";Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" This could reduce
workingset eviction so it ends up increasing performance";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;This patch introduces the new MADV_COLD hint to madvise(2) syscall;Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"MADV_COLD can be used by a process to mark a memory range as not expected
to be used in the near future";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" The hint can help kernel in deciding which
pages to evict early during memory pressure";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;It works for every LRU pages like MADV_[DONTNEED|FREE];Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"IOW, It moves
	active file page -> inactive file LRU
	active anon page -> inacdtive anon LRU
Unlike MADV_FREE, it doesn't move active anonymous pages to inactive file
LRU's head because MADV_COLD is a little bit different symantic";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"MADV_FREE means it's okay to discard when the memory pressure because the
content of the page is *garbage* so freeing such pages is almost zero
overhead since we don't need to swap out and access afterward causes just
minor fault";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Thus, it would make sense to put those freeable pages in
inactive file LRU to compete other used-once pages";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" It makes sense for
implmentaion point of view, too because it's not swapbacked memory any
longer until it would be re-dirtied";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Even, it could give a bonus to make
them be reclaimed on swapless system";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" However, MADV_COLD doesn't mean
garbage so reclaiming them requires swap-out/in in the end so it's bigger
cost";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Since we have designed VM LRU aging based on cost-model, anonymous
cold pages would be better to position inactive anon's LRU list, not file
LRU";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Furthermore, it would help to avoid unnecessary scanning if system
doesn't have a swap device";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" Let's start simpler way without adding
complexity at this moment";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" However, keep in mind, too that it's a caveat
that workloads with a lot of pages cache are likely to ignore MADV_COLD on
anonymous memory because we rarely age anonymous LRU lists";Minchan Kim;2019-09-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"MADV_COLD (since Linux x.x)
Pages in the specified regions will be treated as less-recently-accessed
compared to pages in the system with similar access frequencies";Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;" In
contrast to MADV_FREE, the contents of the region are preserved regardless
of subsequent writes to pages";Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YzI3NmNjNjVhNThmYWY5OGJlOGU1Njk2Mjc0NWVjOTlhYjg3NjM2;"MADV_COLD cannot be applied to locked pages, Huge TLB pages, or VM_PFNMAP
pages.";Minchan Kim;2019-09-25;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZWI0MWJiMDdlNTY4NjI5ODA1YWNiODQ1NWM0NGI2NzA5ODE5NTUx;mm, oom: consider present pages for the node size;Michal Hocko;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZWI0MWJiMDdlNTY4NjI5ODA1YWNiODQ1NWM0NGI2NzA5ODE5NTUx;"constrained_alloc() calculates the size of the oom domain by using
node_spanned_pages which is incorrect because this is the full range of
the physical memory range that the numa node occupies rather than the
memory that backs that range which is represented by node_present_pages";Michal Hocko;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZWI0MWJiMDdlNTY4NjI5ODA1YWNiODQ1NWM0NGI2NzA5ODE5NTUx;Sparsely populated nodes (e.g;Michal Hocko;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODoxZWI0MWJiMDdlNTY4NjI5ODA1YWNiODQ1NWM0NGI2NzA5ODE5NTUx;" after memory hot remove or simply sparse
due to memory layout) can have really a large difference between the two";Michal Hocko;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZWI0MWJiMDdlNTY4NjI5ODA1YWNiODQ1NWM0NGI2NzA5ODE5NTUx;"This shouldn't really cause any real user observable problems because the
oom calculates a ratio against totalpages and used memory cannot exceed
present pages but it is confusing and wrong from code point of view.";Michal Hocko;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmMzY0ZjA2YjM0YjU1Mjg1ZGY3YjEzMmI0ZTM3NTJkODIwNDEyYWQ0;mm/oom_kill.c: fix oom_cpuset_eligible() comment;Yi Wang;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMzY0ZjA2YjM0YjU1Mjg1ZGY3YjEzMmI0ZTM3NTJkODIwNDEyYWQ0;"Commit ac311a14c682 (""oom: decouple mems_allowed from
oom_unkillable_task"") changed has_intersects_mems_allowed() to
oom_cpuset_eligible(), but didn't change the comment.";Yi Wang;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;mm/oom: add oom_score_adj and pgtables to Killed process message;Edward Chron;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;"For an OOM event: print oom_score_adj value for the OOM Killed process to
document what the oom score adjust value was at the time the process was
OOM Killed";Edward Chron;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;" The adjustment value can be set by user code and it affects
the resulting oom_score so it is used to influence kill process selection";Edward Chron;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;"When eligible tasks are not printed (sysctl oom_dump_tasks = 0) printing
this value is the only documentation of the value for the process being
killed";Edward Chron;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;" Having this value on the Killed process message is useful to
document if a miscconfiguration occurred or to confirm that the
oom_score_adj configuration applies as expected";Edward Chron;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;"An example which illustates both misconfiguration and validation that the
oom_score_adj was applied as expected is";Edward Chron;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;"Aug 14 23:00:02 testserver kernel: Out of memory: Killed process 2692
 (systemd-udevd) total-vm:1056800kB, anon-rss:1052760kB, file-rss:4kB,
 shmem-rss:0kB pgtables:22kB oom_score_adj:1000
The systemd-udevd is a critical system application that should have an
oom_score_adj of -1000";Edward Chron;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;" It was miconfigured to have a adjustment of 1000
making it a highly favored OOM kill target process";Edward Chron;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;" The output documents
both the misconfiguration and the fact that the process was correctly
targeted by OOM due to the miconfiguration";Edward Chron;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;" This can be quite helpful for
triage and problem determination";Edward Chron;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODo3MGNiNmQyNjc3OTA1MTIxYmZjN2ZkZjViYWJmZDg0NDQyMThlZGQ5;"The addition of the pgtables_bytes shows page table usage by the process
and is a useful measure of the memory size of the process.";Edward Chron;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;memcg, oom: don't require __GFP_FS when invoking memcg OOM killer;Tetsuo Handa;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;"Masoud Sharbiani noticed that commit 29ef680ae7c21110 (""memcg, oom: move
out_of_memory back to the charge path"") broke memcg OOM called from
__xfs_filemap_fault() path";Tetsuo Handa;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" It turned out that try_charge() is retrying
cannot invoke the OOM killer due to commit 3da88fb3bacfaa33 (""mm, oom";Tetsuo Handa;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;"move GFP_NOFS check to out_of_memory"")";Tetsuo Handa;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;"Allowing forced charge due to being unable to invoke memcg OOM killer will
lead to global OOM situation";Tetsuo Handa;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" Also, just returning -ENOMEM will be risky
because OOM path is lost and some paths (e.g";Tetsuo Handa;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" get_user_pages()) will leak
-ENOMEM";Tetsuo Handa;2019-09-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" Therefore, invoking memcg OOM killer (despite GFP_NOFS) will be
the only choice we can choose for now";Tetsuo Handa;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;"Until 29ef680ae7c21110, we were able to invoke memcg OOM killer when
GFP_KERNEL reclaim failed [1]";Tetsuo Handa;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" But since 29ef680ae7c21110, we need to
invoke memcg OOM killer when GFP_NOFS reclaim failed [2]";Tetsuo Handa;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODpmOWM2NDU2MjFhMjhlMzc4MTNhMWRlOTZkOWNiZDg5Y2RlOTRhMWU0;" Although in the
past we did invoke memcg OOM killer for GFP_NOFS [3], we might get
pre-mature memcg OOM reports due to this patch.";Tetsuo Handa;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;mm/oom_kill.c: add task UID to info message on an oom kill;Joel Savitz;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;"In the event of an oom kill, useful information about the killed process
is printed to dmesg";Joel Savitz;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;" Users, especially system administrators, will find
it useful to immediately see the UID of the process";Joel Savitz;2019-09-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;"We already print uid when dumping eligible tasks so it is not overly hard
to find that information in the oom report";Joel Savitz;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;" However this information is
unavailable when dumping of eligible tasks is disabled";Joel Savitz;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;"In the following example, abuse_the_ram is the name of a program that
attempts to iteratively allocate all available memory until it is stopped
by force";Joel Savitz;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;Current message;Joel Savitz;2019-09-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;"Out of memory: Killed process 35389 (abuse_the_ram)
total-vm:133718232kB, anon-rss:129624980kB, file-rss:0kB,
shmem-rss:0kB
Patched message";Joel Savitz;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YWMzZjhmZTkxYTIxMTk1MjJhNzNmYmM0MWQzNTQwNTcwNTRlNmVk;"Out of memory: Killed process 2739 (abuse_the_ram),
total-vm:133880028kB, anon-rss:129754836kB, file-rss:0kB,
shmem-rss:0kB, UID:0";Joel Savitz;2019-09-23;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYzIwNzk4NWYzNTRkZmI1NDllNWE1NDMxMDJhM2UwODRlZWE4MWY2;mm/oom_kill.c: remove redundant OOM score normalization in select_bad_process();Tetsuo Handa;2019-07-12;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYzIwNzk4NWYzNTRkZmI1NDllNWE1NDMxMDJhM2UwODRlZWE4MWY2;"Since commit bbbe48029720 (""mm, oom: remove 'prefer children over
parent' heuristic"") removed the
  ""%s: Kill process %d (%s) score %u or sacrifice child\n""
line, oc->chosen_points is no longer used after select_bad_process().";Tetsuo Handa;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;oom: decouple mems_allowed from oom_unkillable_task;Shakeel Butt;2019-07-12;1;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"Commit ef08e3b4981a (""[PATCH] cpusets: confine oom_killer to
mem_exclusive cpuset"") introduces a heuristic where a potential
oom-killer victim is skipped if the intersection of the potential victim
and the current (the process triggered the oom) is empty based on the
reason that killing such victim most probably will not help the current
allocating process";Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"However the commit 7887a3da753e (""[PATCH] oom: cpuset hint"") changed the
heuristic to just decrease the oom_badness scores of such potential
victim based on the reason that the cpuset of such processes might have
changed and previously they may have allocated memory on mems where the
current allocating process can allocate from";Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"Unintentionally 7887a3da753e (""[PATCH] oom: cpuset hint"") introduced a
side effect as the oom_badness is also exposed to the user space through
/proc/[pid]/oom_score, so, readers with different cpusets can read
different oom_score of the same process";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"Later, commit 6cf86ac6f36b (""oom: filter tasks not sharing the same
cpuset"") fixed the side effect introduced by 7887a3da753e by moving the
cpuset intersection back to only oom-killer context and out of
oom_badness";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;" However the combination of ab290adbaf8f (""oom: make
oom_unkillable_task() helper function"") and 26ebc984913b (""oom";Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"/proc/<pid>/oom_score treat kernel thread honestly"") unintentionally
brought back the cpuset intersection check into the oom_badness
calculation function";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"Other than doing cpuset/mempolicy intersection from oom_badness, the memcg
oom context is also doing cpuset/mempolicy intersection which is quite
wrong and is caught by syzcaller with the following report";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODphYzMxMWExNGM2ODJkY2Q4YTEyMGE2MjQ0ZDA1NDJlYzY1NGUzZDkz;"kasan: CONFIG_KASAN_INLINE enabled
kasan: GPF could be caused by NULL-ptr deref or user memory access
general protection fault: 0000 [#1] PREEMPT SMP KASAN
CPU: 0 PID: 28426 Comm: syz-executor.5 Not tainted 5.2.0-rc3-next-20190607
Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
Google 01/01/2011
RIP: 0010:__read_once_size include/linux/compiler.h:194 [inline]
RIP: 0010:has_intersects_mems_allowed mm/oom_kill.c:84 [inline]
RIP: 0010:oom_unkillable_task mm/oom_kill.c:168 [inline]
RIP: 0010:oom_unkillable_task+0x180/0x400 mm/oom_kill.c:155
Code: c1 ea 03 80 3c 02 00 0f 85 80 02 00 00 4c 8b a3 10 07 00 00 48 b8 00
00 00 00 00 fc ff df 4d 8d 74 24 10 4c 89 f2 48 c1 ea 03 <80> 3c 02 00 0f
85 67 02 00 00 49 8b 44 24 10 4c 8d a0 68 fa ff ff
RSP: 0018:ffff888000127490 EFLAGS: 00010a03
RAX: dffffc0000000000 RBX: ffff8880a4cd5438 RCX: ffffffff818dae9c
RDX: 100000000c3cc602 RSI: ffffffff818dac8d RDI: 0000000000000001
RBP: ffff8880001274d0 R08: ffff888000086180 R09: ffffed1015d26be0
R10: ffffed1015d26bdf R11: ffff8880ae935efb R12: 8000000061e63007
R13: 0000000000000000 R14: 8000000061e63017 R15: 1ffff11000024ea6
FS:  00005555561f5940(0000) GS:ffff8880ae800000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 0000000000607304 CR3: 000000009237e000 CR4: 00000000001426f0
DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600
The fix is to decouple the cpuset/mempolicy intersection check from
oom_unkillable_task() and make sure cpuset/mempolicy intersection check is
only done in the global oom context.";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;mm, oom: remove redundant task_in_mem_cgroup() check;Shakeel Butt;2019-07-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;oom_unkillable_task() can be called from three different contexts i.e;Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;global OOM, memcg OOM and oom_score procfs interface;Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;" At the moment
oom_unkillable_task() does a task_in_mem_cgroup() check on the given
process";Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;" Since there is no reason to perform task_in_mem_cgroup()
check for global OOM and oom_score procfs interface, those contexts
provide NULL memcg and skips the task_in_mem_cgroup() check";Shakeel Butt;2019-07-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;" However
for memcg OOM context, the oom_unkillable_task() is always called from
mem_cgroup_scan_tasks() and thus task_in_mem_cgroup() check becomes
redundant and effectively dead code";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YmE3NDllZTc4ZWY0MmZmZGY0Yjk1YzA0MmZjNTc0YTM3ZDIyOWQ5;" So, just remove the
task_in_mem_cgroup() check altogether.";Shakeel Butt;2019-07-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo1ZWVlN2UxY2RiOTcxMjNiYjU1YWMxNGNjZDNhZjhiNmVkYzMxNTM3;mm, oom: refactor dump_tasks for memcg OOMs;Shakeel Butt;2019-07-12;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZWVlN2UxY2RiOTcxMjNiYjU1YWMxNGNjZDNhZjhiNmVkYzMxNTM3;"dump_tasks() traverses all the existing processes even for the memcg OOM
context which is not only unnecessary but also wasteful";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo1ZWVlN2UxY2RiOTcxMjNiYjU1YWMxNGNjZDNhZjhiNmVkYzMxNTM3;" This imposes a
long RCU critical section even from a contained context which can be quite
disruptive";Shakeel Butt;2019-07-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo1ZWVlN2UxY2RiOTcxMjNiYjU1YWMxNGNjZDNhZjhiNmVkYzMxNTM3;"Change dump_tasks() to be aligned with select_bad_process and use
mem_cgroup_scan_tasks to selectively traverse only processes of the target
memcg hierarchy during memcg OOM.";Shakeel Butt;2019-07-12;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMTY4YTlhNTRlYzM5YjNmODMyYzM1MzczMzg5OGI3MTNiNmI1YzFm;mm: memcontrol: use CSS_TASK_ITER_PROCS at mem_cgroup_scan_tasks();Tetsuo Handa;2019-07-12;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMTY4YTlhNTRlYzM5YjNmODMyYzM1MzczMzg5OGI3MTNiNmI1YzFm;"Since commit c03cd7738a83 (""cgroup: Include dying leaders with live
threads in PROCS iterations"") corrected how CSS_TASK_ITER_PROCS works,
mem_cgroup_scan_tasks() can use CSS_TASK_ITER_PROCS in order to check
only one thread from each thread group.";Tetsuo Handa;2019-07-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;mm/oom_kill.c: fix uninitialized oc->constraint;Yafang Shao;2019-06-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;"In dump_oom_summary() oc->constraint is used to show oom_constraint_text,
but it hasn't been set before";Yafang Shao;2019-06-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;" So the value of it is always the default
value 0";Yafang Shao;2019-06-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm; We should inititialize it before;Yafang Shao;2019-06-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;"Bellow is the output when memcg oom occurs,
before this patch";Yafang Shao;2019-06-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;"  oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null), cpuset=/,mems_allowed=0,oom_memcg=/foo,task_memcg=/foo,task=bash,pid=7997,uid=0
after this patch";Yafang Shao;2019-06-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MzJiMWRlMGRlMDJhODNmNjQ2OTVlNjlhMmQ4M2NiZWUxMGMyMzZm;  oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null), cpuset=/,mems_allowed=0,oom_memcg=/foo,task_memcg=/foo,task=bash,pid=13681,uid=0;Yafang Shao;2019-06-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NTdjODk5NjUzOTkxMTVlNWNkOGJmMzhmOWM1OTcyOTM0MDU3MDNk;treewide: Add SPDX license identifier for missed files;Thomas Gleixner;2019-05-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NTdjODk5NjUzOTkxMTVlNWNkOGJmMzhmOWM1OTcyOTM0MDU3MDNk;Add SPDX license identifiers to all files which;Thomas Gleixner;2019-05-19;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NTdjODk5NjUzOTkxMTVlNWNkOGJmMzhmOWM1OTcyOTM0MDU3MDNk;" - Have no license information of any form
 - Have EXPORT_.*_SYMBOL_GPL inside which was used in the
   initial scan/conversion to ignore the file
These files fall under the project license, GPL v2 only";Thomas Gleixner;2019-05-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NTdjODk5NjUzOTkxMTVlNWNkOGJmMzhmOWM1OTcyOTM0MDU3MDNk;"The resulting SPDX
license identifier is";Thomas Gleixner;2019-05-19;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NTdjODk5NjUzOTkxMTVlNWNkOGJmMzhmOWM1OTcyOTM0MDU3MDNk;  GPL-2.0-only;Thomas Gleixner;2019-05-19;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;mm/mmu_notifier: contextual information for event triggering invalidation;JÃ©rÃ´me Glisse;2019-05-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"CPU page table update can happens for many reasons, not only as a result
of a syscall (munmap(), mprotect(), mremap(), madvise(), ...) but also as
a result of kernel activities (memory compression, reclaim, migration,
Users of mmu notifier API track changes to the CPU page table and take
specific action for them";JÃ©rÃ´me Glisse;2019-05-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;" While current API only provide range of virtual
address affected by the change, not why the changes is happening";JÃ©rÃ´me Glisse;2019-05-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"This patchset do the initial mechanical convertion of all the places that
calls mmu_notifier_range_init to also provide the default MMU_NOTIFY_UNMAP
event as well as the vma if it is know (most invalidation happens against
a given vma)";JÃ©rÃ´me Glisse;2019-05-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;" Passing down the vma allows the users of mmu notifier to
inspect the new vma page protection";JÃ©rÃ´me Glisse;2019-05-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"The MMU_NOTIFY_UNMAP is always the safe default as users of mmu notifier
should assume that every for the range is going away when that event
happens";JÃ©rÃ´me Glisse;2019-05-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;" A latter patch do convert mm call path to use a more appropriate
events for each call";JÃ©rÃ´me Glisse;2019-05-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"This is done as 2 patches so that no call site is forgotten especialy
as it uses this following coccinelle patch";JÃ©rÃ´me Glisse;2019-05-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"static inline void mmu_notifier_range_init(struct mmu_notifier_range *I1,
+enum mmu_notifier_event event,
+unsigned flags,
+struct vm_area_struct *vma,
struct mm_struct *I2, unsigned long I3, unsigned long I4) { ..";JÃ©rÃ´me Glisse;2019-05-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjRmMTNlOGQ5ZTI3Y2VmZDJjZDg4ZGQ0ZmQ4MGFhNmQ2OGI5MTMx;"}
mmu_notifier_range_init(E1,
+MMU_NOTIFY_UNMAP, 0, I1,
I1->vm_mm, E3, E4)
mmu_notifier_range_init(E1,
+MMU_NOTIFY_UNMAP, 0, VMA,
E2, E3, E4)
mmu_notifier_range_init(E1,
+MMU_NOTIFY_UNMAP, 0, VMA,
E2, E3, E4)
mmu_notifier_range_init(E1,
+MMU_NOTIFY_UNMAP, 0, NULL,
E2, E3, E4)
Applied with:";JÃ©rÃ´me Glisse;2019-05-14;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMzQyYTBiMzg2NzQ4NjdlYTY3ZmRlNDdiMGUxZTYwZmZlOWYxN2Ey;mm,oom: don't kill global init via memory.oom.group;Tetsuo Handa;2019-03-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMzQyYTBiMzg2NzQ4NjdlYTY3ZmRlNDdiMGUxZTYwZmZlOWYxN2Ey;"Since setting global init process to some memory cgroup is technically
possible, oom_kill_memcg_member() must check it";Tetsuo Handa;2019-03-05;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMzQyYTBiMzg2NzQ4NjdlYTY3ZmRlNDdiMGUxZTYwZmZlOWYxN2Ey;"  Tasks in /test1 are going to be killed due to memory.oom.group set
  Memory cgroup out of memory: Killed process 1 (systemd) total-vm:43400kB, anon-rss:1228kB, file-rss:3992kB, shmem-rss:0kB
  oom_reaper: reaped process 1 (systemd), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
  Kernel panic - not syncing: Attempted to kill init! exitcode=0x0000008b
int main(int argc, char *argv[])
	for (i = 0; i < 10; i++)";Tetsuo Handa;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;mm, oom: remove 'prefer children over parent' heuristic;Shakeel Butt;2019-03-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;"Since the start of the git history of Linux, the kernel after selecting
the worst process to be oom-killed, prefer to kill its child (if the
child does not share mm with the parent)";Shakeel Butt;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" Later it was changed to
prefer to kill a child who is worst";Shakeel Butt;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" If the parent is still the worst
then the parent will be killed";Shakeel Butt;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;"This heuristic assumes that the children did less work than their parent
and by killing one of them, the work lost will be less";Shakeel Butt;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" However this is
very workload dependent";Shakeel Butt;2019-03-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" If there is a workload which can benefit from
this heuristic, can use oom_score_adj to prefer children to be killed
before the parent";Shakeel Butt;2019-03-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;"The select_bad_process() has already selected the worst process in the
system/memcg";Shakeel Butt;2019-03-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" There is no need to recheck the badness of its children
and hoping to find a worse candidate";Shakeel Butt;2019-03-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" That's a lot of unneeded racy
work";Shakeel Butt;2019-03-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" Also the heuristic is dangerous because it make fork bomb like
workloads to recover much later because we constantly pick and kill
processes which are not memory hogs";Shakeel Butt;2019-03-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmJlNDgwMjk3MjBkMmM2YjY3MzNmNzhkMDI1NzFhMjgxNTExYWRi;" So, let's remove this whole
heuristic.";Shakeel Butt;2019-03-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;mm, oom: fix use-after-free in oom_kill_process;Shakeel Butt;2019-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;"Syzbot instance running on upstream kernel found a use-after-free bug in
oom_kill_process";Shakeel Butt;2019-02-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;" On further inspection it seems like the process
selected to be oom-killed has exited even before reaching
read_lock(&tasklist_lock) in oom_kill_process()";Shakeel Butt;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;" More specifically the
tsk->usage is 1 which is due to get_task_struct() in oom_evaluate_task()
and the put_task_struct within for_each_thread() frees the tsk and
for_each_thread() tries to access the tsk";Shakeel Butt;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;" The easiest fix is to do
get/put across the for_each_thread() on the selected task";Shakeel Butt;2019-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;"Now the next question is should we continue with the oom-kill as the
previously selected task has exited? However before adding more
complexity and heuristics, let's answer why we even look at the children
of oom-kill selected task? The select_bad_process() has already selected
the worst process in the system/memcg";Shakeel Butt;2019-02-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;" Due to race, the selected
process might not be the worst at the kill time but does that matter?
The userspace can use the oom_score_adj interface to prefer children to
be killed before the parent";Shakeel Butt;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpjZWZjN2VmM2M4N2QwMmZjOTMwNzgzNTg2OGZmNzIxZWExMmNjNTk3;" I looked at the history but it seems like
this is there before git history.";Shakeel Butt;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;oom, oom_reaper: do not enqueue same task twice;Tetsuo Handa;2019-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"Arkadiusz reported that enabling memcg's group oom killing causes
strange memcg statistics where there is no task in a memcg despite the
number of tasks in that memcg is not 0";Tetsuo Handa;2019-02-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;" It turned out that there is a
bug in wake_oom_reaper() which allows enqueuing same task twice which
makes impossible to decrease the number of tasks in that memcg due to a
refcount leak";Tetsuo Handa;2019-02-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"This bug existed since the OOM reaper became invokable from
task_will_free_mem(current) path in out_of_memory() in Linux 4.7,
  T1@P1     |T2@P1     |T3@P1     |OOM reaper
                                   # Processing an OOM victim in a different memcg domain";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"                        try_charge()
                          mem_cgroup_out_of_memory()
                            mutex_lock(&oom_lock)
             try_charge()
               mem_cgroup_out_of_memory()
                 mutex_lock(&oom_lock)
  try_charge()
    mem_cgroup_out_of_memory()
      mutex_lock(&oom_lock)
                            out_of_memory()
                              oom_kill_process(P1)
                                do_send_sig_info(SIGKILL, @P1)
                                mark_oom_victim(T1@P1)
                                wake_oom_reaper(T1@P1) # T1@P1 is enqueued";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"                            mutex_unlock(&oom_lock)
                 out_of_memory()
                   mark_oom_victim(T2@P1)
                   wake_oom_reaper(T2@P1) # T2@P1 is enqueued";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"                 mutex_unlock(&oom_lock)
      out_of_memory()
        mark_oom_victim(T1@P1)
        wake_oom_reaper(T1@P1) # T1@P1 is enqueued again due to oom_reaper_list == T2@P1 && T1@P1->oom_reaper_list == NULL";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"      mutex_unlock(&oom_lock)
                                   # Completed processing an OOM victim in a different memcg domain";Tetsuo Handa;2019-02-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"                                   spin_lock(&oom_reaper_lock)
                                   # T1P1 is dequeued";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"                                   spin_unlock(&oom_reaper_lock)
but memcg's group oom killing made it easier to trigger this bug by
calling wake_oom_reaper() on the same task from one out_of_memory()
request";Tetsuo Handa;2019-02-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;"Fix this bug using an approach used by commit 855b018325737f76 (""oom,
oom_reaper: disable oom_reaper for oom_kill_allocating_task"")";Tetsuo Handa;2019-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YmNkZWI1MWJkN2QyYWU5ZmU2NWVhNGQ2MDY0M2QyYWVlZjViZmUz;" As a
side effect of this patch, this patch also avoids enqueuing multiple
threads sharing memory via task_will_free_mem(current) path.";Tetsuo Handa;2019-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODphYzQ2ZDRmM2M0MzI0MWZmYTIzZDViZjM2MTUzYTA4MzBjMGUwMmNj;mm/mmu_notifier: use structure for invalidate_range_start/end calls v2;JÃ©rÃ´me Glisse;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODphYzQ2ZDRmM2M0MzI0MWZmYTIzZDViZjM2MTUzYTA4MzBjMGUwMmNj;"To avoid having to change many call sites everytime we want to add a
parameter use a structure to group all parameters for the mmu_notifier
invalidate_range_start/end cakks";JÃ©rÃ´me Glisse;2018-12-28;1;1
MDY6Q29tbWl0MjMyNTI5ODphYzQ2ZDRmM2M0MzI0MWZmYTIzZDViZjM2MTUzYTA4MzBjMGUwMmNj; No functional changes with this patch.;JÃ©rÃ´me Glisse;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;mm, oom: add oom victim's memcg to the oom context information;yuzhoujian;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;"The current oom report doesn't display victim's memcg context during the
global OOM situation";yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;" While this information is not strictly needed, it
can be really helpful for containerized environments to locate which
container has lost a process";yuzhoujian;2018-12-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;" Now that we have a single line for the oom
context, we can trivially add both the oom memcg (this can be either
global_oom or a specific memcg which hits its hard limits) and task_memcg
which is the victim's memcg";yuzhoujian;2018-12-28;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;Below is the single line output in the oom report after this patch;yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;- global oom context information;yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;"oom-kill:constraint=<constraint>,nodemask=<nodemask>,cpuset=<cpuset>,mems_allowed=<mems_allowed>,global_oom,task_memcg=<memcg>,task=<comm>,pid=<pid>,uid=<uid>
- memcg oom context information";yuzhoujian;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMGM4NjdkOTU4OGQ5ZWZjMTBkNmE1NTAwOWM5NTYwMzM2NjczMzY5;oom-kill:constraint=<constraint>,nodemask=<nodemask>,cpuset=<cpuset>,mems_allowed=<mems_allowed>,oom_memcg=<memcg>,task_memcg=<memcg>,task=<comm>,pid=<pid>,uid=<uid>;yuzhoujian;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;mm, oom: reorganize the oom report in dump_header;yuzhoujian;2018-12-28;1;1
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;OOM report contains several sections;yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;" The first one is the allocation
context that has triggered the OOM";yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;" Then we have cpuset context followed
by the stack trace of the OOM path";yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;" The tird one is the OOM memory
information";yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk; Followed by the current memory state of all system tasks;yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;"At last, we will show oom eligible tasks and the information about the
chosen oom victim";yuzhoujian;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;"One thing that makes parsing more awkward than necessary is that we do not
have a single and easily parsable line about the oom context";yuzhoujian;2018-12-28;0;1
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;" This patch
is reorganizing the oom report to
1) who invoked oom and what was the allocation request
2) OOM stack trace
3) OOM memory information
 active_file:4402672 inactive_file:483963 isolated_file:1344
 unevictable:0 dirty:4886753 writeback:0 unstable:0
 slab_reclaimable:148442 slab_unreclaimable:18741
 mapped:1347 shmem:1347 pagetables:58669 bounce:0
 free:88663 free_pcp:0 free_cma:0
4) current memory state of all system tasks
5) oom context (contrains and the chosen victim)";yuzhoujian;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODplZjg0NDRlYTAxZDc0NDI2NTJmOGUxYjhhOGI5NDI3OGNiNTdlYWZk;"oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0-1,task=panic,pid=10737,uid=0
An admin can easily get the full oom context at a single line which
makes parsing much easier.";yuzhoujian;2018-12-28;1;1
MDY6Q29tbWl0MjMyNTI5ODpjYTc5YjBjMjExYWY2M2ZhMzI3NmYwZTNmZDdkZDlhZGEyNDM5ODM5;mm: convert totalram_pages and totalhigh_pages variables to atomic;Arun KS;2018-12-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpjYTc5YjBjMjExYWY2M2ZhMzI3NmYwZTNmZDdkZDlhZGEyNDM5ODM5;totalram_pages and totalhigh_pages are made static inline function;Arun KS;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpjYTc5YjBjMjExYWY2M2ZhMzI3NmYwZTNmZDdkZDlhZGEyNDM5ODM5;"Main motivation was that managed_page_count_lock handling was complicating
things";Arun KS;2018-12-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpjYTc5YjBjMjExYWY2M2ZhMzI3NmYwZTNmZDdkZDlhZGEyNDM5ODM5;" It was discussed in length here,
So it seemes
better to remove the lock and convert variables to atomic, with preventing
poteintial store-to-read tearing as a bonus.";Arun KS;2018-12-28;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzliMjJkYzliZTk4NWM1OTE1ODlmY2I5NDc2OWI4ZTEzNTE4YWEw;signal: Use SEND_SIG_PRIV not SEND_SIG_FORCED with SIGKILL and SIGSTOP;Eric W. Biederman;2018-09-03;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzliMjJkYzliZTk4NWM1OTE1ODlmY2I5NDc2OWI4ZTEzNTE4YWEw;"Now that siginfo is never allocated for SIGKILL and SIGSTOP there is
no difference between SEND_SIG_PRIV and SEND_SIG_FORCED for SIGKILL
and SIGSTOP";Eric W. Biederman;2018-09-03;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzliMjJkYzliZTk4NWM1OTE1ODlmY2I5NDc2OWI4ZTEzNTE4YWEw;" This makes SEND_SIG_FORCED unnecessary and redundant in
the presence of SIGKILL and SIGSTOP";Eric W. Biederman;2018-09-03;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzliMjJkYzliZTk4NWM1OTE1ODlmY2I5NDc2OWI4ZTEzNTE4YWEw;" Therefore change users of
SEND_SIG_FORCED that are sending SIGKILL or SIGSTOP to use
SEND_SIG_PRIV instead";Eric W. Biederman;2018-09-03;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzliMjJkYzliZTk4NWM1OTE1ODlmY2I5NDc2OWI4ZTEzNTE4YWEw;This removes the last users of SEND_SIG_FORCED.;Eric W. Biederman;2018-09-03;1;0
MDY6Q29tbWl0MjMyNTI5ODo3OWNjODEwNTdlZWY3YWQ4NDY1ODg5NzYyOTZhYjBmMjY2YzFhN2E1;mm, oom: fix missing tlb_finish_mmu() in __oom_reap_task_mm().;Tetsuo Handa;2018-09-04;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OWNjODEwNTdlZWY3YWQ4NDY1ODg5NzYyOTZhYjBmMjY2YzFhN2E1;"Commit 93065ac753e4 (""mm, oom: distinguish blockable mode for mmu
notifiers"") has added an ability to skip over vmas with blockable mmu
notifiers";Tetsuo Handa;2018-09-04;0;0
MDY6Q29tbWl0MjMyNTI5ODo3OWNjODEwNTdlZWY3YWQ4NDY1ODg5NzYyOTZhYjBmMjY2YzFhN2E1;This however didn't call tlb_finish_mmu as it should;Tetsuo Handa;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODo3OWNjODEwNTdlZWY3YWQ4NDY1ODg5NzYyOTZhYjBmMjY2YzFhN2E1;"As a result inc_tlb_flush_pending has been called without its pairing
dec_tlb_flush_pending and all callers mm_tlb_flush_pending would flush
even though this is not really needed";Tetsuo Handa;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODo3OWNjODEwNTdlZWY3YWQ4NDY1ODg5NzYyOTZhYjBmMjY2YzFhN2E1;" This alone is not harmful and it
seems there shouldn't be any such callers for oom victims at all but
there is no real reason to skip tlb_finish_mmu on early skip either so
call it.";Tetsuo Handa;2018-09-04;1;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;mm: memcontrol: print proper OOM header when no eligible victim left;Johannes Weiner;2018-09-04;1;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;"When the memcg OOM killer runs out of killable tasks, it currently
prints a WARN with no further OOM context";Johannes Weiner;2018-09-04;0;0
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;" This has caused some user
confusion";Johannes Weiner;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;Warnings indicate a kernel problem;Johannes Weiner;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;" In a reported case, however, the
situation was triggered by a nonsensical memcg configuration (hard limit
set to 0)";Johannes Weiner;2018-09-04;0;0
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;" But without any VM context this wasn't obvious from the
report, and it took some back and forth on the mailing list to identify
what is actually a trivial issue";Johannes Weiner;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;Handle this OOM condition like we handle it in the global OOM killer;Johannes Weiner;2018-09-04;1;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;dump the full OOM context and tell the user we ran out of tasks;Johannes Weiner;2018-09-04;1;0
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;"This way the user can identify misconfigurations easily by themselves
and rectify the problem - without having to go through the hassle of
running into an obscure but unsettling warning, finding the appropriate
kernel mailing list and waiting for a kernel developer to remote-analyze
that the memcg configuration caused this";Johannes Weiner;2018-09-04;0;0
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;"If users cannot make sense of why the OOM killer was triggered or why it
failed, they will still report it to the mailing list, we know that from
experience";Johannes Weiner;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODozMTAwZGFiMmFhMDlkYzZlMDgyOTU2ZTMwNmZjOWY4MWIzY2MwZjdh;" So in case there is an actual kernel bug causing this,
kernel developers will very likely hear about it.";Johannes Weiner;2018-09-04;0;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;mm, oom: introduce memory.oom.group;Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;For some workloads an intervention from the OOM killer can be painful;Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;Killing a random task can bring the workload into an inconsistent state;Roman Gushchin;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"Historically, there are two common solutions for this
problem";Roman Gushchin;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"1) enabling panic_on_oom,
2) using a userspace daemon to monitor OOMs and kill
   all outstanding processes";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"Both approaches have their downsides: rebooting on each OOM is an obvious
waste of capacity, and handling all in userspace is tricky and requires a
userspace agent, which will monitor all cgroups for OOMs";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"In most cases an in-kernel after-OOM cleaning-up mechanism can eliminate
the necessity of enabling panic_on_oom";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;" Also, it can simplify the cgroup
management for userspace applications";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;This commit introduces a new knob for cgroup v2 memory controller;Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;memory.oom.group;Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;" The knob determines whether the cgroup should be
treated as an indivisible workload by the OOM killer";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;" If set, all tasks
belonging to the cgroup or to its descendants (if the memory cgroup is not
a leaf cgroup) are killed together or not at all";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"To determine which cgroup has to be killed, we do traverse the cgroup
hierarchy from the victim task's cgroup up to the OOMing cgroup (or root)
and looking for the highest-level cgroup with memory.oom.group set";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;"Tasks with the OOM protection (oom_score_adj set to -1000) are treated as
an exception and are never killed";Roman Gushchin;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODozZDhiMzhlYjgxY2FjODEzOTVmNmE4MjNmNmJmNDAxYjMyNzI2OGU2;This patch doesn't change the OOM victim selection algorithm.;Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;mm, oom: refactor oom_kill_process();Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"Patch series ""introduce memory.oom.group"", v2";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"This is a tiny implementation of cgroup-aware OOM killer, which adds an
ability to kill a cgroup as a single unit and so guarantee the integrity
of the workload";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"Although it has only a limited functionality in comparison to what now
resides in the mm tree (it doesn't change the victim task selection
algorithm, doesn't look at memory stas on cgroup level, etc), it's also
much simpler and more straightforward";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;" So, hopefully, we can avoid having
long debates here, as we had with the full implementation";Roman Gushchin;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"As it doesn't prevent any futher development, and implements an useful and
complete feature, it looks as a sane way forward";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;This patch (of 2);Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"oom_kill_process() consists of two logical parts: the first one is
responsible for considering task's children as a potential victim and
printing the debug information";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;" The second half is responsible for
sending SIGKILL to all tasks sharing the mm struct with the given victim";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"This commit splits oom_kill_process() with an intention to re-use the the
second half: __oom_kill_process()";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;"The cgroup-aware OOM killer will kill multiple tasks belonging to the
victim cgroup";Roman Gushchin;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OTg5YWQ3YjVlZGUzOGQ2MDVjNTg4OTgxZjYzNGMwODI1MmFiZmMz;" We don't need to print the debug information for the each
task, as well as play with task selection (considering task's children),
so we can't use the existing oom_kill_process().";Roman Gushchin;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;mm/oom_kill.c: clean up oom_reap_task_mm();Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;Andrew has noticed some inconsistencies in oom_reap_task_mm;Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;" Notably
 - Undocumented return value";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;" - comment ""failed to reap part..."" is misleading - sounds like it's
   referring to something which happened in the past, is in fact
   referring to something which might happen in the future";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;" - fails to call trace_finish_task_reaping() in one case
 - code duplication";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;" - Increases mmap_sem hold time a little by moving
   trace_finish_task_reaping() inside the locked region";Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;" So sue me ;)
 - Sharing the finish: path means that the trace event won't
   distinguish between the two sources of finishing";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzFmNDJmZGZkYjM2ZjA2ZjQzYzcxMWZjNTliZTliODE0ZDhmYjIy;"Add a short explanation for the return value and fix the rest by
reorganizing the function a bit to have unified function exit paths.";Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpjM2I3OGIxMWVmYmIyODY1NDMzYWJmOWQyMmMwMDRmZmU0YTczZjVj;mm, oom: describe task memory unit, larger PID pad;Rodrigo Freire;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpjM2I3OGIxMWVmYmIyODY1NDMzYWJmOWQyMmMwMDRmZmU0YTczZjVj;"The default page memory unit of OOM task dump events might not be
intuitive and potentially misleading for the non-initiated when debugging
OOM events: These are pages and not kBs";Rodrigo Freire;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODpjM2I3OGIxMWVmYmIyODY1NDMzYWJmOWQyMmMwMDRmZmU0YTczZjVj;" Add a small printk prior to the
task dump informing that the memory units are actually memory _pages_";Rodrigo Freire;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpjM2I3OGIxMWVmYmIyODY1NDMzYWJmOWQyMmMwMDRmZmU0YTczZjVj;Also extends PID field to align on up to 7 characters;Rodrigo Freire;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpjM2I3OGIxMWVmYmIyODY1NDMzYWJmOWQyMmMwMDRmZmU0YTczZjVj;Reference ;Rodrigo Freire;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;mm, oom: remove oom_lock from oom_reaper;Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;"oom_reaper used to rely on the oom_lock since e2fe14564d33 (""oom_reaper";Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;"close race with exiting task"")";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;" We do not really need the lock anymore
though";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;" 212925802454 (""mm: oom: let oom_reap_task and exit_mmap run
concurrently"") has removed serialization with the exit path based on the
mm reference count and so we do not really rely on the oom_lock anymore";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;"Tetsuo was arguing that at least MMF_OOM_SKIP should be set under the lock
to prevent from races when the page allocator didn't manage to get the
freed (reaped) memory in __alloc_pages_may_oom but it sees the flag later
on and move on to another victim";Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;" Although this is possible in principle
let's wait for it to actually happen in real life before we make the
locking more complex again";Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;"Therefore remove the oom_lock for oom_reaper paths (both exit_mmap and
oom_reap_task_mm)";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;" The reaper serializes with exit_mmap by mmap_sem +
MMF_OOM_SKIP flag";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjU2NzlmYmM2NjlmMzFmN2ViZDBkNDczYmNhNzZjMjRjMDdkZTMw;" There is no synchronization with out_of_memory path
now.";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;mm, oom: distinguish blockable mode for mmu notifiers;Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"There are several blockable mmu notifiers which might sleep in
mmu_notifier_invalidate_range_start and that is a problem for the
oom_reaper because it needs to guarantee a forward progress so it cannot
depend on any sleepable locks";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"Currently we simply back off and mark an oom victim with blockable mmu
notifiers as done after a short sleep";Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" That can result in selecting a new
oom victim prematurely because the previous one still hasn't torn its
memory down yet";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;We can do much better though;Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" Even if mmu notifiers use sleepable locks
there is no reason to automatically assume those locks are held";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" Moreover
majority of notifiers only care about a portion of the address space and
there is absolutely zero reason to fail when we are unmapping an unrelated
range";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" Many notifiers do really block and wait for HW which is harder to
handle and we have to bail out though";Michal Hocko;2018-08-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;This patch handles the low hanging fruit;Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"__mmu_notifier_invalidate_range_start gets a blockable flag and callbacks
are not allowed to sleep if the flag is set to false";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" This is achieved by
using trylock instead of the sleepable lock for most callbacks and
continue as long as we do not block down the call chain";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"I think we can improve that even further because there is a common pattern
to do a range lookup first and then do something about that";Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" The first
part can be done without a sleeping lock in most cases AFAICS";Michal Hocko;2018-08-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"The oom_reaper end then simply retries if there is at least one notifier
which couldn't make any progress in !blockable mode";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" A retry loop is
already implemented to wait for the mmap_sem and this is basically the
same thing";Michal Hocko;2018-08-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;"The simplest way for driver developers to test this code path is to wrap
userspace code which uses these notifiers into a memcg and set the hard
limit to hit the oom";Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5; This can be done e.g;Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5;" after the test faults in all
the mmu notifier managed memory and set the hard limit to something really
small";Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MzA2NWFjNzUzZTQ0NDM4NDBhMDU3YmZlZjRiZTcxZWM3NjZmZGU5; Then we are looking for a proper process tear down.;Michal Hocko;2018-08-22;0;0
MDY6Q29tbWl0MjMyNTI5ODphMTk1ZDNmNWI3NGYzZjQ1YTY3NDJmOTA2M2I1ZTk1YTI1MjJiNDZk;mm/oom_kill.c: document oom_lock;Michal Hocko;2018-08-17;1;1
MDY6Q29tbWl0MjMyNTI5ODphMTk1ZDNmNWI3NGYzZjQ1YTY3NDJmOTA2M2I1ZTk1YTI1MjJiNDZk;Add comments describing oom_lock's scope.;Michal Hocko;2018-08-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;mm, oom: remove sleep from under oom_lock;Michal Hocko;2018-08-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;"Tetsuo has pointed out that since 27ae357fa82b (""mm, oom: fix concurrent
munlock and oom reaper unmap, v3"") we have a strong synchronization
between the oom_killer and victim's exiting because both have to take
the oom_lock";Michal Hocko;2018-08-17;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;" Therefore the original heuristic to sleep for a short
time in out_of_memory doesn't serve the original purpose";Michal Hocko;2018-08-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;"Moreover Tetsuo has noticed that the short sleep can be more harmful
than actually useful";Michal Hocko;2018-08-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;" Hammering the system with many processes can lead
to a starvation when the task holding the oom_lock can block for a long
time (minutes) and block any further progress because the oom_reaper
depends on the oom_lock as well";Michal Hocko;2018-08-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;Drop the short sleep from out_of_memory when we hold the lock;Michal Hocko;2018-08-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;" Keep the
sleep when the trylock fails to throttle the concurrent OOM paths a bit";Michal Hocko;2018-08-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;This should be solved in a more reasonable way (e.g;Michal Hocko;2018-08-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2;" sleep proportional
to the time spent in the active reclaiming etc.) but this is much more
complex thing to achieve";Michal Hocko;2018-08-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YmZlNWRlZDA1NGI4ZTI4YTk0Yzc4NTgwZjIzM2Q2ODc5YTAwMTQ2; This is a quick fixup to remove a stale code.;Michal Hocko;2018-08-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MGIzYjAyNTM1NjIxMDI3ZjU2ZDI0ODEzOWUwZTQ2NzU3M2MzMDk4;signal: Pass pid type into do_send_sig_info;Eric W. Biederman;2018-07-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MGIzYjAyNTM1NjIxMDI3ZjU2ZDI0ODEzOWUwZTQ2NzU3M2MzMDk4;"This passes the information we already have at the call sight into
do_send_sig_info";Eric W. Biederman;2018-07-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MGIzYjAyNTM1NjIxMDI3ZjU2ZDI0ODEzOWUwZTQ2NzU3M2MzMDk4;" Ultimately allowing for better handling of signals
sent to a group of processes during fork.";Eric W. Biederman;2018-07-21;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi;mm: fix oom_kill event handling;Roman Gushchin;2018-06-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi;"Commit e27be240df53 (""mm: memcg: make sure memory.events is uptodate
when waking pollers"") converted most of memcg event counters to
per-memcg atomics, which made them less confusing for a user";Roman Gushchin;2018-06-14;0;0
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi;" The
""oom_kill"" counter remained untouched, so now it behaves differently
than other counters (including ""oom"")";Roman Gushchin;2018-06-14;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi; This adds nothing but confusion;Roman Gushchin;2018-06-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi;"Let's fix this by adding the MEMCG_OOM_KILL event, and follow the
MEMCG_OOM approach";Roman Gushchin;2018-06-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTZiZGZjOGUxZTEzMTcyMGFiYmU3N2EyZWI5OTBjOTRjOTAyNGNi;"This also removes a hack from count_memcg_event_mm(), introduced earlier
specially for the OOM_KILL counter.";Roman Gushchin;2018-06-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYmVjMmUxNTE3MGFhZTNlMDg0ZDdkOWFmYzczMGFlZWJlMDFiNjU0;mm: rename page_counter's count/limit into usage/max;Roman Gushchin;2018-06-08;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYmVjMmUxNTE3MGFhZTNlMDg0ZDdkOWFmYzczMGFlZWJlMDFiNjU0;This patch renames struct page_counter fields;Roman Gushchin;2018-06-08;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYmVjMmUxNTE3MGFhZTNlMDg0ZDdkOWFmYzczMGFlZWJlMDFiNjU0;"  count -> usage
  limit -> max
and the corresponding functions";Roman Gushchin;2018-06-08;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYmVjMmUxNTE3MGFhZTNlMDg0ZDdkOWFmYzczMGFlZWJlMDFiNjU0;"  page_counter_limit() -> page_counter_set_max()
  mem_cgroup_get_limit() -> mem_cgroup_get_max()
  mem_cgroup_resize_limit() -> mem_cgroup_resize_max()
  memcg_update_kmem_limit() -> memcg_update_kmem_max()
  memcg_update_tcp_limit() -> memcg_update_tcp_max()
The idea behind this renaming is to have the direct matching
between memory cgroup knobs (low, high, max) and page_counters API";Roman Gushchin;2018-06-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYmVjMmUxNTE3MGFhZTNlMDg0ZDdkOWFmYzczMGFlZWJlMDFiNjU0;This is pure renaming, this patch doesn't bring any functional change.;Roman Gushchin;2018-06-08;1;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;mm, oom: fix concurrent munlock and oom reaper unmap, v3;David Rientjes;2018-05-11;1;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;"Since exit_mmap() is done without the protection of mm->mmap_sem, it is
possible for the oom reaper to concurrently operate on an mm until
MMF_OOM_SKIP is set";David Rientjes;2018-05-11;0;0
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;"This allows munlock_vma_pages_all() to concurrently run while the oom
reaper is operating on a vma";David Rientjes;2018-05-11;0;0
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;" Since munlock_vma_pages_range() depends
on clearing VM_LOCKED from vm_flags before actually doing the munlock to
determine if any other vmas are locking the same memory, the check for
VM_LOCKED in the oom reaper is racy";David Rientjes;2018-05-11;0;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;"This is especially noticeable on architectures such as powerpc where
clearing a huge pmd requires serialize_against_pte_lookup()";David Rientjes;2018-05-11;0;0
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;" If the pmd
is zapped by the oom reaper during follow_page_mask() after the check
for pmd_none() is bypassed, this ends up deferencing a NULL ptl or a
kernel oops";David Rientjes;2018-05-11;0;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;"Fix this by manually freeing all possible memory from the mm before
doing the munlock and then setting MMF_OOM_SKIP";David Rientjes;2018-05-11;1;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;" The oom reaper can not
run on the mm anymore so the munlock is safe to do in exit_mmap()";David Rientjes;2018-05-11;1;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;" It
also matches the logic that the oom reaper currently uses for
determining when to set MMF_OOM_SKIP itself, so there's no new risk of
excessive oom killing";David Rientjes;2018-05-11;1;1
MDY6Q29tbWl0MjMyNTI5ODoyN2FlMzU3ZmE4MmJlNWFiNzNiMmVmOGQzOWRjYjhjYTI1NjM0ODNh;This issue fixes CVE-2018-1000200.;David Rientjes;2018-05-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo5N2IxMjU1Y2IyN2M1NTFkN2MzYzVjNDk2ZDc4N2RhNDA3NzJkYTk5;mm,oom_reaper: check for MMF_OOM_SKIP before complaining;Tetsuo Handa;2018-04-05;1;0
MDY6Q29tbWl0MjMyNTI5ODo5N2IxMjU1Y2IyN2M1NTFkN2MzYzVjNDk2ZDc4N2RhNDA3NzJkYTk5;"I got ""oom_reaper: unable to reap pid:"" messages when the victim thread
was blocked inside free_pgtables() (which occurred after returning from
unmap_vmas() and setting MMF_OOM_SKIP)";Tetsuo Handa;2018-04-05;0;1
MDY6Q29tbWl0MjMyNTI5ODo5N2IxMjU1Y2IyN2M1NTFkN2MzYzVjNDk2ZDc4N2RhNDA3NzJkYTk5;" We don't need to complain when
exit_mmap() already set MMF_OOM_SKIP";Tetsuo Handa;2018-04-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5N2IxMjU1Y2IyN2M1NTFkN2MzYzVjNDk2ZDc4N2RhNDA3NzJkYTk5;"  Killed process 7558 (a.out) total-vm:4176kB, anon-rss:84kB, file-rss:0kB, shmem-rss:0kB
  oom_reaper: unable to reap pid:7558 (a.out)
  a.out           D13272  7558   6931 0x00100084";Tetsuo Handa;2018-04-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;mm, oom: remove 3% bonus for CAP_SYS_ADMIN processes;David Rientjes;2018-04-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;"Since the 2.6 kernel, the oom killer has slightly biased away from
CAP_SYS_ADMIN processes by discounting some of its memory usage in
comparison to other processes";David Rientjes;2018-04-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;"This has always been implicit and nothing exactly relies on the
behavior";David Rientjes;2018-04-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;"Gaurav notices that __task_cred() can dereference a potentially freed
pointer if the task under consideration is exiting because a reference
to the task_struct is not held";David Rientjes;2018-04-05;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;Remove the CAP_SYS_ADMIN bias so that all processes are treated equally;David Rientjes;2018-04-05;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNDYwNzhiMjg4ODk0N2E4NmI2YmI5OTdjZDU5MjdlNjAyZThmZGM5;"If any CAP_SYS_ADMIN process would like to be biased against, it is
always allowed to adjust /proc/pid/oom_score_adj.";David Rientjes;2018-04-05;1;1
MDY6Q29tbWl0MjMyNTI5ODplOGIwOThmYzU3NDdhN2M4NzFmMTEzYzllYjY1NDUzY2MyZDg2ZTZm;mm: kernel-doc: add missing parameter descriptions;Mike Rapoport;2018-04-05;1;1
MDY6Q29tbWl0MjMyNTI5ODplOGIwOThmYzU3NDdhN2M4NzFmMTEzYzllYjY1NDUzY2MyZDg2ZTZm;;Mike Rapoport;2018-04-05;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMzQwZmY4MjAzNDViMTc5YjY5N2Y2NmVjNjc0M2M3MDQxNmJmOTNm;mm, oom: avoid reaping only for mm's with blockable invalidate callbacks;David Rientjes;2018-02-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMzQwZmY4MjAzNDViMTc5YjY5N2Y2NmVjNjc0M2M3MDQxNmJmOTNm;"This uses the new annotation to determine if an mm has mmu notifiers
with blockable invalidate range callbacks to avoid oom reaping";David Rientjes;2018-02-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMzQwZmY4MjAzNDViMTc5YjY5N2Y2NmVjNjc0M2M3MDQxNmJmOTNm;Otherwise, the callbacks are used around unmap_page_range().;David Rientjes;2018-02-01;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;mm, oom_reaper: fix memory corruption;Michal Hocko;2017-12-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;"David Rientjes has reported the following memory corruption while the
oom reaper tries to unmap the victims address space
  BUG: Bad page map in process oom_reaper  pte:6353826300000000 pmd:00000000
  addr:00007f50cab1d000 vm_flags:08100073 anon_vma:ffff9eea335603f0 mapping:          (null) index:7f50cab1d
  file:          (null) fault:          (null) mmap:          (null) readpage:          (null)
  CPU: 2 PID: 1001 Comm: oom_reaper
  Tetsuo Handa has noticed that the synchronization inside exit_mmap is
insufficient";Michal Hocko;2017-12-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;" We only synchronize with the oom reaper if
tsk_is_oom_victim which is not true if the final __mmput is called from
a different context than the oom victim exit path";Michal Hocko;2017-12-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;" This can trivially
happen from context of any task which has grabbed mm reference (e.g";Michal Hocko;2017-12-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;" to
read /proc/<pid>/ file which requires mm etc.)";Michal Hocko;2017-12-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;"The race would look like this
  oom_reaper		oom_victim		task
						mmget_not_zero
			do_exit
			  mmput
  __oom_reap_task_mm				mmput
  						  __mmput
						    exit_mmap
						      remove_vma
    unmap_page_range
Fix this issue by providing a new mm_is_oom_victim() helper which
operates on the mm struct rather than a task";Michal Hocko;2017-12-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;" Any context which
operates on a remote mm struct should use this helper in place of
tsk_is_oom_victim";Michal Hocko;2017-12-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;" The flag is set in mark_oom_victim and never cleared
so it is stable in the exit_mmap path";Michal Hocko;2017-12-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ODM3ZmUzN2FkZmYxZDE1OTkwNGYwYzAxMzQ3MWIxZWNiY2I0NTVl;Debugged by Tetsuo Handa.;Michal Hocko;2017-12-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;mm, oom_reaper: gather each vma to prevent leaking TLB entry;Wang Nan;2017-11-30;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;"tlb_gather_mmu(&tlb, mm, 0, -1) means gathering the whole virtual memory
space";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2; In this case, tlb->fullmm is true;Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" Some archs like arm64
doesn't flush TLB when tlb->fullmm is true";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;"  commit 5a7862e83000 (""arm64: tlbflush: avoid flushing when fullmm == 1"")";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;Which causes leaking of tlb entries;Wang Nan;2017-11-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;Will clarifies his patch;Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" ""Basically, we tag each address space with an ASID (PCID on x86) which
  is resident in the TLB";Wang Nan;2017-11-30;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;"This means we can elide TLB invalidation when
  pulling down a full mm because we won't ever assign that ASID to
  another mm without doing TLB invalidation elsewhere (which actually
  just nukes the whole TLB)";Wang Nan;2017-11-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;"  I think that means that we could potentially not fault on a kernel
  uaccess, because we could hit in the TLB""
There could be a window between complete_signal() sending IPI to other
cores and all threads sharing this mm are really kicked off from cores";Wang Nan;2017-11-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;"In this window, the oom reaper may calls tlb_flush_mmu_tlbonly() to
flush TLB then frees pages";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" However, due to the above problem, the TLB
entries are not really flushed on arm64";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" Other threads are possible to
access these pages through TLB entries";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" Moreover, a copy_to_user() can
also write to these pages without generating page fault, causes
use-after-free bugs";Wang Nan;2017-11-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;This patch gathers each vma instead of gathering full vm space;Wang Nan;2017-11-30;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" In this
case tlb->fullmm is not true";Wang Nan;2017-11-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ODdjYjA4ODRhNzE0ZmY0ODRkMDM4ZTkxOTBlZGM4NzRlZGNmMTQ2;" The behavior of oom reaper become similar
to munmapping before do_exit, which should be safe for all archs.";Wang Nan;2017-11-30;1;1
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi;mm: simplify nodemask printing;Michal Hocko;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi;"alloc_warn() and dump_header() have to explicitly handle NULL nodemask
which forces both paths to use pr_cont";Michal Hocko;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi; We can do better;Michal Hocko;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi;" printk
already handles NULL pointers properly so all we need is to teach
nodemask_pr_args to handle NULL nodemask carefully";Michal Hocko;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi;" This allows
simplification of both alloc_warn() and dump_header() and gets rid of
pr_cont altogether";Michal Hocko;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODowMjA1Zjc1NTcxZTNhNzBjMzVmMGRkNWU2MDg3NzNjY2U5N2Q5ZGJi;This patch has been motivated by patch from Joe Perches;Michal Hocko;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpjNTA4NDJjOGUxY2RkY2RiNjlkM2VjZTRmNGRmMDA1YTBlNmM1Y2Vi;mm,oom_reaper: remove pointless kthread_run() error check;Tetsuo Handa;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNTA4NDJjOGUxY2RkY2RiNjlkM2VjZTRmNGRmMDA1YTBlNmM1Y2Vi;"Since oom_init() is called before userspace processes start, memory
allocation failure for creating the OOM reaper kernel thread will let
the OOM killer call panic() rather than wake up the OOM reaper.";Tetsuo Handa;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;mm: consolidate page table accounting;Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;"Currently, we account page tables separately for each page table level,
but that's redundant -- we only make use of total memory allocated to
page tables for oom_badness calculation";Kirill A. Shutemov;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;" We also provide the
information to userspace, but it has dubious value there too";Kirill A. Shutemov;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;This patch switches page table accounting to single counter;Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;mm->pgtables_bytes is now used to account all page table levels;Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;" We use
bytes, because page table size for different levels of page table tree
may be different";Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;"The change has user-visible effect: we don't have VmPMD and VmPUD
reported in /proc/[pid]/status";Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2; Not sure if anybody uses them;Kirill A. Shutemov;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;" (As
alternative, we can always report 0 kB for them.)
OOM-killer report is also slightly changed: we now report pgtables_bytes
instead of nr_ptes, nr_pmd, nr_puds";Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;"Apart from reducing number of counters per-mm, the benefit is that we
now calculate oom_badness() more correctly for machines which have
different size of page tables depending on level or where page tables
are less than a page in size";Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;"The only downside can be debuggability because we do not know which page
table level could leak";Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViMGY2YTA5ZTQyYzlmNGZhODc3MzVmMmEzNjY3NDg3NjdiNjg2;" But I do not remember many bugs that would be
caught by separate counters so I wouldn't lose sleep over this.";Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNDgxMjkwOWY1ZDVhOWI3ZjFjODVhMmQ5NWJlMzg4YTA2NmNkYTUy;mm: introduce wrappers to access mm->nr_ptes;Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNDgxMjkwOWY1ZDVhOWI3ZjFjODVhMmQ5NWJlMzg4YTA2NmNkYTUy;"Let's add wrappers for ->nr_ptes with the same interface as for nr_pmd
and nr_pud";Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNDgxMjkwOWY1ZDVhOWI3ZjFjODVhMmQ5NWJlMzg4YTA2NmNkYTUy;The patch also makes nr_ptes accounting dependent onto CONFIG_MMU;Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODpjNDgxMjkwOWY1ZDVhOWI3ZjFjODVhMmQ5NWJlMzg4YTA2NmNkYTUy;" Page
table accounting doesn't make sense if you don't have page tables";Kirill A. Shutemov;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpjNDgxMjkwOWY1ZDVhOWI3ZjFjODVhMmQ5NWJlMzg4YTA2NmNkYTUy;It's preparation for consolidation of page-table counters in mm_struct.;Kirill A. Shutemov;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;mm: account pud page tables;Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;"On a machine with 5-level paging support a process can allocate
significant amount of memory and stay unnoticed by oom-killer and memory
cgroup";Kirill A. Shutemov;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw; The trick is to allocate a lot of PUD page tables;Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;" We don't
account PUD page tables, only PMD and PTE";Kirill A. Shutemov;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;"We already addressed the same issue for PMD page tables, see commit
dc6c9a35b66b (""mm: account pmd page tables to the process"")";Kirill A. Shutemov;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;"Introduction of 5-level paging brings the same issue for PUD page
tables";Kirill A. Shutemov;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpiNGU5OGQ5YWM3NzU5MDdjYzUzZmIwOGZjYjY3NzZkZWI3Njk0ZTMw;The patch expands accounting to PUD level.;Kirill A. Shutemov;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;mm: oom: show unreclaimable slab info when unreclaimable slabs > user memory;Yang Shi;2017-11-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;"The kernel may panic when an oom happens without killable process
sometimes it is caused by huge unreclaimable slabs used by kernel";Yang Shi;2017-11-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;"Although kdump could help debug such problem, however, kdump is not
available on all architectures and it might be malfunction sometime";Yang Shi;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;"And, since kernel already panic it is worthy capturing such information
in dmesg to aid touble shooting";Yang Shi;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;"Print out unreclaimable slab info (used size and total size) which
actual memory usage is not zero (num_objs * size != 0) when
unreclaimable slabs amount is greater than total user memory (LRU
pages)";Yang Shi;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;The output looks like;Yang Shi;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;  Unreclaimable slab info;Yang Shi;2017-11-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NTJkOGJlMGFkODUxMTYxMWVmZjE4ZjI4ZGNlMTFkMjUxOTViNjU0;"  Name                      Used          Total
  rpc_buffers               31KB         31KB
  rpc_tasks                  7KB          7KB
  ebitmap_node            1964KB       1964KB
  avtab_node              5024KB       5024KB
  xfs_buf                 1402KB       1402KB
  xfs_ili                  134KB        134KB
  xfs_efi_item             115KB        115KB
  xfs_efd_item             115KB        115KB
  xfs_buf_item             134KB        134KB
  xfs_log_item_desc        342KB        342KB
  xfs_trans               1412KB       1412KB
  xfs_ifork                212KB        212KB";Yang Shi;2017-11-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;mm, oom_reaper: skip mm structs with mmu notifiers;Michal Hocko;2017-10-03;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"Andrea has noticed that the oom_reaper doesn't invalidate the range via
mmu notifiers (mmu_notifier_invalidate_range_start/end) and that can
corrupt the memory of the kvm guest for example";Michal Hocko;2017-10-03;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"tlb_flush_mmu_tlbonly already invokes mmu notifiers but that is not
sufficient as per Andrea";Michal Hocko;2017-10-03;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;" ""mmu_notifier_invalidate_range cannot be used in replacement of
  mmu_notifier_invalidate_range_start/end";Michal Hocko;2017-10-03;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"For KVM
  mmu_notifier_invalidate_range is a noop and rightfully so";Michal Hocko;2017-10-03;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"A MMU
  notifier implementation has to implement either ->invalidate_range
  method or the invalidate_range_start/end methods, not both";Michal Hocko;2017-10-03;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"And if you
  implement invalidate_range_start/end like KVM is forced to do, calling
  mmu_notifier_invalidate_range in common code is a noop for KVM";Michal Hocko;2017-10-03;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"  For those MMU notifiers that can get away only implementing
  ->invalidate_range, the ->invalidate_range is implicitly called by
  mmu_notifier_invalidate_range_end()";Michal Hocko;2017-10-03;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;"And only those secondary MMUs
  that share the same pagetable with the primary MMU (like AMD iommuv2)
  can get away only implementing ->invalidate_range""
As the callback is allowed to sleep and the implementation is out of
hand of the MM it is safer to simply bail out if there is an mmu
notifier registered";Michal Hocko;2017-10-03;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDRiYmQ4NTI2YThmYmViMmMwOTBlYTM2MDIxMWZjZWZmOTUyMzgz;" In order to not fail too early make the
mm_has_notifiers check under the oom_lock and have a little nap before
failing to give the current oom victim some more time to exit.";Michal Hocko;2017-10-03;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;mm: oom: let oom_reap_task and exit_mmap run concurrently;Andrea Arcangeli;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"This is purely required because exit_aio() may block and exit_mmap() may
never start, if the oom_reap_task cannot start running on a mm with
mm_users == 0";Andrea Arcangeli;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"At the same time if the OOM reaper doesn't wait at all for the memory of
the current OOM candidate to be freed by exit_mmap->unmap_vmas, it would
generate a spurious OOM kill";Andrea Arcangeli;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"If it wasn't because of the exit_aio or similar blocking functions in
the last mmput, it would be enough to change the oom_reap_task() in the
case it finds mm_users == 0, to wait for a timeout or to wait for
__mmput to set MMF_OOM_SKIP itself, but it's not just exit_mmap the
problem here so the concurrency of exit_mmap and oom_reap_task is
apparently warranted";Andrea Arcangeli;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"It's a non standard runtime, exit_mmap() runs without mmap_sem, and
oom_reap_task runs with the mmap_sem for reading as usual (kind of
MADV_DONTNEED)";Andrea Arcangeli;2017-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"The race between the two is solved with a combination of
tsk_is_oom_victim() (serialized by task_lock) and MMF_OOM_SKIP
(serialized by a dummy down_write/up_write cycle on the same lines of
the ksm_exit method)";Andrea Arcangeli;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"If the oom_reap_task() may be running concurrently during exit_mmap,
exit_mmap will wait it to finish in down_write (before taking down mm
structures that would make the oom_reap_task fail with use after free)";Andrea Arcangeli;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMTI5MjU4MDI0NTQ2NzJlNmNkMjk0OWE3MjdmNWUyYzEzNzdiZjA2;"If exit_mmap comes first, oom_reap_task() will skip the mm if
MMF_OOM_SKIP is already set and in turn all memory is already freed and
furthermore the mm data structures may already have been taken down by
free_pgtables.";Andrea Arcangeli;2017-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;mm, oom: do not rely on TIF_MEMDIE for memory reserves access;Michal Hocko;2017-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"For ages we have been relying on TIF_MEMDIE thread flag to mark OOM
victims and then, among other things, to give these threads full access
to memory reserves";Michal Hocko;2017-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" There are few shortcomings of this implementation,
though";Michal Hocko;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"First of all and the most serious one is that the full access to memory
reserves is quite dangerous because we leave no safety room for the
system to operate and potentially do last emergency steps to move on";Michal Hocko;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"Secondly this flag is per task_struct while the OOM killer operates on
mm_struct granularity so all processes sharing the given mm are killed";Michal Hocko;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"Giving the full access to all these task_structs could lead to a quick
memory reserves depletion";Michal Hocko;2017-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" We have tried to reduce this risk by giving
TIF_MEMDIE only to the main thread and the currently allocating task but
that doesn't really solve this problem while it surely opens up a room
for corner cases - e.g";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" GFP_NO{FS,IO} requests might loop inside the
allocator without access to memory reserves because a particular thread
was not the group leader";Michal Hocko;2017-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"Now that we have the oom reaper and that all oom victims are reapable
after 1b51e65eab64 (""oom, oom_reaper: allow to reap mm shared by the
kthreads"") we can be more conservative and grant only partial access to
memory reserves because there are reasonable chances of the parallel
memory freeing";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" We still want some access to reserves because we do not
want other consumers to eat up the victim's freed memory";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" oom victims
will still contend with __GFP_HIGH users but those shouldn't be so
aggressive to starve oom victims completely";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"Introduce ALLOC_OOM flag and give all tsk_is_oom_victim tasks access to
the half of the reserves";Michal Hocko;2017-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" This makes the access to reserves independent
on which task has passed through mark_oom_victim";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" Also drop any usage
of TIF_MEMDIE from the page allocator proper and replace it by
tsk_is_oom_victim as well which will make page_alloc.c completely
TIF_MEMDIE free finally";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"CONFIG_MMU=n doesn't have oom reaper so let's stick to the original
ALLOC_NO_WATERMARKS approach";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;"There is a demand to make the oom killer memcg aware which will imply
many tasks killed at once";Michal Hocko;2017-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpjZDA0YWUxZTJkYzhlMzY1MWI4YzQyN2VjMWI5NTAwYzZlZWQ3Yjkw;" This change will allow such a usecase
without worrying about complete memory reserves depletion.";Michal Hocko;2017-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;mm/oom_kill.c: add tracepoints for oom reaper-related events;Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"During the debugging of the problem described in
and fixed by Tetsuo Handa in
, I've found that the existing debug
output is not really useful to understand issues related to the oom
reaper";Roman Gushchin;2017-07-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"So, I assume, that adding some tracepoints might help with debugging of
similar issues";Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;Trace the following events;Roman Gushchin;2017-07-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;" 1) a process is marked as an oom victim,
 2) a process is added to the oom reaper list,
 3) the oom reaper starts reaping process's mm,
 4) the oom reaper finished reaping,
 5) the oom reaper skips reaping";Roman Gushchin;2017-07-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"How it works in practice? Below is an example which show how the problem
mentioned above can be found: one process is added twice to the
oom_reaper list";Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;          allocate-502   [001] ...;Roman Gushchin;2017-07-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"   91.836405: mark_victim: pid=502
          allocate-502   [001] .N.";Roman Gushchin;2017-07-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"   91.837356: wake_reaper: pid=502
          allocate-502   [000] .N.";Roman Gushchin;2017-07-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"   91.871149: wake_reaper: pid=502
        oom_reaper-23    [000] ...";Roman Gushchin;2017-07-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"   91.871177: start_task_reaping: pid=502
        oom_reaper-23    [000] .N.";Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;"   91.879511: finish_task_reaping: pid=502
        oom_reaper-23    [000] ...";Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjI1ODBjM2NlYTdmYWFjYTY3ZjYxOTkzNzViNzk1NjVkM2Q4ZWJk;   91.879580: skip_task_reaping: pid=502;Roman Gushchin;2017-07-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZTY3NWY3YWY1MDc0N2UxZTllOTY1MzhlODcwNjc2N2U0ZjgwZTJj;mm/oom_kill: count global and memory cgroup oom kills;Konstantin Khlebnikov;2017-07-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ZTY3NWY3YWY1MDc0N2UxZTllOTY1MzhlODcwNjc2N2U0ZjgwZTJj;"Show count of oom killer invocations in /proc/vmstat and count of
processes killed in memory cgroup in knob ""memory.events"" (in
memory.oom_control for v1 cgroup)";Konstantin Khlebnikov;2017-07-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ZTY3NWY3YWY1MDc0N2UxZTllOTY1MzhlODcwNjc2N2U0ZjgwZTJj;"Also describe difference between ""oom"" and ""oom_kill"" in memory cgroup
documentation";Konstantin Khlebnikov;2017-07-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZTY3NWY3YWY1MDc0N2UxZTllOTY1MzhlODcwNjc2N2U0ZjgwZTJj;" Currently oom in memory cgroup kills tasks iff shortage
has happened inside page fault";Konstantin Khlebnikov;2017-07-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ZTY3NWY3YWY1MDc0N2UxZTllOTY1MzhlODcwNjc2N2U0ZjgwZTJj;These counters helps in monitoring oom kills - for now the only way is;Konstantin Khlebnikov;2017-07-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;oom: improve oom disable handling;Michal Hocko;2017-05-03;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;"Tetsuo has reported that sysrq triggered OOM killer will print a
misleading information when no tasks are selected";Michal Hocko;2017-05-03;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;"  sysrq: SysRq : Manual OOM execution
  Out of memory: Kill process 4468 ((agetty)) score 0 or sacrifice child
  Killed process 4468 ((agetty)) total-vm:43704kB, anon-rss:1760kB, file-rss:0kB, shmem-rss:0kB
  sysrq: SysRq : Manual OOM execution
  Out of memory: Kill process 4469 (systemd-cgroups) score 0 or sacrifice child
  Killed process 4469 (systemd-cgroups) total-vm:10704kB, anon-rss:120kB, file-rss:0kB, shmem-rss:0kB
  sysrq: SysRq : Manual OOM execution
  sysrq: OOM request ignored because killer is disabled
  sysrq: SysRq : Manual OOM execution
  sysrq: OOM request ignored because killer is disabled
  sysrq: SysRq : Manual OOM execution
  sysrq: OOM request ignored because killer is disabled
The real reason is that there are no eligible tasks for the OOM killer
to select but since commit 7c5f64f84483 (""mm: oom: deduplicate victim
selection code for memcg and global oom"") the semantic of out_of_memory
has changed without updating moom_callback";Michal Hocko;2017-05-03;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;"This patch updates moom_callback to tell that no task was eligible which
is the case for both oom killer disabled and no eligible tasks";Michal Hocko;2017-05-03;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;" In
order to help distinguish first case from the second add printk to both
oom_killer_{enable,disable}";Michal Hocko;2017-05-03;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;" This information is useful on its own
because it might help debugging potential memory allocation failures";Michal Hocko;2017-05-03;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNzVkYTAwNGM3MDhjOWZjYTdiNTNmN2RhMjkzYTI5NTUyMjQxNGQ5;"Fixes: 7c5f64f84483 (""mm: oom: deduplicate victim selection code for memcg and global oom"")";Michal Hocko;2017-05-03;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOTkzMDAyNThkMWJjNGU5OTdiN2RiMzQwYTJlMDY2MzY3NTdmZTJl;sched/headers: Prepare for new header dependencies before moving code to <linux/sched/task.h>;Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOTkzMDAyNThkMWJjNGU5OTdiN2RiMzQwYTJlMDY2MzY3NTdmZTJl;"We are going to split <linux/sched/task.h> out of <linux/sched.h>, which
will have to be picked up from other headers and a couple of .c files";Ingo Molnar;2017-02-08;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOTkzMDAyNThkMWJjNGU5OTdiN2RiMzQwYTJlMDY2MzY3NTdmZTJl;"Create a trivial placeholder <linux/sched/task.h> file that just
maps to <linux/sched.h> to make this patch obviously correct and
bisectable";Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOTkzMDAyNThkMWJjNGU5OTdiN2RiMzQwYTJlMDY2MzY3NTdmZTJl;Include the new header in the files that are going to need it.;Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpmN2NjYmFlNDVjNWUyYzEwNzc2NTRiMGU4NTdlN2VmYjFhYTMxYzky;sched/headers: Prepare for new header dependencies before moving code to <linux/sched/coredump.h>;Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpmN2NjYmFlNDVjNWUyYzEwNzc2NTRiMGU4NTdlN2VmYjFhYTMxYzky;"We are going to split <linux/sched/coredump.h> out of <linux/sched.h>, which
will have to be picked up from other headers and a couple of .c files";Ingo Molnar;2017-02-08;0;1
MDY6Q29tbWl0MjMyNTI5ODpmN2NjYmFlNDVjNWUyYzEwNzc2NTRiMGU4NTdlN2VmYjFhYTMxYzky;"Create a trivial placeholder <linux/sched/coredump.h> file that just
maps to <linux/sched.h> to make this patch obviously correct and
bisectable";Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpmN2NjYmFlNDVjNWUyYzEwNzc2NTRiMGU4NTdlN2VmYjFhYTMxYzky;Include the new header in the files that are going to need it.;Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTg0ZjMxNTIyZjkzMTAyN2JmNjk1NzUyMDg3ZWNlMjc4YzEwZDNm;sched/headers: Prepare for new header dependencies before moving code to <linux/sched/mm.h>;Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTg0ZjMxNTIyZjkzMTAyN2JmNjk1NzUyMDg3ZWNlMjc4YzEwZDNm;"We are going to split <linux/sched/mm.h> out of <linux/sched.h>, which
will have to be picked up from other headers and a couple of .c files";Ingo Molnar;2017-02-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTg0ZjMxNTIyZjkzMTAyN2JmNjk1NzUyMDg3ZWNlMjc4YzEwZDNm;"Create a trivial placeholder <linux/sched/mm.h> file that just
maps to <linux/sched.h> to make this patch obviously correct and
bisectable";Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTg0ZjMxNTIyZjkzMTAyN2JmNjk1NzUyMDg3ZWNlMjc4YzEwZDNm;The APIs that are going to be moved first are;Ingo Molnar;2017-02-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZTg0ZjMxNTIyZjkzMTAyN2JmNjk1NzUyMDg3ZWNlMjc4YzEwZDNm;"   mm_alloc()
   __mmdrop()
   mmdrop()
   mmdrop_async_fn()
   mmdrop_async()
   mmget_not_zero()
   mmput()
   mmput_async()
   get_task_mm()
   mm_access()
   mm_release()
Include the new header in the files that are going to need it.";Ingo Molnar;2017-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMWYxMDA3NjQ0ZmZjODA1MWE0YzExNDI3ZDU4YjE5NjdhZTdiNzVh;mm: add new mmgrab() helper;Vegard Nossum;2017-02-27;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMWYxMDA3NjQ0ZmZjODA1MWE0YzExNDI3ZDU4YjE5NjdhZTdiNzVh;"Apart from adding the helper function itself, the rest of the kernel is
converted mechanically using";Vegard Nossum;2017-02-27;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMWYxMDA3NjQ0ZmZjODA1MWE0YzExNDI3ZDU4YjE5NjdhZTdiNzVh;"This is needed for a later patch that hooks into the helper, but might
be a worthwhile cleanup on its own";Vegard Nossum;2017-02-27;0;1
MDY6Q29tbWl0MjMyNTI5ODpmMWYxMDA3NjQ0ZmZjODA1MWE0YzExNDI3ZDU4YjE5NjdhZTdiNzVh;(Michal Hocko provided most of the kerneldoc comment.);Vegard Nossum;2017-02-27;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOTljNTE3YWRiOTAzZGRkMzc2ZGQxMDNmY2M5ZGNmZmYzZDQ3Mjhi;mm, oom: header nodemask is NULL when cpusets are disabled;David Rientjes;2017-02-24;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOTljNTE3YWRiOTAzZGRkMzc2ZGQxMDNmY2M5ZGNmZmYzZDQ3Mjhi;"Commit 82e7d3abec86 (""oom: print nodemask in the oom report"") implicitly
sets the allocation nodemask to cpuset_current_mems_allowed when there
is no effective mempolicy";David Rientjes;2017-02-24;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOTljNTE3YWRiOTAzZGRkMzc2ZGQxMDNmY2M5ZGNmZmYzZDQ3Mjhi;" cpuset_current_mems_allowed is only
effective when cpusets are enabled, which is also printed by
dump_header(), so setting the nodemask to cpuset_current_mems_allowed is
redundant and prevents debugging issues where ac->nodemask is not set
properly in the page allocator";David Rientjes;2017-02-24;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOTljNTE3YWRiOTAzZGRkMzc2ZGQxMDNmY2M5ZGNmZmYzZDQ3Mjhi;"This provides better debugging output since
cpuset_print_current_mems_allowed() is already provided.";David Rientjes;2017-02-24;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMzUxOTA3MzhhYmE3YzVjOTQzMDBjOGQ4ODI4NDJhNTM1MjgwZTVh;oom-reaper: use madvise_dontneed() logic to decide if unmap the VMA;Kirill A. Shutemov;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMzUxOTA3MzhhYmE3YzVjOTQzMDBjOGQ4ODI4NDJhNTM1MjgwZTVh;"Logic on whether we can reap pages from the VMA should match what we
have in madvise_dontneed()";Kirill A. Shutemov;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMzUxOTA3MzhhYmE3YzVjOTQzMDBjOGQ4ODI4NDJhNTM1MjgwZTVh;" In particular, we should skip, VM_PFNMAP
VMAs, but we don't now";Kirill A. Shutemov;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMzUxOTA3MzhhYmE3YzVjOTQzMDBjOGQ4ODI4NDJhNTM1MjgwZTVh;"Let's just extract condition on which we can shoot down pagesi from a
VMA with MADV_DONTNEED into separate function and use it in both places.";Kirill A. Shutemov;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozZTg3MTVmZGMwM2U4ZGY0ZDI2ZDhlNDM2MTY2ZTQ0ZTNlNDE2ZDNi;mm: drop zap_details::check_swap_entries;Kirill A. Shutemov;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozZTg3MTVmZGMwM2U4ZGY0ZDI2ZDhlNDM2MTY2ZTQ0ZTNlNDE2ZDNi;"detail == NULL would give the same functionality as
.check_swap_entries==true.";Kirill A. Shutemov;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYTE2MmU5MzY4OTkwZWQ3NDcwNzVlMmFiNDI3ZGEwNzU5ZmM0YTU5;mm: drop zap_details::ignore_dirty;Kirill A. Shutemov;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYTE2MmU5MzY4OTkwZWQ3NDcwNzVlMmFiNDI3ZGEwNzU5ZmM0YTU5;The only user of ignore_dirty is oom-reaper;Kirill A. Shutemov;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYTE2MmU5MzY4OTkwZWQ3NDcwNzVlMmFiNDI3ZGEwNzU5ZmM0YTU5;" But it doesn't really use
ignore_dirty only has effect on file pages mapped with dirty pte";Kirill A. Shutemov;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYTE2MmU5MzY4OTkwZWQ3NDcwNzVlMmFiNDI3ZGEwNzU5ZmM0YTU5;" But
oom-repear skips shared VMAs, so there's no way we can dirty file pte in
them.";Kirill A. Shutemov;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;mm, oom: do not enforce OOM killer for __GFP_NOFAIL automatically;Michal Hocko;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;"__alloc_pages_may_oom makes sure to skip the OOM killer depending on the
allocation request";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" This includes lowmem requests, costly high order
requests and others";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" For a long time __GFP_NOFAIL acted as an override
for all those rules";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" This is not documented and it can be quite
surprising as well";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3; E.g;Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" GFP_NOFS requests are not invoking the OOM
killer but GFP_NOFS|__GFP_NOFAIL does so if we try to convert some of
the existing open coded loops around allocator to nofail request (and we
have done that in the past) then such a change would have a non trivial
side effect which is far from obvious";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" Note that the primary motivation
for skipping the OOM killer is to prevent from pre-mature invocation";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;"The exception has been added by commit 82553a937f12 (""oom: invoke oom
killer for __GFP_NOFAIL"")";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" The changelog points out that the oom killer
has to be invoked otherwise the request would be looping for ever";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" But
this argument is rather weak because the OOM killer doesn't really
guarantee a forward progress for those exceptional cases";Michal Hocko;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;"- it will hardly help to form costly order which in turn can result in
  the system panic because of no oom killable task in the end - I believe
  we certainly do not want to put the system down just because there is a
  nasty driver asking for order-9 page with GFP_NOFAIL not realizing all
  the consequences";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;" It is much better this request would loop for ever
  than the massive system disruption
- lowmem is also highly unlikely to be freed during OOM killer
- GFP_NOFS request could trigger while there is still a lot of memory
  pinned by filesystems";Michal Hocko;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODowNmFkMjc2YWMxODc0MmM2YjI4MTY5OGQ0MWIyN2EyOTBjZDQyNDA3;"This patch simply removes the __GFP_NOFAIL special case in order to have a
more clear semantic without surprising side effects.";Michal Hocko;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;lib/show_mem.c: teach show_mem to work with the given nodemask;Michal Hocko;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;"show_mem() allows to filter out node specific data which is irrelevant
to the allocation request via SHOW_MEM_FILTER_NODES";Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;" The filtering is
done in skip_free_areas_node which skips all nodes which are not in the
mems_allowed of the current process";Michal Hocko;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;" This works most of the time as
expected because the nodemask shouldn't be outside of the allocating
task but there are some exceptions";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4; E.g;Michal Hocko;2017-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;" memory hotplug might want to
request allocations from outside of the allowed nodes (see
new_node_page)";Michal Hocko;2017-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;"Get rid of this hardcoded behavior and push the allocation mask down the
show_mem path and use it instead of cpuset_current_mems_allowed";Michal Hocko;2017-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YWY3NDRkNzQzMTcwYjVmNWVmNzAwMzFkZWE4ZDc3MmQxNjZhYjI4;" NULL
nodemask is interpreted as cpuset_current_mems_allowed.";Michal Hocko;2017-02-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;oom: print nodemask in the oom report;Michal Hocko;2016-10-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;We have received a hard to explain oom report from a customer;Michal Hocko;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" The oom
triggered regardless there is a lot of free memory";Michal Hocko;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;"  PoolThread invoked oom-killer: gfp_mask=0x280da, order=0, oom_adj=0, oom_score_adj=0
  PoolThread cpuset=/ mems_allowed=0-7
  Pid: 30055, comm: PoolThread Tainted: G           E X 3.0.101-80-default #1
  So all nodes but Node 0 have a lot of free memory which should suggest
that there is an available memory especially when mems_allowed=0-7";Michal Hocko;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" One
could speculate that a massive process has managed to terminate and free
up a lot of memory while racing with the above allocation request";Michal Hocko;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;Although this is highly unlikely it cannot be ruled out;Michal Hocko;2016-10-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;"A further debugging, however shown that the faulting process had
mempolicy (not cpuset) to bind to Node 0";Michal Hocko;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" We cannot see that
information from the report though";Michal Hocko;2016-10-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" mems_allowed turned out to be more
confusing than really helpful";Michal Hocko;2016-10-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;Fix this by always priting the nodemask;Michal Hocko;2016-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" It is either mempolicy mask
(and non-null) or the one defined by the cpusets";Michal Hocko;2016-10-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" The new output for
the above oom report would be
  PoolThread invoked oom-killer: gfp_mask=0x280da(GFP_HIGHUSER_MOVABLE|__GFP_ZERO), nodemask=0, order=0, oom_adj=0, oom_score_adj=0
This patch doesn't touch show_mem and the node filtering based on the
cpuset node mask because mempolicy is always a subset of cpusets and
seeing the full cpuset oom context might be helpful for tunning more
specific mempolicies inside cpusets (e.g";Michal Hocko;2016-10-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" when they turn out to be too
restrictive)";Michal Hocko;2016-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo4MmU3ZDNhYmVjODZjYmE5ZGY5NDVhNzY1YmJhMzg0ZjhhYzExM2E3;" To prevent from ugly ifdefs the mask is printed even for
!NUMA configurations but this should be OK (a single node will be
printed).";Michal Hocko;2016-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;mm: don't emit warning from pagefault_out_of_memory();Tetsuo Handa;2016-10-08;1;0
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;"Commit c32b3cbe0d06 (""oom, PM: make OOM detection in the freezer path
raceless"") inserted a WARN_ON() into pagefault_out_of_memory() in order
to warn when we raced with disabling the OOM killer";Tetsuo Handa;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;"Now, patch ""oom, suspend: fix oom_killer_disable vs";Tetsuo Handa;2016-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;" pm suspend
properly"" introduced a timeout for oom_killer_disable()";Tetsuo Handa;2016-10-08;0;0
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;" Even if we
raced with disabling the OOM killer and the system is OOM livelocked,
the OOM killer will be enabled eventually (in 20 seconds by default) and
the OOM livelock will be solved";Tetsuo Handa;2016-10-08;0;1
MDY6Q29tbWl0MjMyNTI5ODphMTA0ODA4ZTIxMmE5ZWU5N2U2YjljYjY5NDUxODVlNTA5MDVmMDA5;" Therefore, we no longer need to warn
when we raced with disabling the OOM killer.";Tetsuo Handa;2016-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;oom: warn if we go OOM for higher order and compaction is disabled;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;"Since the lumpy reclaim is gone there is no source of higher order pages
if CONFIG_COMPACTION=n except for the order-0 pages reclaim which is
unreliable for that purpose to say the least";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;" Hitting an OOM for
!costly higher order requests is therefore all not that hard to imagine";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;"We are trying hard to not invoke OOM killer as much as possible but
there is simply no reliable way to detect whether more reclaim retries
make sense";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;"Disabling COMPACTION is not widespread but it seems that some users
might have disable the feature without realizing full consequences
(mostly along with disabling THP because compaction used to be THP
mainly thing)";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;" This patch just adds a note if the OOM killer was
triggered by higher order request with compaction disabled";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo5MjU0OTkwZmI5ZjBmMTVmMjU2MDU3NDhkYTIwY2ZiZWNlZDdjODE2;" This will
help us identifying possible misconfiguration right from the oom report
which is easier than to always keep in mind that somebody might have
disabled COMPACTION without a good reason.";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYjUxZTY1ZWFiNjRmYWM3MmNhYjAwOTY5MWU4Y2E5OTE1NjI0ODc2;oom, oom_reaper: allow to reap mm shared by the kthreads;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYjUxZTY1ZWFiNjRmYWM3MmNhYjAwOTY5MWU4Y2E5OTE1NjI0ODc2;"oom reaper was skipped for an mm which is shared with the kernel thread
(aka use_mm())";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODoxYjUxZTY1ZWFiNjRmYWM3MmNhYjAwOTY5MWU4Y2E5OTE1NjI0ODc2;" The primary concern was that such a kthread might want
to read from the userspace memory and see zero page as a result of the
oom reaper action";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYjUxZTY1ZWFiNjRmYWM3MmNhYjAwOTY5MWU4Y2E5OTE1NjI0ODc2;" This is no longer a problem after ""mm: make sure
that kthreads will not refault oom reaped memory"" because any attempt to
fault in when the MMF_UNSTABLE is set will result in SIGBUS and so the
target user should see an error";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYjUxZTY1ZWFiNjRmYWM3MmNhYjAwOTY5MWU4Y2E5OTE1NjI0ODc2;" This means that we can finally allow
oom reaper also to tasks which share their mm with kthreads.";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;mm: make sure that kthreads will not refault oom reaped memory;Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;There are only few use_mm() users in the kernel right now;Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;" Most of them
write to the target memory but vhost driver relies on
copy_from_user/get_user from a kernel thread context";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;" This makes it
impossible to reap the memory of an oom victim which shares the mm with
the vhost kernel thread because it could see a zero page unexpectedly
and theoretically make an incorrect decision visible outside of the
killed task context";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;To quote Michael S;Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;Tsirkin;Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;: Getting an error from __get_user and friends is handled gracefully;Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;": Getting zero instead of a real value will cause userspace
: memory corruption";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;"The vhost kernel thread is bound to an open fd of the vhost device which
is not tight to the mm owner life cycle in general";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;" The device fd can
be inherited or passed over to another process which means that we
really have to be careful about unexpected memory corruption because
unlike for normal oom victims the result will be visible outside of the
oom victim context";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;"Make sure that no kthread context (users of use_mm) can ever see
corrupted data because of the oom reaper and hook into the page fault
path by checking MMF_UNSTABLE mm flag";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;" __oom_reap_task_mm will set the
flag before it starts unmapping the address space while the flag is
checked after the page fault has been handled";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;" If the flag is set then
SIGBUS is triggered so any g-u-p user will get a error code";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;"Regular tasks do not need this protection because all which share the mm
are killed when the mm is reaped and so the corruption will not outlive
them";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjcwZGMzOGNlYzJhZDZlNTM1NWY4MGM0YzdhMTVhM2Y3ZTk3YTE5;"This patch shouldn't have any visible effect at this moment because the
OOM killer doesn't invoke oom reaper for tasks with mm shared with
kthreads yet.";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODozODUzMTIwMWMxMjE0NGNkN2Q5NmFiZmRmZTc0NDljMmIwMTM3NWU4;mm, oom: enforce exit_oom_victim on current task;Tetsuo Handa;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODozODUzMTIwMWMxMjE0NGNkN2Q5NmFiZmRmZTc0NDljMmIwMTM3NWU4;"There are no users of exit_oom_victim on !current task anymore so enforce
the API to always work on the current.";Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;oom, suspend: fix oom_killer_disable vs. pm suspend properly;Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;"Commit 74070542099c (""oom, suspend: fix oom_reaper vs";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;"oom_killer_disable race"") has workaround an existing race between
oom_killer_disable and oom_reaper by adding another round of
try_to_freeze_tasks after the oom killer was disabled";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;" This was the
easiest thing to do for a late 4.7 fix";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw; Let's fix it properly now;Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;"After ""oom: keep mm of the killed task available"" we no longer have to
call exit_oom_victim from the oom reaper because we have stable mm
available and hide the oom_reaped mm by MMF_OOM_SKIP flag";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;" So let's
remove exit_oom_victim and the race described in the above commit
doesn't exist anymore if";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;"Unfortunately this alone is not sufficient for the oom_killer_disable
usecase because now we do not have any reliable way to reach
exit_oom_victim (the victim might get stuck on a way to exit for an
unbounded amount of time)";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;" OOM killer can cope with that by checking mm
flags and move on to another victim but we cannot do the same for
oom_killer_disable as we would lose the guarantee of no further
interference of the victim with the rest of the system";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;" What we can do
instead is to cap the maximum time the oom_killer_disable waits for
victims";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;" The only current user of this function (pm suspend) already
has a concept of timeout for back off so we can reuse the same value
there";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZDJlN2EyMmNmMjdlNzU2OWU2ODE2Y2NjMDVkZDc0MjQ4MDQ4YjMw;"Let's drop set_freezable for the oom_reaper kthread because it is no
longer needed as the reaper doesn't wake or thaw any processes.";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NjJlMzA3M2IzZWVkMTNmMTdiZDZiZTZjYTYwNTJkYjE1YzBiNzI4;mm, oom: get rid of signal_struct::oom_victims;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NjJlMzA3M2IzZWVkMTNmMTdiZDZiZTZjYTYwNTJkYjE1YzBiNzI4;"After ""oom: keep mm of the killed task available"" we can safely detect
an oom victim by checking task->signal->oom_mm so we do not need the
signal_struct counter anymore so let's get rid of it";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NjJlMzA3M2IzZWVkMTNmMTdiZDZiZTZjYTYwNTJkYjE1YzBiNzI4;"This alone wouldn't be sufficient for nommu archs because
exit_oom_victim doesn't hide the process from the oom killer anymore";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NjJlMzA3M2IzZWVkMTNmMTdiZDZiZTZjYTYwNTJkYjE1YzBiNzI4;We can, however, mark the mm with a MMF flag in __mmput;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NjJlMzA3M2IzZWVkMTNmMTdiZDZiZTZjYTYwNTJkYjE1YzBiNzI4;" We can reuse
MMF_OOM_REAPED and rename it to a more generic MMF_OOM_SKIP.";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;oom: keep mm of the killed task available;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;"oom_reap_task has to call exit_oom_victim in order to make sure that the
oom vicim will not block the oom killer for ever";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" This is, however,
opening new problems (e.g oom_killer_disable exclusion - see commit
74070542099c (""oom, suspend: fix oom_reaper vs";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" oom_killer_disable
race""))";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" exit_oom_victim should be only called from the victim's
context ideally";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;One way to achieve this would be to rely on per mm_struct flags;Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" We
already have MMF_OOM_REAPED to hide a task from the oom killer since
""mm, oom: hide mm which is shared with kthread or global init""";Michal Hocko;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;"The
problem is that the exit path";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;"  do_exit
    exit_mm
      mmput
        __mmput
      exit_oom_victim
doesn't guarantee that exit_oom_victim will get called in a bounded
amount of time";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" At least exit_aio depends on IO which might get blocked
due to lack of memory and who knows what else is lurking there";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;This patch takes a different approach;Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" We remember tsk->mm into the
signal_struct and bind it to the signal struct life time for all oom
victims";Michal Hocko;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" __oom_reap_task_mm as well as oom_scan_process_thread do not
have to rely on find_lock_task_mm anymore and they will have a reliable
reference to the mm struct";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" As a result all the oom specific
communication inside the OOM killer can be done via tsk->signal->oom_mm";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;"Increasing the signal_struct for something as unlikely as the oom killer
is far from ideal but this approach will make the code much more
reasonable and long term we even might want to move task->mm into the
signal_struct anyway";Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNmRiNjJmMTc5ZDExMmQzNDUwMzFlMTQ5MjZhNGNkYTljZDQwZDZl;" In the next step we might want to make the oom
killer exclusion and access to memory reserves completely independent
which would be also nice.";Michal Hocko;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;mm,oom_reaper: do not attempt to reap a task twice;Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;"""mm, oom_reaper: do not attempt to reap a task twice"" tried to give the
OOM reaper one more chance to retry using MMF_OOM_NOT_REAPABLE flag";Tetsuo Handa;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;"But the usefulness of the flag is rather limited and actually never
shown in practice";Tetsuo Handa;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;" If the flag is set, it means that the holder of
mm->mmap_sem cannot call up_write() due to presumably being blocked at
unkillable wait waiting for other thread's memory allocation";Tetsuo Handa;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;" But since
one of threads sharing that mm will queue that mm immediately via
task_will_free_mem() shortcut (otherwise, oom_badness() will select the
same mm again due to oom_score_adj value unchanged), retrying
MMF_OOM_NOT_REAPABLE mm is unlikely helpful";Tetsuo Handa;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDk2YWZhYmE5M2VjZTgwYTgzY2JkMDk2ZjA2NzVhMTAyMGRkZmM0;Let's always set MMF_OOM_REAPED.;Tetsuo Handa;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;mm,oom_reaper: reduce find_lock_task_mm() usage;Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;"Patch series ""fortify oom killer even more"", v2";Tetsuo Handa;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;This patch (of 9);Tetsuo Handa;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;"__oom_reap_task() can be simplified a bit if it receives a valid mm from
oom_reap_task() which also uses that mm when __oom_reap_task() failed";Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;"We can drop one find_lock_task_mm() call and also make the
__oom_reap_task() code flow easier to follow";Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;" Moreover, this will make
later patch in the series easier to review";Tetsuo Handa;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;" Pinning mm's mm_count for
longer time is not really harmful because this will not pin much memory";Tetsuo Handa;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZWJmZmE0NTU1MWZlN2RiODZhMmIzMmJmNTg2ZjEyNGVmNDg0ZTZl;This patch doesn't introduce any functional change.;Tetsuo Handa;2016-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ODcwYzJlMWQ3OGIwNDNiNjlkZTMxOTk0NjljMDU2Y2EzYjA1MTAy;mm/oom_kill.c: fix task_will_free_mem() comment;Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo1ODcwYzJlMWQ3OGIwNDNiNjlkZTMxOTk0NjljMDU2Y2EzYjA1MTAy;Attempt to demystify the task_will_free_mem() loop.;Michal Hocko;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;mm: oom: deduplicate victim selection code for memcg and global oom;Vladimir Davydov;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;"When selecting an oom victim, we use the same heuristic for both memory
cgroup and global oom";Vladimir Davydov;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;" The only difference is the scope of tasks to
select the victim from";Vladimir Davydov;2016-10-07;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;" So we could just export an iterator over all
memcg tasks and keep all oom related logic in oom_kill.c, but instead we
duplicate pieces of it in memcontrol.c reusing some initially private
functions of oom_kill.c in order to not duplicate all of it";Vladimir Davydov;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;" That looks
ugly and error prone, because any modification of select_bad_process
should also be propagated to mem_cgroup_out_of_memory";Vladimir Davydov;2016-10-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YzVmNjRmODQ0ODNiZDEzODg2MzQ4ZWRkYThiM2U3Yjc5OWE3ZmRi;"Let's rework this as follows: keep all oom heuristic related code private
to oom_kill.c and make oom_kill.c use exported memcg functions when it's
really necessary (like in case of iterating over memcg tasks).";Vladimir Davydov;2016-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMzNlNmYwNjcxYjNiYTgxYWNlZjRkN2MwNzhhZjg2YWZjYzg1NWM0;mm, oom: fix uninitialized ret in task_will_free_mem();Geert Uytterhoeven;2016-08-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMzNlNmYwNjcxYjNiYTgxYWNlZjRkN2MwNzhhZjg2YWZjYzg1NWM0;    mm/oom_kill.c: In function `task_will_free_mem';Geert Uytterhoeven;2016-08-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMzNlNmYwNjcxYjNiYTgxYWNlZjRkN2MwNzhhZjg2YWZjYzg1NWM0;"    mm/oom_kill.c:767: warning: `ret' may be used uninitialized in this function
If __task_will_free_mem() is never called inside the for_each_process()
loop, ret will not be initialized.";Geert Uytterhoeven;2016-08-11;0;1
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;mm, oom: tighten task_will_free_mem() locking;Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;"""mm, oom: fortify task_will_free_mem"" has dropped task_lock around
task_will_free_mem in oom_kill_process bacause it assumed that a
potential race when the selected task exits will not be a problem as the
oom_reaper will call exit_oom_victim";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;"Tetsuo was objecting that nommu doesn't have oom_reaper so the race
would be still possible";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;" The code would be racy and lockup prone
theoretically in other aspects without the oom reaper anyway so I didn't
considered this a big deal";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;" But it seems that further changes I am
planning in this area will benefit from stable task->mm in this path as
well";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;" So let's drop find_lock_task_mm from task_will_free_mem and call
it from under task_lock as we did previously";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODowOTFmMzYyYzUzYzI0Y2E5NzUxNzI3YTY5OWQ2M2U1MDUyOGMzMDZi;" Just pull the task->mm !=
NULL check inside the function.";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;mm, oom: hide mm which is shared with kthread or global init;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;"The only case where the oom_reaper is not triggered for the oom victim
is when it shares the memory with a kernel thread (aka use_mm) or with
the global init";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;" After ""mm, oom: skip vforked tasks from being
selected"" the victim cannot be a vforked task of the global init so we
are left with clone(CLONE_VM) (without CLONE_SIGHAND)";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;" use_mm() users
are quite rare as well";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;"In order to help forward progress for the OOM killer, make sure that
this really rare case will not get in the way - we do this by hiding the
mm from the oom killer by setting MMF_OOM_REAPED flag for it";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;"oom_scan_process_thread will ignore any TIF_MEMDIE task if it has
MMF_OOM_REAPED flag set to catch these oom victims";Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODphMzczOTY2ZDFmNjRjMDRiYTlkMDE1OTA4N2YwZmExYjVhYWM0YzMz;"After this patch we should guarantee forward progress for the OOM killer
even when the selected victim is sharing memory with a kernel thread or
global init as long as the victims mm is still alive.";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;mm, oom_reaper: do not attempt to reap a task more than twice;Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;oom_reaper relies on the mmap_sem for read to do its job;Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;" Many places
which might block readers have been converted to use down_write_killable
and that has reduced chances of the contention a lot";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;" Some paths where
the mmap_sem is held for write can take other locks and they might
either be not prepared to fail due to fatal signal pending or too
impractical to be changed";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;"This patch introduces MMF_OOM_NOT_REAPABLE flag which gets set after the
first attempt to reap a task's mm fails";Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;" If the flag is present after
the failure then we set MMF_OOM_REAPED to hide this mm from the oom
killer completely so it can go and chose another victim";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMWE0MTBkNTE2ZTg5MzIwZmUwODE3NjA2ZWVhYjU4ZjM2YzIyOTY4;"As a result a risk of OOM deadlock when the oom victim would be blocked
indefinetly and so the oom killer cannot make any progress should be
mitigated considerably while we still try really hard to perform all
reclaim attempts and stay predictable in the behavior.";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;mm, oom: task_will_free_mem should skip oom_reaped tasks;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;The 0-day robot has encountered the following;Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;"   Out of memory: Kill process 3914 (trinity-c0) score 167 or sacrifice child
   Killed process 3914 (trinity-c0) total-vm:55864kB, anon-rss:1512kB, file-rss:1088kB, shmem-rss:25616kB
   oom_reaper: reaped process 3914 (trinity-c0), now anon-rss:0kB, file-rss:0kB, shmem-rss:26488kB
   oom_reaper: reaped process 3914 (trinity-c0), now anon-rss:0kB, file-rss:0kB, shmem-rss:26900kB
   oom_reaper: reaped process 3914 (trinity-c0), now anon-rss:0kB, file-rss:0kB, shmem-rss:26900kB
   oom_reaper: reaped process 3914 (trinity-c0), now anon-rss:0kB, file-rss:0kB, shmem-rss:27296kB
   oom_reaper: reaped process 3914 (trinity-c0), now anon-rss:0kB, file-rss:0kB, shmem-rss:28148kB
oom_reaper is trying to reap the same task again and again";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;"This is possible only when the oom killer is bypassed because of
task_will_free_mem because we skip over tasks with MMF_OOM_REAPED
already set during select_bad_process";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;" Teach task_will_free_mem to skip
over MMF_OOM_REAPED tasks as well because they will be unlikely to free
anything more";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo2OTY0NTNlNjY2MzBhZDQ1ZTY0NGM0NTcxMzA3ZmEzZWJlYzlhODM1;Analyzed by Tetsuo Handa.;Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;mm, oom: fortify task_will_free_mem();Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;task_will_free_mem is rather weak;Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;" It doesn't really tell whether the
task has chance to drop its mm";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;" 98748bd72200 (""oom: consider
multi-threaded tasks in task_will_free_mem"") made a first step into making
it more robust for multi-threaded applications so now we know that the
whole process is going down and probably drop the mm";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;"This patch builds on top for more complex scenarios where mm is shared
between different processes - CLONE_VM without CLONE_SIGHAND, or in kernel
use_mm()";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;Make sure that all processes sharing the mm are killed or exiting;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;" This
will allow us to replace try_oom_reaper by wake_oom_reaper because
task_will_free_mem implies the task is reapable now";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYWY4YmI0MzI2OTU2M2U0NThlYmNmMGVjZTgxMmU5YTk3MDg2NGIz;" Therefore all paths
which bypass the oom killer are now reapable and so they shouldn't lock up
the oom killer.";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;mm, oom: kill all tasks sharing the mm;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;"Currently oom_kill_process skips both the oom reaper and SIG_KILL if a
process sharing the same mm is unkillable via OOM_ADJUST_MIN";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;" After ""mm,
oom_adj: make sure processes sharing mm have same view of oom_score_adj""
all such processes are sharing the same value so we shouldn't see such a
task at all (oom_badness would rule them out)";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;"We can still encounter oom disabled vforked task which has to be killed as
well if we want to have other tasks sharing the mm reapable because it can
access the memory before doing exec";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;" Killing such a task should be
acceptable because it is highly unlikely it has done anything useful
because it cannot modify any memory before it calls exec";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;" An alternative
would be to keep the task alive and skip the oom reaper and risk all the
weird corner cases where the OOM killer cannot make forward progress
because the oom victim hung somewhere on the way to exit";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2ZkNDljMjM1NWZmZGVkZTY1MjZhZmMwYzcyYmMzMTRkMDVmNDJh;"[rientjes@google.com - drop printk when OOM_SCORE_ADJ_MIN killed task
 the setting is inherently racy and we cannot do much about it without
 introducing locks in hot paths]";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;mm, oom: skip vforked tasks from being selected;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;vforked tasks are not really sitting on any memory;Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;" They are sharing the
mm with parent until they exec into a new code";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;" Until then it is just
pinning the address space";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;" OOM killer will kill the vforked task along
with its parent but we still can end up selecting vforked task when the
parent wouldn't be selected";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl; E.g;Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;" init doing vfork to launch a task or
vforked being a child of oom unkillable task with an updated oom_score_adj
to be killable";Michal Hocko;2016-07-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpiMThkYzVmMjkxYzA3ZGRhZjMxNTYyYjlmMjdiM2ExMjJmMWY5Yjdl;"Add a new helper to check whether a task is in the vfork sharing memory
with its parent and use it in oom_badness to skip over these tasks.";Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;mm, oom_adj: make sure processes sharing mm have same view of oom_score_adj;Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;"oom_score_adj is shared for the thread groups (via struct signal) but this
is not sufficient to cover processes sharing mm (CLONE_VM without
CLONE_SIGHAND) and so we can easily end up in a situation when some
processes update their oom_score_adj and confuse the oom killer";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" In the
worst case some of those processes might hide from the oom killer
altogether via OOM_SCORE_ADJ_MIN while others are eligible";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" OOM killer
would then pick up those eligible but won't be allowed to kill others
sharing the same mm so the mm wouldn't release the mm and so the memory";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;"It would be ideal to have the oom_score_adj per mm_struct because that is
the natural entity OOM killer considers";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" But this will not work because
some programs are doing
	vfork()
	set_oom_adj()
	exec()
We can achieve the same though";Michal Hocko;2016-07-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" oom_score_adj write handler can set the
oom_score_adj for all processes sharing the same mm if the task is not in
the middle of vfork";Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" As a result all the processes will share the same
oom_score_adj";Michal Hocko;2016-07-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NGE3MGFkZWM5MTBkNjkyOTY4OWU0MmI2ZTVjZWU1YjdkMjAyZDIw;" The current implementation is rather pessimistic and
checks all the existing processes by default if there is more than 1
holder of the mm but we do not have any reliable way to check for external
users yet.";Michal Hocko;2016-07-28;1;0
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;mm, oom_reaper: make sure that mmput_async is called only when memory was reaped;Michal Hocko;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;"Tetsuo is worried that mmput_async might still lead to a premature new
oom victim selection due to the following race";Michal Hocko;2016-07-26;0;1
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;"__oom_reap_task				exit_mm
  find_lock_task_mm
  atomic_inc(mm->mm_users) # = 2
  task_unlock
  					  task_lock
					  task->mm = NULL
					  up_read(&mm->mmap_sem)
		< somebody write locks mmap_sem >
					  task_unlock
					  mmput
  					    atomic_dec_and_test # = 1
					  exit_oom_victim
  down_read_trylock # failed - no reclaim
  mmput_async # Takes unpredictable amount of time
  		< new OOM situation >
the final __mmput will be executed in the delayed context which might
happen far in the future";Michal Hocko;2016-07-26;0;1
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;" Such a race is highly unlikely because the
write holder of mmap_sem would have to be an external task (all direct
holders are already killed or exiting) and it usually have to pin
mm_users in order to do anything reasonable";Michal Hocko;2016-07-26;0;0
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;"We can, however, make sure that the mmput_async is only called when we
do not back off and reap some memory";Michal Hocko;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;" That would reduce the impact of
the delayed __mmput because the real content would be already freed";Michal Hocko;2016-07-26;0;1
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;"Pin mm_count to keep it alive after we drop task_lock and before we try
to get mmap_sem";Michal Hocko;2016-07-26;1;0
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;" If the mmap_sem succeeds we can try to grab mm_users
reference and then go on with unmapping the address space";Michal Hocko;2016-07-26;1;0
MDY6Q29tbWl0MjMyNTI5ODplNWUzZjRjNGYwZTk1ZWNiYWQyZjhkMmY0ZjZhMjliYjhhOTAyMjZi;"It is not clear whether this race is possible at all but it is better to
be more robust and do not pin mm_users unless we are sure we are
actually doing some real work during __oom_reap_task.";Michal Hocko;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYmU4NGEwOWRhNzQ2Zjc4MTU1MzA1MWJiM2RiYzYzZjdiMGE1MTYy;mm,oom: remove unused argument from oom_scan_process_thread().;Tetsuo Handa;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYmU4NGEwOWRhNzQ2Zjc4MTU1MzA1MWJiM2RiYzYzZjdiMGE1MTYy;oom_scan_process_thread() does not use totalpages argument;Tetsuo Handa;2016-07-26;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYmU4NGEwOWRhNzQ2Zjc4MTU1MzA1MWJiM2RiYzYzZjdiMGE1MTYy;oom_badness() uses it.;Tetsuo Handa;2016-07-26;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYTk2NmI3N2FlM2VkZTIwN2U3ODdlNzUzOGI4N2QxMDExYzQzNjRl;mm: oom: add memcg to oom_control;Vladimir Davydov;2016-07-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYTk2NmI3N2FlM2VkZTIwN2U3ODdlNzUzOGI4N2QxMDExYzQzNjRl;"It's a part of oom context just like allocation order and nodemask, so
let's move it to oom_control instead of passing it in the argument list.";Vladimir Davydov;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OThmZDc1Njk1MmM0YjZjYjdkZmU2ZjY0MzdlOWYwMmRhNzlhNWJj;mm: zap ZONE_OOM_LOCKED;Vladimir Davydov;2016-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OThmZDc1Njk1MmM0YjZjYjdkZmU2ZjY0MzdlOWYwMmRhNzlhNWJj;Not used since oom_lock was instroduced.;Vladimir Davydov;2016-07-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ZGYxMGZiN2I4MGJjMmY1NDA5NTZiYTAxYjVlN2VlMTAxMjAwMWE1;oom_reaper: avoid pointless atomic_inc_not_zero usage.;Tetsuo Handa;2016-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ZGYxMGZiN2I4MGJjMmY1NDA5NTZiYTAxYjVlN2VlMTAxMjAwMWE1;"Since commit 36324a990cf5 (""oom: clear TIF_MEMDIE after oom_reaper
managed to unmap the address space"") changed to use find_lock_task_mm()
for finding a mm_struct to reap, it is guaranteed that mm->mm_users > 0
because find_lock_task_mm() returns a task_struct with ->mm != NULL";Tetsuo Handa;2016-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZGYxMGZiN2I4MGJjMmY1NDA5NTZiYTAxYjVlN2VlMTAxMjAwMWE1;Therefore, we can safely use atomic_inc().;Tetsuo Handa;2016-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTFhMWM2NWFlNDk4ZGVhMGUzOWIyNGE0NmU1MjhhNzhhODUzMmVk;mm,oom_reaper: don't call mmput_async() without atomic_inc_not_zero();Tetsuo Handa;2016-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTFhMWM2NWFlNDk4ZGVhMGUzOWIyNGE0NmU1MjhhNzhhODUzMmVk;"Commit e2fe14564d33 (""oom_reaper: close race with exiting task"") reduced
frequency of needlessly selecting next OOM victim, but was calling
mmput_async() when atomic_inc_not_zero() failed.";Tetsuo Handa;2016-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjYmRjZjdmNzg5MDA2MjVkZTM1MTczOTYxYjliOTVjZGUyMmJjZTQ1;mm, oom_reaper: do not use siglock in try_oom_reaper();Michal Hocko;2016-06-03;1;0
MDY6Q29tbWl0MjMyNTI5ODpjYmRjZjdmNzg5MDA2MjVkZTM1MTczOTYxYjliOTVjZGUyMmJjZTQ1;"Oleg has noted that siglock usage in try_oom_reaper is both pointless
and dangerous";Michal Hocko;2016-06-03;0;1
MDY6Q29tbWl0MjMyNTI5ODpjYmRjZjdmNzg5MDA2MjVkZTM1MTczOTYxYjliOTVjZGUyMmJjZTQ1; signal_group_exit can be checked lockless;Michal Hocko;2016-06-03;0;0
MDY6Q29tbWl0MjMyNTI5ODpjYmRjZjdmNzg5MDA2MjVkZTM1MTczOTYxYjliOTVjZGUyMmJjZTQ1;" The problem
is that sighand becomes NULL in __exit_signal so we can crash";Michal Hocko;2016-06-03;0;1
MDY6Q29tbWl0MjMyNTI5ODpjYmRjZjdmNzg5MDA2MjVkZTM1MTczOTYxYjliOTVjZGUyMmJjZTQ1;"Fixes: 3ef22dfff239 (""oom, oom_reaper: try to reap tasks which skip regular OOM killer path"")";Michal Hocko;2016-06-03;0;1
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;oom_reaper: close race with exiting task;Michal Hocko;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;Tetsuo has reported;Michal Hocko;2016-05-27;0;0
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;"  Out of memory: Kill process 443 (oleg's-test) score 855 or sacrifice child
  Killed process 443 (oleg's-test) total-vm:493248kB, anon-rss:423880kB, file-rss:4kB, shmem-rss:0kB
  sh invoked oom-killer: gfp_mask=0x24201ca(GFP_HIGHUSER_MOVABLE|__GFP_COLD), order=0, oom_score_adj=0
  sh cpuset=/ mems_allowed=0
  CPU: 2 PID: 1 Comm: sh Not tainted 4.6.0-rc7+ #51
  Hardware name: VMware, Inc";Michal Hocko;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;"VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 07/31/2013
  In other words";Michal Hocko;2016-05-27;1;0
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;"  __oom_reap_task		exit_mm
    atomic_inc_not_zero
				  tsk->mm = NULL
				  mmput
				    atomic_dec_and_test # > 0
				  exit_oom_victim # New victim will be
						  # selected
				<OOM killer invoked>
				  # no TIF_MEMDIE task so we can select a new one
    unmap_page_range # to release the memory
The race exists even without the oom_reaper because anybody who pins the
address space and gets preempted might race with exit_mm but oom_reaper
made this race more probable";Michal Hocko;2016-05-27;0;1
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;"We can address the oom_reaper part by using oom_lock for __oom_reap_task
because this would guarantee that a new oom victim will not be selected
if the oom reaper might race with the exit path";Michal Hocko;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplMmZlMTQ1NjRkMzMxNmQxNjI1ZWQyMGJmMTA4Mzk5NWY0OTYwODkz;" This doesn't solve the
original issue, though, because somebody else still might be pinning
mm_users and so __mmput won't be called to release the memory but that
is not really realiably solvable because the task will get away from the
oom sight as soon as it is unhashed from the task_list and so we cannot
guarantee a new victim won't be selected.";Michal Hocko;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ5ZjcyMzBmNTkxYjc5ODg1MzNiMWNhZmIwN2YzYzAzNTU1ZjE5;mm: oom: do not reap task if there are live threads in threadgroup;Vladimir Davydov;2016-05-27;1;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ5ZjcyMzBmNTkxYjc5ODg1MzNiMWNhZmIwN2YzYzAzNTU1ZjE5;"If the current process is exiting, we don't invoke oom killer, instead
we give it access to memory reserves and try to reap its mm in case
nobody is going to use it";Vladimir Davydov;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ5ZjcyMzBmNTkxYjc5ODg1MzNiMWNhZmIwN2YzYzAzNTU1ZjE5;" There's a mistake in the code performing
this check - we just ignore any process of the same thread group no
matter if it is exiting or not - see try_oom_reaper";Vladimir Davydov;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ5ZjcyMzBmNTkxYjc5ODg1MzNiMWNhZmIwN2YzYzAzNTU1ZjE5; Fix it.;Vladimir Davydov;2016-05-27;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;mm,oom: speed up select_bad_process() loop;Tetsuo Handa;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;"Since commit 3a5dda7a17cf (""oom: prevent unnecessary oom kills or kernel
panics""), select_bad_process() is using for_each_process_thread()";Tetsuo Handa;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;"Since oom_unkillable_task() scans all threads in the caller's thread
group and oom_task_origin() scans signal_struct of the caller's thread
group, we don't need to call oom_unkillable_task() and oom_task_origin()
on each thread";Tetsuo Handa;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;" Also, since !mm test will be done later at
oom_badness(), we don't need to do !mm test on each thread";Tetsuo Handa;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;" Therefore,
we only need to do TIF_MEMDIE test on each thread";Tetsuo Handa;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;"Although the original code was correct it was quite inefficient because
each thread group was scanned num_threads times which can be a lot
especially with processes with many threads";Tetsuo Handa;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;" Even though the OOM is
extremely cold path it is always good to be as effective as possible
when we are inside rcu_read_lock() - aka unpreemptible context";Tetsuo Handa;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;"If we track number of TIF_MEMDIE threads inside signal_struct, we don't
need to do TIF_MEMDIE test on each thread";Tetsuo Handa;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;" This will allow
select_bad_process() to use for_each_process()";Tetsuo Handa;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQ2NjZiMDQ2MDVkMWM3ZmQ5NGFiOTBiN2NjZjYzM2U3ZWZmMjI4;"This patch adds a counter to signal_struct for tracking how many
TIF_MEMDIE threads are in a given thread group, and check it at
oom_scan_process_thread() so that select_bad_process() can use
for_each_process() rather than for_each_process_thread().";Tetsuo Handa;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;mm, oom_reaper: do not mmput synchronously from the oom reaper context;Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;"Tetsuo has properly noted that mmput slow path might get blocked waiting
for another party (e.g";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy; exit_aio waits for an IO);Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;" If that happens the
oom_reaper would be put out of the way and will not be able to process
next oom victim";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;" We should strive for making this context as reliable
and independent on other subsystems as much as possible";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;"Introduce mmput_async which will perform the slow path from an async
(WQ) context";Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;" This will delay the operation but that shouldn't be a
problem because the oom_reaper has reclaimed the victim's address space
for most cases as much as possible and the remaining context shouldn't
bind too much memory anymore";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;" The only exception is when mmap_sem
trylock has failed which shouldn't happen too often";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODplYzhkN2MxNGVhMTQ5MjJmZTIxOTQ1YjQ1OGE3NWUzOWYxMWRkODMy;The issue is only theoretical but not impossible.;Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;mm, oom_reaper: hide oom reaped tasks from OOM killer more carefully;Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;"Commit 36324a990cf5 (""oom: clear TIF_MEMDIE after oom_reaper managed to
unmap the address space"") not only clears TIF_MEMDIE for oom reaped task
but also set OOM_SCORE_ADJ_MIN for the target task to hide it from the
oom killer";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;" This works in simple cases but it is not sufficient for
(unlikely) cases where the mm is shared between independent processes
(as they do not share signal struct)";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;" If the mm had only small amount
of memory which could be reaped then another task sharing the mm could
be selected and that wouldn't help to move out from the oom situation";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;"Introduce MMF_OOM_REAPED mm flag which is checked in oom_badness (same
as OOM_SCORE_ADJ_MIN) and task is skipped if the flag is set";Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;" Set the
flag after __oom_reap_task is done with a task";Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYjhhNGI3ZmQxMjY2ZWY4ODhiM2E4MGFhNWYyNjYwNjJiMjI0ZWY0;" This will force the
select_bad_process() to ignore all already oom reaped tasks as well as
no such task is sacrificed for its parent.";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;mm, oom_reaper: clear TIF_MEMDIE for all tasks queued for oom_reaper;Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;"Right now the oom reaper will clear TIF_MEMDIE only for tasks which were
successfully reaped";Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" This is the safest option because we know that
such an oom victim would only block forward progress of the oom killer
without a good reason because it is highly unlikely it would release
much more memory";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" Basically most of its memory has been already torn
down";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;We can relax this assumption to catch more corner cases though;Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;"The first obvious one is when the oom victim clears its mm and gets
stuck later on";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" oom_reaper would back of on find_lock_task_mm returning
NULL";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" We can safely try to clear TIF_MEMDIE in this case because such a
task would be ignored by the oom killer anyway";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" The flag would be
cleared by that time already most of the time anyway";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;"The less obvious one is when the oom reaper fails due to mmap_sem
contention";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" Even if we clear TIF_MEMDIE for this task then it is not
very likely that we would select another task too easily because we
haven't reaped the last victim and so it would be still the #1
candidate";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;" There is a rare race condition possible when the current
victim terminates before the next select_bad_process but considering
that oom_reap_task had retried several times before giving up then this
sounds like a borderline thing";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NDlkNzc3ZDdhZDZkN2Y5YWM1ZWQ4ZjYxOGZhMTNlNmZmMzZjMzJm;"After this patch we should have a guarantee that the OOM killer will not
be block for unbounded amount of time for most cases.";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZWYyMmRmZmYyMzkwZTc1YjM3OWY5NzE1Mzg4YTg1MmFhNTZlMGQ1;oom, oom_reaper: try to reap tasks which skip regular OOM killer path;Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZWYyMmRmZmYyMzkwZTc1YjM3OWY5NzE1Mzg4YTg1MmFhNTZlMGQ1;"If either the current task is already killed or PF_EXITING or a selected
task is PF_EXITING then the oom killer is suppressed and so is the oom
reaper";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozZWYyMmRmZmYyMzkwZTc1YjM3OWY5NzE1Mzg4YTg1MmFhNTZlMGQ1;" This patch adds try_oom_reaper which checks the given task and
queues it for the oom reaper if that is safe to be done meaning that the
task doesn't share the mm with an alive process";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZWYyMmRmZmYyMzkwZTc1YjM3OWY5NzE1Mzg4YTg1MmFhNTZlMGQ1;"This might help to release the memory pressure while the task tries to
exit.";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;mm, oom: move GFP_NOFS check to out_of_memory;Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;"__alloc_pages_may_oom is the central place to decide when the
out_of_memory should be invoked";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" This is a good approach for most
checks there because they are page allocator specific and the allocation
fails right after for all of them";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;"The notable exception is GFP_NOFS context which is faking
did_some_progress and keep the page allocator looping even though there
couldn't have been any progress from the OOM killer";Michal Hocko;2016-05-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" This patch doesn't
change this behavior because we are not ready to allow those allocation
requests to fail yet (and maybe we will face the reality that we will
never manage to safely fail these request)";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" Instead __GFP_FS check is
moved down to out_of_memory and prevent from OOM victim selection there";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;"There are two reasons for that
	- OOM notifiers might release some memory even from this context
	  as none of the registered notifier seems to be FS related
	- this might help a dying thread to get an access to memory
          reserves and move on which will make the behavior more
          consistent with the case when the task gets killed from a
          different context";Michal Hocko;2016-05-20;0;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;"Keep a comment in __alloc_pages_may_oom to make sure we do not forget
how GFP_NOFS is special and that we really want to do something about
Note to the current oom_notifier users";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;"The observable difference for you is that oom notifiers cannot depend on
any fs locks because we could deadlock";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" Not that this would be allowed
today because that would just lockup machine in most of the cases and
ruling out the OOM killer along the way";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" Another difference is that
callbacks might be invoked sooner now because GFP_NOFS is a weaker
reclaim context and so there could be reclaimable memory which is just
not reachable now";Michal Hocko;2016-05-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozZGE4OGZiM2JhY2ZhYTMzZmY5ZDEzNzMwZDE3MTEwYmIyZDk2MDRk;" That would require GFP_NOFS only loads which are
really rare and more importantly the observable result would be dropping
of reconstructible object and potential performance drop which is not
such a big deal when we are struggling to fulfill other important
allocation requests.";Michal Hocko;2016-05-20;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjhlMTVjYzg1YTI1MzE1NWZkY2VhNzA3NTg4YmY2ZGRmYzBiZTJl;oom, oom_reaper: do not enqueue task if it is on the oom_reaper_list head;Michal Hocko;2016-04-01;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjhlMTVjYzg1YTI1MzE1NWZkY2VhNzA3NTg4YmY2ZGRmYzBiZTJl;"Commit bb29902a7515 (""oom, oom_reaper: protect oom_reaper_list using
simpler way"") has simplified the check for tasks already enqueued for
the oom reaper by checking tsk->oom_reaper_list != NULL";Michal Hocko;2016-04-01;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjhlMTVjYzg1YTI1MzE1NWZkY2VhNzA3NTg4YmY2ZGRmYzBiZTJl;" This check is
not sufficient because the tsk might be the head of the queue without
any other tasks queued and then we would simply lockup looping on the
same task";Michal Hocko;2016-04-01;0;1
MDY6Q29tbWl0MjMyNTI5ODphZjhlMTVjYzg1YTI1MzE1NWZkY2VhNzA3NTg4YmY2ZGRmYzBiZTJl; Fix the condition by checking for the head as well;Michal Hocko;2016-04-01;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjhlMTVjYzg1YTI1MzE1NWZkY2VhNzA3NTg4YmY2ZGRmYzBiZTJl;"Fixes: bb29902a7515 (""oom, oom_reaper: protect oom_reaper_list using simpler way"")";Michal Hocko;2016-04-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYjI5OTAyYTc1MTUyMDg4NDYxMTRiM2IzNmE0MjgxYTliYmY3NjZh;oom, oom_reaper: protect oom_reaper_list using simpler way;Tetsuo Handa;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYjI5OTAyYTc1MTUyMDg4NDYxMTRiM2IzNmE0MjgxYTliYmY3NjZh;"""oom, oom_reaper: disable oom_reaper for oom_kill_allocating_task"" tried
to protect oom_reaper_list using MMF_OOM_KILLED flag";Tetsuo Handa;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODpiYjI5OTAyYTc1MTUyMDg4NDYxMTRiM2IzNmE0MjgxYTliYmY3NjZh;" But we can do it
by simply checking tsk->oom_reaper_list != NULL.";Tetsuo Handa;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;oom: make oom_reaper freezable;Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;"After ""oom: clear TIF_MEMDIE after oom_reaper managed to unmap the
address space"" oom_reaper will call exit_oom_victim on the target task
after it is done";Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5; This might however race with the PM freezer;Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;"CPU0				CPU1				CPU2
freeze_processes
  try_to_freeze_tasks
  				# Allocation request
				out_of_memory
  oom_killer_disable
				  wake_oom_reaper(P1)
				  				__oom_reap_task
								  exit_oom_victim(P1)
    wait_event(oom_victims==0)
    				do_exit(P1)
				  perform IO/interfere with the freezer
which breaks the oom_killer_disable semantic";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;" We no longer have a
guarantee that the oom victim won't interfere with the freezer because
it might be anywhere on the way to do_exit while the freezer thinks the
task has already terminated";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;" It might trigger IO or touch devices which
are frozen already";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;In order to close this race, make the oom_reaper thread freezable;Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODplMjY3OTYwNjZmZGY5MjljYmJhMjJkYWJiODAxODA4Zjk4NmFjZGI5;" This
will work because
	a) already running oom_reaper will block freezer to enter the
	   quiescent state
	b) wake_oom_reaper will not wake up the reaper after it has been
	   frozen
	c) the only way to call exit_oom_victim after try_to_freeze_tasks
	   is from the oom victim's context when we know the further
	   interference shouldn't be possible";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOWM2OTZlMWM2ZWNlYjVkYjZiMjFmMGM4OTQ5NWZjZmNkNDBjMGVi;oom: make oom_reaper_list single linked;Vladimir Davydov;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODoyOWM2OTZlMWM2ZWNlYjVkYjZiMjFmMGM4OTQ5NWZjZmNkNDBjMGVi;"Entries are only added/removed from oom_reaper_list at head so we can
use a single linked list and hence save a word in task_struct.";Vladimir Davydov;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NTViMDE4MzI1NzM3Zjc2OTFmOWI3ZDg2MzM5ZGY0MGFhNGU0N2Mz;oom, oom_reaper: disable oom_reaper for oom_kill_allocating_task;Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NTViMDE4MzI1NzM3Zjc2OTFmOWI3ZDg2MzM5ZGY0MGFhNGU0N2Mz;"Tetsuo has reported that oom_kill_allocating_task=1 will cause
oom_reaper_list corruption because oom_kill_process doesn't follow
standard OOM exclusion (aka ignores TIF_MEMDIE) and allows to enqueue
the same task multiple times - e.g";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NTViMDE4MzI1NzM3Zjc2OTFmOWI3ZDg2MzM5ZGY0MGFhNGU0N2Mz;" by sacrificing the same child
multiple times";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NTViMDE4MzI1NzM3Zjc2OTFmOWI3ZDg2MzM5ZGY0MGFhNGU0N2Mz;"This patch fixes the issue by introducing a new MMF_OOM_KILLED mm flag
which is set in oom_kill_process atomically and oom reaper is disabled
if the flag was already set.";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;mm, oom_reaper: implement OOM victims queuing;Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;wake_oom_reaper has allowed only 1 oom victim to be queued;Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" The main
reason for that was the simplicity as other solutions would require some
way of queuing";Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" The current approach is racy and that was deemed
sufficient as the oom_reaper is considered a best effort approach to
help with oom handling when the OOM victim cannot terminate in a
reasonable time";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" The race could lead to missing an oom victim which can
get stuck
out_of_memory
  wake_oom_reaper
    cmpxchg // OK
    			oom_reaper
			  oom_reap_task
			    __oom_reap_task
oom_victim terminates
			      atomic_inc_not_zero // fail
out_of_memory
  wake_oom_reaper
    cmpxchg // fails
			  task_to_reap = NULL
This race requires 2 OOM invocations in a short time period which is not
very likely but certainly not impossible";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk; E.g;Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" the original victim
might have not released a lot of memory for some reason";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;"The situation would improve considerably if wake_oom_reaper used a more
robust queuing";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk; This is what this patch implements;Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" This means adding
oom_reaper_list list_head into task_struct (eat a hole before embeded
thread_struct for that purpose) and a oom_reaper_lock spinlock for
queuing synchronization";Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODowMzA0OTI2OWRlNDMzY2I1ZmUyODU5YmU5YWU0NDY5Y2ViMTE2M2Vk;" wake_oom_reaper will then add the task on the
queue and oom_reaper will dequeue it.";Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYzQ0OGU4OTdiNmQyNGFhZTMyNzAxNzYzYjhhMWZlMTVkMjlmYTI2;mm, oom_reaper: report success/failure;Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYzQ0OGU4OTdiNmQyNGFhZTMyNzAxNzYzYjhhMWZlMTVkMjlmYTI2;"Inform about the successful/failed oom_reaper attempts and dump all the
held locks to tell us more who is blocking the progress.";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;oom: clear TIF_MEMDIE after oom_reaper managed to unmap the address space;Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;"When oom_reaper manages to unmap all the eligible vmas there shouldn't
be much of the freable memory held by the oom victim left anymore so it
makes sense to clear the TIF_MEMDIE flag for the victim and allow the
OOM killer to select another task";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;"The lack of TIF_MEMDIE also means that the victim cannot access memory
reserves anymore but that shouldn't be a problem because it would get
the access again if it needs to allocate and hits the OOM killer again
due to the fatal_signal_pending resp";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0; PF_EXITING check;Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;" We can safely
hide the task from the OOM killer because it is clearly not a good
candidate anymore as everyhing reclaimable has been torn down already";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;"This patch will allow to cap the time an OOM victim can keep TIF_MEMDIE
and thus hold off further global OOM killer actions granted the oom
reaper is able to take mmap_sem for the associated mm struct";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;" This is
not guaranteed now but further steps should make sure that mmap_sem for
write should be blocked killable which will help to reduce such a lock
contention";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0; This is not done by this patch;Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODozNjMyNGE5OTBjZjU3OGI1NzgyOGMwNGNkODVhYzYyY2QyNWNmNWE0;"Note that exit_oom_victim might be called on a remote task from
__oom_reap_task now so we have to check and clear the flag atomically
otherwise we might race and underflow oom_victims or wake up waiters too
early.";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;mm, oom: introduce oom reaper;Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;This patch (of 5);Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"This is based on the idea from Mel Gorman discussed during LSFMM 2015
and independently brought up by Oleg Nesterov";Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"The OOM killer currently allows to kill only a single task in a good
hope that the task will terminate in a reasonable time and frees up its
memory";Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" Such a task (oom victim) will get an access to memory reserves
via mark_oom_victim to allow a forward progress should there be a need
for additional memory during exit path";Michal Hocko;2016-03-25;0;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;It has been shown (e.g;Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" by Tetsuo Handa) that it is not that hard to
construct workloads which break the core assumption mentioned above and
the OOM victim might take unbounded amount of time to exit because it
might be blocked in the uninterruptible state waiting for an event (e.g";Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;lock) which is blocked by another task looping in the page allocator;Michal Hocko;2016-03-25;0;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"This patch reduces the probability of such a lockup by introducing a
specialized kernel thread (oom_reaper) which tries to reclaim additional
memory by preemptively reaping the anonymous or swapped out memory owned
by the oom victim under an assumption that such a memory won't be needed
when its owner is killed and kicked from the userspace anyway";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" There is
one notable exception to this, though, if the OOM victim was in the
process of coredumping the result would be incomplete";Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" This is
considered a reasonable constrain because the overall system health is
more important than debugability of a particular application";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"A kernel thread has been chosen because we need a reliable way of
invocation so workqueue context is not appropriate because all the
workers might be busy (e.g";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1; allocating memory);Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" Kswapd which sounds
like another good fit is not appropriate as well because it might get
blocked on locks during reclaim as well";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"oom_reaper has to take mmap_sem on the target task for reading so the
solution is not 100% because the semaphore might be held or blocked for
write but the probability is reduced considerably wrt";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" basically any
lock blocking forward progress as described above";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" In order to prevent
from blocking on the lock without any forward progress we are using only
a trylock and retry 10 times with a short sleep in between";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" Users of
mmap_sem which need it for write should be carefully reviewed to use
_killable waiting as much as possible and reduce allocations requests
done with the lock held to absolute minimum to reduce the risk even
further";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;The API between oom killer and oom reaper is quite trivial;Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;"wake_oom_reaper updates mm_to_reap with cmpxchg to guarantee only
NULL->mm transition and oom_reaper clear this atomically once it is done
with the work";Michal Hocko;2016-03-25;1;0
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" This means that only a single mm_struct can be reaped at
the time";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" As the operation is potentially disruptive we are trying to
limit it to the ncessary minimum and the reaper blocks any updates while
it operates on an mm";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODphYWM0NTM2MzU1NDk2OTljMTNhODRlYTE0NTZkNWIwZTU3NGVmODU1;" mm_struct is pinned by mm_count to allow parallel
exit_mmap and a race is detected by atomic_inc_not_zero(mm_users).";Michal Hocko;2016-03-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YWZjZjI4OTVlNmYyMjk0NzZiZDBkYzk1ZmU5MTVlNjM5YWUwYTQ5;mm,oom: make oom_killer_disable() killable;Tetsuo Handa;2016-03-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo2YWZjZjI4OTVlNmYyMjk0NzZiZDBkYzk1ZmU5MTVlNjM5YWUwYTQ5;"While oom_killer_disable() is called by freeze_processes() after all
user threads except the current thread are frozen, it is possible that
kernel threads invoke the OOM killer and sends SIGKILL to the current
thread due to sharing the thawed victim's memory";Tetsuo Handa;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YWZjZjI4OTVlNmYyMjk0NzZiZDBkYzk1ZmU5MTVlNjM5YWUwYTQ5;" Therefore, checking
for SIGKILL is preferable than TIF_MEMDIE.";Tetsuo Handa;2016-03-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NTZhMDI1ZjAwMDkxOTE4ZDlkMDljYTMyMjlkZWZiMTYwYjQwOWMw;mm: coalesce split strings;Joe Perches;2016-03-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo3NTZhMDI1ZjAwMDkxOTE4ZDlkMDljYTMyMjlkZWZiMTYwYjQwOWMw;"Kernel style prefers a single string over split strings when the string is
'user-visible'";Joe Perches;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NTZhMDI1ZjAwMDkxOTE4ZDlkMDljYTMyMjlkZWZiMTYwYjQwOWMw;Miscellanea;Joe Perches;2016-03-17;0;0
MDY6Q29tbWl0MjMyNTI5ODo3NTZhMDI1ZjAwMDkxOTE4ZDlkMDljYTMyMjlkZWZiMTYwYjQwOWMw;" - Add a missing newline
 - Realign arguments";Joe Perches;2016-03-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;mm: oom_kill: don't ignore oom score on exiting tasks;Johannes Weiner;2016-03-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;"When the OOM killer scans tasks and encounters a PF_EXITING one, it
force-selects that task regardless of the score";Johannes Weiner;2016-03-17;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;" The problem is that if
that task got stuck waiting for some state the allocation site is
holding, the OOM reaper can not move on to the next best victim";Johannes Weiner;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;"Frankly, I don't even know why we check for exiting tasks in the OOM
killer";Johannes Weiner;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;" We've tried direct reclaim at least 15 times by the time we
decide the system is OOM, there was plenty of time to exit and free
memory; and a task might exit voluntarily right after we issue a kill";Johannes Weiner;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2;This is testing pure noise;Johannes Weiner;2016-03-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YTYxODk1N2FkMTdkOGY0ZjRjN2VlZWRlNzUyNjg1Mzc0YjFiMTc2; Remove it.;Johannes Weiner;2016-03-17;1;0
MDY6Q29tbWl0MjMyNTI5ODphMDc5NWNkNDE2ZDExNDIxMTc2OTVmOTMyYTk2OTA2MTFhZTBlZGJi;mm, oom: print symbolic gfp_flags in oom warning;Vlastimil Babka;2016-03-15;1;0
MDY6Q29tbWl0MjMyNTI5ODphMDc5NWNkNDE2ZDExNDIxMTc2OTVmOTMyYTk2OTA2MTFhZTBlZGJi;"It would be useful to translate gfp_flags into string representation
when printing in case of an OOM, especially as the flags have been
undergoing some changes recently and the script ./scripts/gfp-translate
needs a matching source version to be accurate";Vlastimil Babka;2016-03-15;0;1
MDY6Q29tbWl0MjMyNTI5ODphMDc5NWNkNDE2ZDExNDIxMTc2OTVmOTMyYTk2OTA2MTFhZTBlZGJi;Example output;Vlastimil Babka;2016-03-15;0;1
MDY6Q29tbWl0MjMyNTI5ODphMDc5NWNkNDE2ZDExNDIxMTc2OTVmOTMyYTk2OTA2MTFhZTBlZGJi;  a.out invoked oom-killer: gfp_mask=0x24280ca(GFP_HIGHUSER_MOVABLE|GFP_ZERO), order=0, om_score_adj=0;Vlastimil Babka;2016-03-15;1;0
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;mm, shmem: add internal shmem resident memory accounting;Jerome Marchand;2016-01-14;1;0
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;"Currently looking at /proc/<pid>/status or statm, there is no way to
distinguish shmem pages from pages mapped to a regular file (shmem pages
are mapped to /dev/zero), even though their implication in actual memory
use is quite different";Jerome Marchand;2016-01-14;0;1
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;"The internal accounting currently counts shmem pages together with
regular files";Jerome Marchand;2016-01-14;0;0
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;" As a preparation to extend the userspace interfaces,
this patch adds MM_SHMEMPAGES counter to mm_rss_stat to account for
shmem pages separately from MM_FILEPAGES";Jerome Marchand;2016-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;" The next patch will expose it
to userspace - this patch doesn't change the exported values yet, by
adding up MM_SHMEMPAGES to MM_FILEPAGES at places where MM_FILEPAGES was
used before";Jerome Marchand;2016-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODplY2E1NmZmOTA2YmRkMDIzOTQ4NWU4YjQ3MTU0YTZlNzNkZDlhMmYz;" The only user-visible change after this patch is the OOM
killer message that separates the reported ""shmem-rss"" from ""file-rss"".";Jerome Marchand;2016-01-14;1;0
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;mm/oom_kill.c: avoid attempting to kill init sharing same memory;Chen Jie;2015-12-11;1;1
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;"It's possible that an oom killed victim shares an ->mm with the init
process and thus oom_kill_process() would end up trying to kill init as
well";Chen Jie;2015-12-11;0;1
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;This has been shown in practice;Chen Jie;2015-12-11;0;1
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;"	Out of memory: Kill process 9134 (init) score 3 or sacrifice child
	Killed process 9134 (init) total-vm:1868kB, anon-rss:84kB, file-rss:572kB
	Kill process 1 (init) sharing same memory
	Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000009
And this will result in a kernel panic";Chen Jie;2015-12-11;0;1
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;"If a process is forked by init and selected for oom kill while still
sharing init_mm, then it's likely this system is in a recoverable state";Chen Jie;2015-12-11;0;0
MDY6Q29tbWl0MjMyNTI5ODphMmI4MjlkOTU5NThkYTIwMjVlZjg0NGMwZjUzYWMxNWFkNzIwZmFj;"However, it's better not to try to kill init and allow the machine to
panic due to unkillable processes.";Chen Jie;2015-12-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYjJhMGRkN2E0M2RlNTk1ZDNmMDU0Mjk4NmJiMTdjY2I2Y2MzNjRj;mm/oom_kill.c: introduce is_sysrq_oom helper;Yaowei Bai;2015-11-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYjJhMGRkN2E0M2RlNTk1ZDNmMDU0Mjk4NmJiMTdjY2I2Y2MzNjRj;"Introduce is_sysrq_oom helper function indicating oom kill triggered
by sysrq to improve readability";Yaowei Bai;2015-11-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYjJhMGRkN2E0M2RlNTk1ZDNmMDU0Mjk4NmJiMTdjY2I2Y2MzNjRj;No functional changes.;Yaowei Bai;2015-11-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz;mm/oom_kill: fix the wrong task->mm == mm checks in oom_kill_process();Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz;"Both ""child->mm == mm"" and ""p->mm != mm"" checks in oom_kill_process() are
wrong";Oleg Nesterov;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz; task->mm can be NULL if the task is the exited group leader;Oleg Nesterov;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz;" This
means in particular that ""kill sharing same memory"" loop can miss a
process with a zombie leader which uses the same ->mm";Oleg Nesterov;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz;"Note: the process_has_mm(child, p->mm) check is still not 100% correct,
p->mm can be NULL too";Oleg Nesterov;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDdiMzM5NGY3NmVkNzJjZmRlYzIzY2E1NTcxZGJhYjZlYzQxNzkz;" This is minor, but probably deserves a fix or a
comment anyway.";Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzE5MDI1YTZjNzllNTMyZDg2MmUzYTBiOTUwNmJhMzE2YTRkMTNh;"mm/oom_kill: cleanup the ""kill sharing same memory"" loop";Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzE5MDI1YTZjNzllNTMyZDg2MmUzYTBiOTUwNmJhMzE2YTRkMTNh;"Purely cosmetic, but the complex ""if"" condition looks annoying to me";Oleg Nesterov;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpjMzE5MDI1YTZjNzllNTMyZDg2MmUzYTBiOTUwNmJhMzE2YTRkMTNh;"Especially because it is not consistent with OOM_SCORE_ADJ_MIN check
which adds another if/continue.";Oleg Nesterov;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;mm/oom_kill: remove the wrong fatal_signal_pending() check in oom_kill_process();Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;"The fatal_signal_pending() was added to suppress unnecessary ""sharing same
memory"" message, but it can't 100% help anyway because it can be
false-negative; SIGKILL can be already dequeued";Oleg Nesterov;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;And worse, it can be false-positive due to exec or coredump;Oleg Nesterov;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;" exec is
mostly fine, but coredump is not";Oleg Nesterov;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;" It is possible that the group leader
has the pending SIGKILL because its sub-thread originated the coredump, in
this case we must not skip this process";Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODowYzFiMmQ3ODNjZjM0MzI0OTBiZjFlNTMyYzc0MmZmZmVhZGMwYmYz;"We could probably add the additional ->group_exit_task check but this
patch just removes the wrong check along with pr_info().";Oleg Nesterov;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;mm, oom: remove task_lock protecting comm printing;David Rientjes;2015-11-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;"The oom killer takes task_lock() in a couple of places solely to protect
printing the task's comm";David Rientjes;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;"A process's comm, including current's comm, may change due to
/proc/pid/comm or PR_SET_NAME";David Rientjes;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;"The comm will always be NULL-terminated, so the worst race scenario would
only be during update";David Rientjes;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;" We can tolerate a comm being printed that is in
the middle of an update to avoid taking the lock";David Rientjes;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYTM5ZGEzYTU0ZmVkODhlMjkwMjRmMmYxZjZjZDczNTdjZDAzYTQ0;"Other locations in the kernel have already dropped task_lock() when
printing comm, so this is consistent.";David Rientjes;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDA4MDdhOGY0MGJiMjVhOGRmNWI2NDEyYmJhNmJjMTU2NjQzYmU1;"mm/oom_kill.c: suppress unnecessary ""sharing same memory"" message";Tetsuo Handa;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDA4MDdhOGY0MGJiMjVhOGRmNWI2NDEyYmJhNmJjMTU2NjQzYmU1;"oom_kill_process() sends SIGKILL to other thread groups sharing victim's
mm";Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo4NDA4MDdhOGY0MGJiMjVhOGRmNWI2NDEyYmJhNmJjMTU2NjQzYmU1;" But printing
  ""Kill process %d (%s) sharing same memory\n""
lines makes no sense if they already have pending SIGKILL";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDA4MDdhOGY0MGJiMjVhOGRmNWI2NDEyYmJhNmJjMTU2NjQzYmU1;" This patch
reduces the ""Kill process"" lines by printing that line with info level
only if SIGKILL is not pending.";Tetsuo Handa;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;mm/oom_kill.c: fix potentially killing unrelated process;Tetsuo Handa;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;"At the for_each_process() loop in oom_kill_process(), we are comparing
address of OOM victim's mm without holding a reference to that mm";Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;" If
there are a lot of processes to compare or a lot of ""Kill process %d (%s)
sharing same memory"" messages to print, for_each_process() loop could take
very long time";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;"It is possible that meanwhile the OOM victim exits and releases its mm,
and then mm is allocated with the same address and assigned to some
unrelated process";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;" When we hit such race, the unrelated process will be
killed by error";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ODBiNzY4OTM3ZTkwYzQzM2MwYzgyNTRhMjJiMWViNjNkZjAwNWE0;" To make sure that the OOM victim's mm does not go away
until for_each_process() loop finishes, get a reference on the OOM
victim's mm before calling task_unlock(victim).";Tetsuo Handa;2015-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;mm/oom_kill.c: reverse the order of setting TIF_MEMDIE and sending SIGKILL;Tetsuo Handa;2015-11-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"It was confirmed that a local unprivileged user can consume all memory
reserves and hang up that system using time lag between the OOM killer
sets TIF_MEMDIE on an OOM victim and sends SIGKILL to that victim, for
printk() inside for_each_process() loop at oom_kill_process() can consume
many seconds when there are many thread groups sharing the same memory";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;Before starting oom-depleter process;Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"    Node 0 DMA: 3*4kB (UM) 6*8kB (U) 4*16kB (UEM) 0*32kB 0*64kB 1*128kB (M) 2*256kB (EM) 2*512kB (UE) 2*1024kB (EM) 1*2048kB (E) 1*4096kB (M) = 9980kB
    Node 0 DMA32: 31*4kB (UEM) 27*8kB (UE) 32*16kB (UE) 13*32kB (UE) 14*64kB (UM) 7*128kB (UM) 8*256kB (UM) 8*512kB (UM) 3*1024kB (U) 4*2048kB (UM) 362*4096kB (UM) = 1503220kB
As of invoking the OOM killer";Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"    Node 0 DMA: 11*4kB (UE) 8*8kB (UEM) 6*16kB (UE) 2*32kB (EM) 0*64kB 1*128kB (U) 3*256kB (UEM) 2*512kB (UE) 3*1024kB (UEM) 1*2048kB (U) 0*4096kB = 7308kB
    Node 0 DMA32: 1049*4kB (UEM) 507*8kB (UE) 151*16kB (UE) 53*32kB (UEM) 83*64kB (UEM) 52*128kB (EM) 25*256kB (UEM) 11*512kB (M) 6*1024kB (UM) 1*2048kB (M) 0*4096kB = 44556kB
Between the thread group leader got TIF_MEMDIE and receives SIGKILL";Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"    Node 0 DMA: 0*4kB 0*8kB 0*16kB 0*32kB 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 0kB
    Node 0 DMA32: 0*4kB 0*8kB 0*16kB 0*32kB 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 0kB
The oom-depleter's thread group leader which got TIF_MEMDIE started
memset() in user space after the OOM killer set TIF_MEMDIE, and it was
free to abuse ALLOC_NO_WATERMARKS by TIF_MEMDIE for memset() in user space
until SIGKILL is delivered";Tetsuo Handa;2015-11-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;" If SIGKILL is delivered before TIF_MEMDIE is
set, the oom-depleter can terminate without touching memory reserves";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"Although the possibility of hitting this time lag is very small for 3.19
and earlier kernels because TIF_MEMDIE is set immediately before sending
SIGKILL, preemption or long interrupts (an extreme example is SysRq-t) can
step between and allow memory allocations which are not needed for
terminating the OOM victim";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjZmYjVlNzJkOTJiODY4OTEyZTQ3YTFlM2NhMmRmNmVhYmMzODcy;"Fixes: 83363b917a29 (""oom: make sure that TIF_MEMDIE is set under task_lock"")";Tetsuo Handa;2015-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NWU4ZjhiMjRjYjBkYzQ5NTEyNjdkMzFmMGE0OWU1Y2UyZjM0NWM0;mm, oom: remove unnecessary variable;David Rientjes;2015-09-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NWU4ZjhiMjRjYjBkYzQ5NTEyNjdkMzFmMGE0OWU1Y2UyZjM0NWM0;"The ""killed"" variable in out_of_memory() can be removed since the call to
oom_kill_process() where we should block to allow the process time to
exit is obvious.";David Rientjes;2015-09-08;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzFhNGJlZmViYjY1NWQ2YjMxYmY1YzZiYWNkNWE2ZGYwMzUyMjRk;mm, oom: do not panic for oom kills triggered from sysrq;David Rientjes;2015-09-08;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzFhNGJlZmViYjY1NWQ2YjMxYmY1YzZiYWNkNWE2ZGYwMzUyMjRk;"Sysrq+f is used to kill a process either for debug or when the VM is
otherwise unresponsive";David Rientjes;2015-09-08;0;0
MDY6Q29tbWl0MjMyNTI5ODowNzFhNGJlZmViYjY1NWQ2YjMxYmY1YzZiYWNkNWE2ZGYwMzUyMjRk;It is not intended to trigger a panic when no process may be killed;David Rientjes;2015-09-08;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzFhNGJlZmViYjY1NWQ2YjMxYmY1YzZiYWNkNWE2ZGYwMzUyMjRk;Avoid panicking the system for sysrq+f when no processes are killed.;David Rientjes;2015-09-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NGU5ZTI5MTMyZDdjYWVmY2FkNDcwMjgxY2FlMDZhYzM0YTk4MmM4;mm, oom: pass an oom order of -1 when triggered by sysrq;David Rientjes;2015-09-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NGU5ZTI5MTMyZDdjYWVmY2FkNDcwMjgxY2FlMDZhYzM0YTk4MmM4;"The force_kill member of struct oom_control isn't needed if an order of -1
is used instead";David Rientjes;2015-09-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo1NGU5ZTI5MTMyZDdjYWVmY2FkNDcwMjgxY2FlMDZhYzM0YTk4MmM4;" This is the same as order == -1 in struct
compact_control which requires full memory compaction";David Rientjes;2015-09-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo1NGU5ZTI5MTMyZDdjYWVmY2FkNDcwMjgxY2FlMDZhYzM0YTk4MmM4;This patch introduces no functional change.;David Rientjes;2015-09-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZTBmYzQ2ZGMyMTUyZDNlMmQyNWE1ZDViNjQwYWUzNTg2YzI0N2M2;mm, oom: organize oom context into struct;David Rientjes;2015-09-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTBmYzQ2ZGMyMTUyZDNlMmQyNWE1ZDViNjQwYWUzNTg2YzI0N2M2;"There are essential elements to an oom context that are passed around to
multiple functions";David Rientjes;2015-09-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTBmYzQ2ZGMyMTUyZDNlMmQyNWE1ZDViNjQwYWUzNTg2YzI0N2M2;"Organize these elements into a new struct, struct oom_control, that
specifies the context for an oom condition";David Rientjes;2015-09-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZTBmYzQ2ZGMyMTUyZDNlMmQyNWE1ZDViNjQwYWUzNTg2YzI0N2M2;This patch introduces no functional change.;David Rientjes;2015-09-08;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMGQ2NjQ3ZTg1MDUwYzZjYTcwZDY5YTY0N2UzYzY1M2RkOWIzNDlh;mm/oom_kill.c: print points as unsigned int;Wang Long;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMGQ2NjQ3ZTg1MDUwYzZjYTcwZDY5YTY0N2UzYzY1M2RkOWIzNDlh;In oom_kill_process(), the variable 'points' is unsigned int;Wang Long;2015-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMGQ2NjQ3ZTg1MDUwYzZjYTcwZDY5YTY0N2UzYzY1M2RkOWIzNDlh;" Print it as
such.";Wang Long;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;mm: oom_kill: simplify OOM killer locking;Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;"The zonelist locking and the oom_sem are two overlapping locks that are
used to serialize global OOM killing against different things";Johannes Weiner;2015-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;"The historical zonelist locking serializes OOM kills from allocations with
overlapping zonelists against each other to prevent killing more tasks
than necessary in the same memory domain";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;" Only when neither tasklists nor
zonelists from two concurrent OOM kills overlap (tasks in separate memcgs
bound to separate nodes) are OOM kills allowed to execute in parallel";Johannes Weiner;2015-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;"The younger oom_sem is a read-write lock to serialize OOM killing against
the PM code trying to disable the OOM killer altogether";Johannes Weiner;2015-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;"However, the OOM killer is a fairly cold error path, there is really no
reason to optimize for highly performant and concurrent OOM kills";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;" And
the oom_sem is just flat-out redundant";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYzU2NDAxZmM5ZjI1ZThmOTM4OTk5OTFlYzg1OGM5OGEzMzFkODhj;"Replace both locking schemes with a single global mutex serializing OOM
kills regardless of context.";Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYTUxYjE0YWRiNjcxODI5MDc3ZGEzYWViOWU5ZWRkNmY4YzgwYWZl;mm: oom_kill: remove unnecessary locking in exit_oom_victim();Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYTUxYjE0YWRiNjcxODI5MDc3ZGEzYWViOWU5ZWRkNmY4YzgwYWZl;"Disabling the OOM killer needs to exclude allocators from entering, not
existing victims from exiting";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYTUxYjE0YWRiNjcxODI5MDc3ZGEzYWViOWU5ZWRkNmY4YzgwYWZl;"Right now the only waiter is suspend code, which achieves quiescence by
disabling the OOM killer";Johannes Weiner;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYTUxYjE0YWRiNjcxODI5MDc3ZGEzYWViOWU5ZWRkNmY4YzgwYWZl;" But later on we want to add waits that hold
the lock instead to stop new victims from showing up.";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;mm: oom_kill: generalize OOM progress waitqueue;Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;"It turns out that the mechanism to wait for exiting OOM victims is less
generic than it looks: it won't issue wakeups unless the OOM killer is
disabled";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;"The reason this check was added was the thought that, since only the OOM
disabling code would wait on this queue, wakeup operations could be
saved when that specific consumer is known to be absent";Johannes Weiner;2015-06-24;0;0
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;However, this is quite the handgrenade;Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;" Later attempts to reuse the
waitqueue for other purposes will lead to completely unexpected bugs and
the failure mode will appear seemingly illogical";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;" Generally, providers
shouldn't make unnecessary assumptions about consumers";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;"This could have been replaced with waitqueue_active(), but it only saves
a few instructions in one of the coldest paths in the kernel";Johannes Weiner;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzhmMTAyNWYyOTEwZDYxODNlOTkyM2Q0YjRkNTgwNDQ3NGI1MGM1;" Simply
remove it.";Johannes Weiner;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NjQwMjc3ODVmZjYzMzQ2OGVjYmI2ODNlZGUxNDY3MmQ1MTRiM2Qz;mm: oom_kill: switch test-and-clear of known TIF_MEMDIE to clear;Johannes Weiner;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NjQwMjc3ODVmZjYzMzQ2OGVjYmI2ODNlZGUxNDY3MmQ1MTRiM2Qz;"exit_oom_victim() already knows that TIF_MEMDIE is set, and nobody else
can clear it concurrently";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NjQwMjc3ODVmZjYzMzQ2OGVjYmI2ODNlZGUxNDY3MmQ1MTRiM2Qz; Use clear_thread_flag() directly.;Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNmU5NTE5NjZmMDVkYTVjY2Q2NTAxMDQxNzZmNmJhMjg5ZjdmYTIw;mm: oom_kill: clean up victim marking and exiting interfaces;Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNmU5NTE5NjZmMDVkYTVjY2Q2NTAxMDQxNzZmNmJhMjg5ZjdmYTIw;Rename unmark_oom_victim() to exit_oom_victim();Johannes Weiner;2015-06-24;1;0
MDY6Q29tbWl0MjMyNTI5ODoxNmU5NTE5NjZmMDVkYTVjY2Q2NTAxMDQxNzZmNmJhMjg5ZjdmYTIw;" Marking and unmarking
are related in functionality, but the interface is not symmetrical at
all: one is an internal OOM killer function used during the killing, the
other is for an OOM victim to signal its own death on exit later on";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODoxNmU5NTE5NjZmMDVkYTVjY2Q2NTAxMDQxNzZmNmJhMjg5ZjdmYTIw;This has locking implications, see follow-up changes;Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNmU5NTE5NjZmMDVkYTVjY2Q2NTAxMDQxNzZmNmJhMjg5ZjdmYTIw;"While at it, rename mark_tsk_oom_victim() to mark_oom_victim(), which
is easier on the eye.";Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjVhYjhjZmJmMTVlOGUwMjgzOGZmYzM1NDkxOTEzNTEzMDVkZjBl;mm: oom_kill: remove unnecessary locking in oom_enable();Johannes Weiner;2015-06-24;1;1
MDY6Q29tbWl0MjMyNTI5ODozZjVhYjhjZmJmMTVlOGUwMjgzOGZmYzM1NDkxOTEzNTEzMDVkZjBl;"Setting oom_killer_disabled to false is atomic, there is no need for
further synchronization with ongoing allocations trying to OOM-kill.";Johannes Weiner;2015-06-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpiZGRkYmNkNDVmZDE5MWEwMjEzZTZkMmEwMzJlYjU1ZDE4YmQxZmMw;mm/oom_kill.c: fix typo in comment;Yaowei Bai;2015-04-15;1;1
MDY6Q29tbWl0MjMyNTI5ODpiZGRkYmNkNDVmZDE5MWEwMjEzZTZkMmEwMzJlYjU1ZDE4YmQxZmMw;Alter 'taks' -> 'task';Yaowei Bai;2015-04-15;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNDE1YjlmNWNiMDQ4YTgwM2IzMGI3OTBhZjk5NGJhNzFmZjBiZDRj;memcg: print cgroup information when system panics due to panic_on_oom;Balasubramani Vivekanandan;2015-04-14;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNDE1YjlmNWNiMDQ4YTgwM2IzMGI3OTBhZjk5NGJhNzFmZjBiZDRj;"If kernel panics due to oom, caused by a cgroup reaching its limit, when
'compulsory panic_on_oom' is enabled, then we will only see that the OOM
happened because of ""compulsory panic_on_oom is enabled"" but this doesn't
tell the difference between mempolicy and memcg";Balasubramani Vivekanandan;2015-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNDE1YjlmNWNiMDQ4YTgwM2IzMGI3OTBhZjk5NGJhNzFmZjBiZDRj;" And dumping system wide
information is plain wrong and more confusing";Balasubramani Vivekanandan;2015-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNDE1YjlmNWNiMDQ4YTgwM2IzMGI3OTBhZjk5NGJhNzFmZjBiZDRj;" This patch provides the
information of the cgroup whose limit triggerred panic";Balasubramani Vivekanandan;2015-04-14;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;mm: account pmd page tables to the process;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"Dave noticed that unprivileged process can allocate significant amount of
memory -- >500 MiB on x86_64 -- and stay unnoticed by oom-killer and
memory cgroup";Kirill A. Shutemov;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; The trick is to allocate a lot of PMD page tables;Kirill A. Shutemov;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;" Linux
kernel doesn't account PMD tables to the process, only PTE";Kirill A. Shutemov;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"The use-cases below use few tricks to allocate a lot of PMD page tables
while keeping VmRSS and VmPTE low";Kirill A. Shutemov;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; oom_score for the process will be 0;Kirill A. Shutemov;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"	int main(void)
			addr = mmap(addr + PUD_SIZE, PUD_SIZE, PROT_WRITE|PROT_READ,
			mmap(addr, PMD_SIZE, PROT_WRITE|PROT_READ,
		printf(""PID %d consumed %lu KiB in PMD page tables\n"",
The patch addresses the issue by account PMD tables to the process the
same way we account PTE";Kirill A. Shutemov;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"The main place where PMD tables is accounted is __pmd_alloc() and
free_pmd_range()";Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;But there're few corner cases;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; - HugeTLB can share PMD page tables;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"The patch handles by accounting
   the table to all processes who share it";Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; - x86 PAE pre-allocates few PMD tables on fork;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; - Architectures with FIRST_USER_ADDRESS > 0;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"We need to adjust sanity
   check on exit(2)";Kirill A. Shutemov;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;"Accounting only happens on configuration where PMD page table's level is
present (PMD is not folded)";Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5; As with nr_ptes we use per-mm counter;Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzZjOWEzNWI2NmI1MjBjZjY3ZTA1ZDhjYTYwZWJlY2FkM2IwNDc5;" The
counter value is used to calculate baseline for badness score by
oom-killer.";Kirill A. Shutemov;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;oom, PM: make OOM detection in the freezer path raceless;Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"Commit 5695be142e20 (""OOM, PM: OOM killed task shouldn't escape PM
suspend"") has left a race window when OOM killer manages to
note_oom_kill after freeze_processes checks the counter";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" The race
window is quite small and really unlikely and partial solution deemed
sufficient at the time of submission";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"Tejun wasn't happy about this partial solution though and insisted on a
full solution";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" That requires the full OOM and freezer's task freezing
exclusion, though";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" This is done by this patch which introduces oom_sem
RW lock and turns oom_killer_disable() into a full OOM barrier";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"oom_killer_disabled check is moved from the allocation path to the OOM
level and we take oom_sem for reading for both the check and the whole
OOM invocation";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"oom_killer_disable() takes oom_sem for writing so it waits for all
currently running OOM killer invocations";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" Then it disable all the further
OOMs by setting oom_killer_disabled and checks for any oom victims";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;Victims are counted via mark_tsk_oom_victim resp;Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3; unmark_oom_victim;Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" The
last victim wakes up all waiters enqueued by oom_killer_disable()";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;Therefore this function acts as the full OOM barrier;Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"The page fault path is covered now as well although it was assumed to be
safe before";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" As per Tejun, ""We used to have freezing points deep in file
system code which may be reacheable from page fault."" so it would be
better and more robust to not rely on freezing points here";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" Same applies
to the memcg OOM killer";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"out_of_memory tells the caller whether the OOM was allowed to trigger and
the callers are supposed to handle the situation";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" The page allocation
path simply fails the allocation same as before";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;" The page fault path will
retry the fault (more on that later) and Sysrq OOM trigger will simply
complain to the log";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"Normally there wouldn't be any unfrozen user tasks after
try_to_freeze_tasks so the function will not block";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"But if there was an
OOM killer racing with try_to_freeze_tasks and the OOM victim didn't
finish yet then we have to wait for it";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzJiM2NiZTBkMDY3YTljZmFlODVhYTcwYmExZTk3Y2ViYTBjZWQ3;"This should complete in a finite
time, though, because
	- the victim cannot loop in the page fault handler (it would die
	  on the way out from the exception)
	- it cannot loop in the page allocator because all the further
	  allocation would fail and __GFP_NOFAIL allocations are not
	  acceptable at this stage
	- it shouldn't be blocked on any locks held by frozen tasks
	  (try_to_freeze expects lockless context) and kernel threads and
	  work queues are not frozen yet";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;oom: thaw the OOM victim if it is frozen;Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;"oom_kill_process only sets TIF_MEMDIE flag and sends a signal to the
victim";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;" This is basically noop when the task is frozen though because the
task sleeps in the uninterruptible sleep";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;" The victim is eventually thawed
later when oom_scan_process_thread meets the task again in a later OOM
invocation so the OOM killer doesn't live lock";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;" But this is less than
optimal";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;"Let's add __thaw_task into mark_tsk_oom_victim after we set TIF_MEMDIE to
the victim";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;" We are not checking whether the task is frozen because that
would be racy and __thaw_task does that already";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo2M2E4Y2E5YjIwODRmYTViZDkxYWEzODA1MzJmMThlMzYxNzY0MTA5;" oom_scan_process_thread
doesn't need to care about freezer anymore as TIF_MEMDIE and freezer are
excluded completely now.";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;oom: add helpers for setting and clearing TIF_MEMDIE;Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"This patchset addresses a race which was described in the changelog for
5695be142e20 (""OOM, PM: OOM killed task shouldn't escape PM suspend"")";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;": PM freezer relies on having all tasks frozen by the time devices are
: getting frozen so that no task will touch them while they are getting
: frozen";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" But OOM killer is allowed to kill an already frozen task in order
: to handle OOM situtation";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" In order to protect from late wake ups OOM
: killer is disabled after all tasks are frozen";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" This, however, still keeps
: a window open when a killed task didn't manage to die by the time
: freeze_processes finishes";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"The original patch hasn't closed the race window completely because that
would require a more complex solution as it can be seen by this patchset";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"The primary motivation was to close the race condition between OOM killer
and PM freezer _completely_";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" As Tejun pointed out, even though the race
condition is unlikely the harder it would be to debug weird bugs deep in
the PM freezer when the debugging options are reduced considerably";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" I can
only speculate what might happen when a task is still runnable
unexpectedly";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"On a plus side and as a side effect the oom enable/disable has a better
(full barrier) semantic without polluting hot paths";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;I have tested the series in KVM with 100M RAM;Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"- many small tasks (20M anon mmap) which are triggering OOM continually
- s2ram which resumes automatically is triggered in a loop
	echo processors > /sys/power/pm_test
	while true
		echo mem > /sys/power/state
		sleep 1s
	done
- simple module which allocates and frees 20M in 8K chunks";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"If it sees
  freezing(current) then it tries another round of allocation before calling
  try_to_freeze
- debugging messages of PM stages and OOM killer enable/disable/fail added
  and unmark_oom_victim is delayed by 1s after it clears TIF_MEMDIE and before
  it wakes up waiters";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"- rebased on top of the current mmotm which means some necessary updates
  in mm/oom_kill.c";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"mark_tsk_oom_victim is now called under task_lock but
  I think this should be OK because __thaw_task shouldn't interfere with any
  locking down wake_up_process";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"Oleg?
As expected there are no OOM killed tasks after oom is disabled and
allocations requested by the kernel thread are failing after all the tasks
are frozen and OOM disabled";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" I wasn't able to catch a race where
oom_killer_disable would really have to wait but I kinda expected the race
is really unlikely";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;The first 2 patches are simple cleanups for OOM;Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" They should go in
regardless the rest IMO";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"Patches 3 and 4 are trivial printk -> pr_info conversion and they should
go in ditto";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"The main patch is the last one and I would appreciate acks from Tejun and
Rafael";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz; I think the OOM part should be OK (except for __thaw_task vs;Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"task_lock where a look from Oleg would appreciated) but I am not so sure I
haven't screwed anything in the freezer code";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;" I have found several
surprises there";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;This patch (of 5);Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"This patch is just a preparatory and it doesn't introduce any functional
change";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;Note;Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"I am utterly unhappy about lowmemory killer abusing TIF_MEMDIE just to
wait for the oom victim and to prevent from new killing";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"This is
just a side effect of the flag";Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU1MGI2MDU1ODc5MjRiMzMzNjM4NmNhYWU1MzIwMGM2ODk2OWQz;"The primary meaning is to give the oom
victim access to the memory reserves and that shouldn't be necessary
here.";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;oom: make sure that TIF_MEMDIE is set under task_lock;Michal Hocko;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;"OOM killer tries to exclude tasks which do not have mm_struct associated
because killing such a task wouldn't help much";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;" The OOM victim gets
TIF_MEMDIE set to disable OOM killer while the current victim releases the
memory and then enables the OOM killer again by dropping the flag";Michal Hocko;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;"oom_kill_process is currently prone to a race condition when the OOM
victim is already exiting and TIF_MEMDIE is set after the task releases
its address space";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;" This might theoretically lead to OOM livelock if the
OOM victim blocks on an allocation later during exiting because it
wouldn't kill any other process and the exiting one won't be able to exit";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;" The situation is highly unlikely because the OOM victim is expected to
release some memory which should help to sort out OOM situation";Michal Hocko;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;"Fix this by checking task->mm and setting TIF_MEMDIE flag under task_lock
which will serialize the OOM killer with exit_mm which sets task->mm to
NULL";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo4MzM2M2I5MTdhMjk4MmRkNTA5YTVlMjEyNWU5MDViNjg3MzUwNWEz;" Setting the flag for current is not necessary because check and set
is not racy.";Michal Hocko;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;oom: don't count on mm-less current process;Tetsuo Handa;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;"out_of_memory() doesn't trigger the OOM killer if the current task is
already exiting or it has fatal signals pending, and gives the task
access to memory reserves instead";Tetsuo Handa;2015-02-11;0;0
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;" However, doing so is wrong if
out_of_memory() is called by an allocation (e.g";Tetsuo Handa;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;"from exit_task_work())
after the current task has already released its memory and cleared
TIF_MEMDIE at exit_mm()";Tetsuo Handa;2015-02-11;0;1
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;" If we again set TIF_MEMDIE to post-exit_mm()
current task, the OOM killer will be blocked by the task sitting in the
final schedule() waiting for its parent to reap it";Tetsuo Handa;2015-02-11;1;0
MDY6Q29tbWl0MjMyNTI5ODpkN2E5NGU3ZTExYmFkZjg0MDRkNDBiNDFlMDA4YzMxMzFhM2NlYmUz;" It will trigger an
OOM livelock if its parent is unable to reap it due to doing an
allocation and waiting for the OOM killer to kill it.";Tetsuo Handa;2015-02-11;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YTJkNTY3OWI0YTg1MmEzYmY4MGM1NzA2NDQ0NTZhYjQ2NmFiNzE0;oom: kill the insufficient and no longer needed PT_TRACE_EXIT check;Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YTJkNTY3OWI0YTg1MmEzYmY4MGM1NzA2NDQ0NTZhYjQ2NmFiNzE0;"After the previous patch we can remove the PT_TRACE_EXIT check in
oom_scan_process_thread(), it was added to handle the case when the
coredumping was ""frozen"" by ptrace, but it doesn't really work";Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YTJkNTY3OWI0YTg1MmEzYmY4MGM1NzA2NDQ0NTZhYjQ2NmFiNzE0;" If
nothing else, we would need to check all threads which could share the
same ->mm to make it more or less correct.";Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;oom: don't assume that a coredumping thread will exit soon;Oleg Nesterov;2014-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;"oom_kill.c assumes that PF_EXITING task should exit and free the memory
soon";Oleg Nesterov;2014-12-13;0;0
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1; This is wrong in many ways and one important case is the coredump;Oleg Nesterov;2014-12-13;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;"A task can sleep in exit_mm() ""forever"" while the coredumping sub-thread
can need more memory";Oleg Nesterov;2014-12-13;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;"Change the PF_EXITING checks to take SIGNAL_GROUP_COREDUMP into account,
we add the new trivial helper for that";Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;"Note: this is only the first step, this patch doesn't try to solve other
problems";Oleg Nesterov;2014-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;" The SIGNAL_GROUP_COREDUMP check is obviously racy, a task can
participate in coredump after it was already observed in PF_EXITING state,
so TIF_MEMDIE (which also blocks oom-killer) still can be wrongly set";Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;"fatal_signal_pending() can be true because of SIGNAL_GROUP_COREDUMP so
out_of_memory() and mem_cgroup_out_of_memory() shouldn't blindly trust it";Oleg Nesterov;2014-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMDAzZjM3MWIyNzAxNjM1NGMzOTI0NjQ4MTk1MzBkNDdhOTE1NzY1;" And even the name/usage of the new helper is confusing, an exiting thread
can only free its ->mm if it is the only/last task in thread group.";Oleg Nesterov;2014-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODoyMzE0YjQyZGI2N2JlMzBiNzQ3MTIyZDY1YzZjZDJjODVkYTM0NTM4;mm: memcontrol: drop bogus RCU locking from mem_cgroup_same_or_subtree();Johannes Weiner;2014-12-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoyMzE0YjQyZGI2N2JlMzBiNzQ3MTIyZDY1YzZjZDJjODVkYTM0NTM4;"None of the mem_cgroup_same_or_subtree() callers actually require it to
take the RCU lock, either because they hold it themselves or they have css
references";Johannes Weiner;2014-12-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoyMzE0YjQyZGI2N2JlMzBiNzQ3MTIyZDY1YzZjZDJjODVkYTM0NTM4; Remove it;Johannes Weiner;2014-12-10;1;0
MDY6Q29tbWl0MjMyNTI5ODoyMzE0YjQyZGI2N2JlMzBiNzQ3MTIyZDY1YzZjZDJjODVkYTM0NTM4;"To make the API change clear, rename the leftover helper to
mem_cgroup_is_descendant() to match cgroup_is_descendant().";Johannes Weiner;2014-12-10;1;1
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;cpuset: simplify cpuset_node_allowed API;Vladimir Davydov;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"Current cpuset API for checking if a zone/node is allowed to allocate
from looks rather awkward";Vladimir Davydov;2014-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"We have hardwall and softwall versions of
cpuset_node_allowed with the softwall version doing literally the same
as the hardwall version if __GFP_HARDWALL is passed to it in gfp flags";Vladimir Davydov;2014-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"If it isn't, the softwall version may check the given node against the
enclosing hardwall cpuset, which it needs to take the callback lock to
Such a distinction was introduced by commit 02a0e53d8227 (""cpuset";Vladimir Davydov;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"rework cpuset_zone_allowed api"")";Vladimir Davydov;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"Before, we had the only version with
the __GFP_HARDWALL flag determining its behavior";Vladimir Davydov;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"The purpose of the
commit was to avoid sleep-in-atomic bugs when someone would mistakenly
call the function without the __GFP_HARDWALL flag for an atomic
allocation";Vladimir Davydov;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"The suffixes introduced were intended to make the callers
think before using the function";Vladimir Davydov;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;"However, since the callback lock was converted from mutex to spinlock by
the previous patch, the softwall check function cannot sleep, and these
precautions are no longer necessary";Vladimir Davydov;2014-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDQ3MzZmMjliMzU5NzkwZmFjZDBiN2E1MjFlMzY3ZjE3MTVjMTFj;So let's simplify the API back to the single check.;Vladimir Davydov;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;OOM, PM: OOM killed task shouldn't escape PM suspend;Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"PM freezer relies on having all tasks frozen by the time devices are
getting frozen so that no task will touch them while they are getting
frozen";Michal Hocko;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"But OOM killer is allowed to kill an already frozen task in
order to handle OOM situtation";Michal Hocko;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"In order to protect from late wake ups
OOM killer is disabled after all tasks are frozen";Michal Hocko;2014-10-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"This, however, still
keeps a window open when a killed task didn't manage to die by the time
freeze_processes finishes";Michal Hocko;2014-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"Reduce the race window by checking all tasks after OOM killer has been
disabled";Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"This is still not race free completely unfortunately because
oom_killer_disable cannot stop an already ongoing OOM killer so a task
might still wake up from the fridge and get killed without
freeze_processes noticing";Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"Full synchronization of OOM and freezer is,
however, too heavy weight for this highly unlikely case";Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"Introduce and check oom_kills counter which gets incremented early when
the allocator enters __alloc_pages_may_oom path and only check all the
tasks if the counter changes during the freezing attempt";Michal Hocko;2014-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"The counter
is updated so early to reduce the race window since allocator checked
oom_killer_disabled which is set by PM-freezing code";Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"A false positive
will push the PM-freezer into a slow path but that is not a big deal";Michal Hocko;2014-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Njk1YmUxNDJlMjAzMTY3ZTNjYjUxNWVmODZhODg0MjRmMzUyNGVi;"Changes since v1
- push the re-check loop out of freeze_processes into
  check_frozen_processes and invert the condition to make the code more
  readable as per Rafael";Michal Hocko;2014-10-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NzA1NDY1MTc0Njg2ZDAwNzQ3M2UwMTdiNzZjNGI2NGI0NGFhNjkw;mm: clean up zone flags;Johannes Weiner;2014-10-09;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NzA1NDY1MTc0Njg2ZDAwNzQ3M2UwMTdiNzZjNGI2NGI0NGFhNjkw;"Page reclaim tests zone_is_reclaim_dirty(), but the site that actually
sets this state does zone_set_flag(zone, ZONE_TAIL_LRU_DIRTY), sending the
reader through layers indirection just to track down a simple bit";Johannes Weiner;2014-10-09;0;1
MDY6Q29tbWl0MjMyNTI5ODo1NzA1NDY1MTc0Njg2ZDAwNzQ3M2UwMTdiNzZjNGI2NGI0NGFhNjkw;"Remove all zone flag wrappers and just use bitops against zone->flags
directly";Johannes Weiner;2014-10-09;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NzA1NDY1MTc0Njg2ZDAwNzQ3M2UwMTdiNzZjNGI2NGI0NGFhNjkw; It's just as readable and the lines are barely any longer;Johannes Weiner;2014-10-09;0;0
MDY6Q29tbWl0MjMyNTI5ODo1NzA1NDY1MTc0Njg2ZDAwNzQ3M2UwMTdiNzZjNGI2NGI0NGFhNjkw;"Also rename ZONE_TAIL_LRU_DIRTY to ZONE_DIRTY to match ZONE_WRITEBACK, and
remove the zone_flags_t typedef.";Johannes Weiner;2014-10-09;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;mm, oom: remove unnecessary exit_state check;David Rientjes;2014-08-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;"The oom killer scans each process and determines whether it is eligible
for oom kill or whether the oom killer should abort because of
concurrent memory freeing";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;" It will abort when an eligible process is
found to have TIF_MEMDIE set, meaning it has already been oom killed and
we're waiting for it to exit";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;"Processes with task->mm == NULL should not be considered because they
are either kthreads or have already detached their memory and killing
them would not lead to memory freeing";David Rientjes;2014-08-06;0;1
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;" That memory is only freed after
exit_mm() has returned, however, and not when task->mm is first set to
NULL";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;"Clear TIF_MEMDIE after exit_mm()'s mmput() so that an oom killed process
is no longer considered for oom kill, but only until exit_mm() has
returned";David Rientjes;2014-08-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYjc5NGJjYmI0ZTU1NTIyNDJmOWE0YzVlMWZmZTRjNmRhMjlhOTY4;" This was fragile in the past because it relied on
exit_notify() to be reached before no longer considering TIF_MEMDIE
processes.";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODplOTcyYTA3MGUyZDMyOTZjZDJlMmNjMmZkMDU2MWNlODlhMWQ1ZWJm;mm, oom: rename zonelist locking functions;David Rientjes;2014-08-06;1;0
MDY6Q29tbWl0MjMyNTI5ODplOTcyYTA3MGUyZDMyOTZjZDJlMmNjMmZkMDU2MWNlODlhMWQ1ZWJm;"try_set_zonelist_oom() and clear_zonelist_oom() are not named properly
to imply that they require locking semantics to avoid out_of_memory()
being reordered";David Rientjes;2014-08-06;0;1
MDY6Q29tbWl0MjMyNTI5ODplOTcyYTA3MGUyZDMyOTZjZDJlMmNjMmZkMDU2MWNlODlhMWQ1ZWJm;"zone_scan_lock is required for both functions to ensure that there is
proper locking synchronization";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODplOTcyYTA3MGUyZDMyOTZjZDJlMmNjMmZkMDU2MWNlODlhMWQ1ZWJm;"Rename try_set_zonelist_oom() to oom_zonelist_trylock() and rename
clear_zonelist_oom() to oom_zonelist_unlock() to imply there is proper
locking semantics";David Rientjes;2014-08-06;1;1
MDY6Q29tbWl0MjMyNTI5ODplOTcyYTA3MGUyZDMyOTZjZDJlMmNjMmZkMDU2MWNlODlhMWQ1ZWJm;"At the same time, convert oom_zonelist_trylock() to return bool instead
of int since only success and failure are tested.";David Rientjes;2014-08-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDA2MGJmNDkwOTMwZjMwNWM0ZWZjNDU3MjRlODYxYTI2OGY0ZDJm;mm, oom: ensure memoryless node zonelist always includes zones;David Rientjes;2014-08-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ZDA2MGJmNDkwOTMwZjMwNWM0ZWZjNDU3MjRlODYxYTI2OGY0ZDJm;"With memoryless node support being worked on, it's possible that for
optimizations that a node may not have a non-NULL zonelist";David Rientjes;2014-08-06;0;0
MDY6Q29tbWl0MjMyNTI5ODo4ZDA2MGJmNDkwOTMwZjMwNWM0ZWZjNDU3MjRlODYxYTI2OGY0ZDJm;" When
CONFIG_NUMA is enabled and node 0 is memoryless, this means the zonelist
for first_online_node may become NULL";David Rientjes;2014-08-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDA2MGJmNDkwOTMwZjMwNWM0ZWZjNDU3MjRlODYxYTI2OGY0ZDJm;"The oom killer requires a zonelist that includes all memory zones for
the sysrq trigger and pagefault out of memory handler";David Rientjes;2014-08-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDA2MGJmNDkwOTMwZjMwNWM0ZWZjNDU3MjRlODYxYTI2OGY0ZDJm;Ensure that a non-NULL zonelist is always passed to the oom killer.;David Rientjes;2014-08-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;mm, oom: base root bonus on current usage;David Rientjes;2014-01-30;1;0
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;"A 3% of system memory bonus is sometimes too excessive in comparison to
other processes";David Rientjes;2014-01-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;"With commit a63d83f427fb (""oom: badness heuristic rewrite""), the OOM
killer tries to avoid killing privileged tasks by subtracting 3% of
overall memory (system or cgroup) from their per-task consumption";David Rientjes;2014-01-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;" But
as a result, all root tasks that consume less than 3% of overall memory
are considered equal, and so it only takes 33+ privileged tasks pushing
the system out of memory for the OOM killer to do something stupid and
kill dhclient or other root-owned processes";David Rientjes;2014-01-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;" For example, on a 32G
machine it can't tell the difference between the 1M agetty and the 10G
fork bomb member";David Rientjes;2014-01-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;"The changelog describes this 3% boost as the equivalent to the global
overcommit limit being 3% higher for privileged tasks, but this is not
the same as discounting 3% of overall memory from _every privileged task
individually_ during OOM selection";David Rientjes;2014-01-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;"Replace the 3% of system memory bonus with a 3% of current memory usage
bonus";David Rientjes;2014-01-30;1;0
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;"By giving root tasks a bonus that is proportional to their actual size,
they remain comparable even when relatively small";David Rientjes;2014-01-30;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NzhjMTRhZmZhZjk0YTllNDk1MzE3OWQzZTEzYTU0NGNjY2U3NzA3;" In the example
above, the OOM killer will discount the 1M agetty's 256 badness points
down to 179, and the 10G fork bomb's 262144 points down to 183500 points
and make the right choice, instead of discounting both to 0 and killing
agetty because it's first in the task list.";David Rientjes;2014-01-30;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNDlhZDkzNTU0MjBjNzQzYzczNmJmZDFkZWU5ZWFhNWIxYTc3MjJh;mm, oom: prefer thread group leaders for display purposes;David Rientjes;2014-01-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNDlhZDkzNTU0MjBjNzQzYzczNmJmZDFkZWU5ZWFhNWIxYTc3MjJh;"When two threads have the same badness score, it's preferable to kill
the thread group leader so that the actual process name is printed to
the kernel log rather than the thread group name which may be shared
amongst several processes";David Rientjes;2014-01-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNDlhZDkzNTU0MjBjNzQzYzczNmJmZDFkZWU5ZWFhNWIxYTc3MjJh;"This was the behavior when select_bad_process() used to do
for_each_process(), but it now iterates threads instead and leads to
ambiguity.";David Rientjes;2014-01-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDQwNDhiZThhOTM3NjkzNTBlZmEzMWQyNDgyYTAzOGI3ZGU3M2Qw;oom_kill: add rcu_read_lock() into find_lock_task_mm();Oleg Nesterov;2014-01-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZDQwNDhiZThhOTM3NjkzNTBlZmEzMWQyNDgyYTAzOGI3ZGU3M2Qw;"find_lock_task_mm() expects it is called under rcu or tasklist lock, but
it seems that at least oom_unkillable_task()->task_in_mem_cgroup() and
mem_cgroup_out_of_memory()->oom_badness() can call it lockless";Oleg Nesterov;2014-01-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDQwNDhiZThhOTM3NjkzNTBlZmEzMWQyNDgyYTAzOGI3ZGU3M2Qw;"Perhaps we could fix the callers, but this patch simply adds rcu lock
into find_lock_task_mm()";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDQwNDhiZThhOTM3NjkzNTBlZmEzMWQyNDgyYTAzOGI3ZGU3M2Qw;" This also allows to simplify a bit one of its
callers, oom_kill_process().";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;oom_kill: has_intersects_mems_allowed() needs rcu_read_lock();Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;"At least out_of_memory() calls has_intersects_mems_allowed() without
even rcu_read_lock(), this is obviously buggy";Oleg Nesterov;2014-01-21;0;1
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;Add the necessary rcu_read_lock();Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;" This means that we can not simply
return from the loop, we need ""bool ret"" and ""break""";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;"While at it, swap the names of task_struct's (the argument and the
local)";Oleg Nesterov;2014-01-21;1;0
MDY6Q29tbWl0MjMyNTI5ODphZDk2MjQ0MTc5ZmJkNTViNDBjMDBmMTBmMzk5YmMwNDczOWI4ZTFm;" This cleans up the code a little bit and avoids the unnecessary
initialization.";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGE0ZGIwY2Q1YzhhMzFkNDQ2OGVjOTA2YjQxM2U3NWU2MDRiNDY1;oom_kill: change oom_kill.c to use for_each_thread();Oleg Nesterov;2014-01-21;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZGE0ZGIwY2Q1YzhhMzFkNDQ2OGVjOTA2YjQxM2U3NWU2MDRiNDY1;"Change oom_kill.c to use for_each_thread() rather than the racy
while_each_thread() which can loop forever if we race with exit";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGE0ZGIwY2Q1YzhhMzFkNDQ2OGVjOTA2YjQxM2U3NWU2MDRiNDY1;"Note also that most users were buggy even if while_each_thread() was
fine, the task can exit even _before_ rcu_read_lock()";Oleg Nesterov;2014-01-21;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZGE0ZGIwY2Q1YzhhMzFkNDQ2OGVjOTA2YjQxM2U3NWU2MDRiNDY1;"Fortunately the new for_each_thread() only requires the stable
task_struct, so this change fixes both problems.";Oleg Nesterov;2014-01-21;1;1
MDY6Q29tbWl0MjMyNTI5ODplMWY1NmM4OWIwNDAxMzRhZGQ5M2Y2ODY5MzFjYzI2NjU0MWQyMzlh;mm: convert mm->nr_ptes to atomic_long_t;Kirill A. Shutemov;2013-11-14;1;0
MDY6Q29tbWl0MjMyNTI5ODplMWY1NmM4OWIwNDAxMzRhZGQ5M2Y2ODY5MzFjYzI2NjU0MWQyMzlh;"With split page table lock for PMD level we can't hold mm->page_table_lock
while updating nr_ptes";Kirill A. Shutemov;2013-11-14;0;1
MDY6Q29tbWl0MjMyNTI5ODplMWY1NmM4OWIwNDAxMzRhZGQ5M2Y2ODY5MzFjYzI2NjU0MWQyMzlh;Let's convert it to atomic_long_t to avoid races.;Kirill A. Shutemov;2013-11-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;mm: memcg: handle non-error OOM situations more gracefully;Johannes Weiner;2013-10-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;"Commit 3812c8c8f395 (""mm: memcg: do not trap chargers with full
callstack on OOM"") assumed that only a few places that can trigger a
memcg OOM situation do not return VM_FAULT_OOM, like optional page cache
readahead";Johannes Weiner;2013-10-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;" But there are many more and it's impractical to annotate
them all";Johannes Weiner;2013-10-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;"First of all, we don't want to invoke the OOM killer when the failed
allocation is gracefully handled, so defer the actual kill to the end of
the fault handling as well";Johannes Weiner;2013-10-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;" This simplifies the code quite a bit for
added bonus";Johannes Weiner;2013-10-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;"Second, since a failed allocation might not be the abrupt end of the
fault, the memcg OOM handler needs to be re-entrant until the fault
finishes for subsequent allocation attempts";Johannes Weiner;2013-10-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo0OTQyNjQyMDgwZWE4MmQ5OWFiNWI2NTNhYmI5YTEyYjdiYTMxZjRh;" If an allocation is
attempted after the task already OOMed, allow it to bypass the limit so
that it can quickly finish the fault and invoke the OOM killer.";Johannes Weiner;2013-10-16;1;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;mm: memcg: do not trap chargers with full callstack on OOM;Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;The memcg OOM handling is incredibly fragile and can deadlock;Johannes Weiner;2013-09-12;0;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" When a
task fails to charge memory, it invokes the OOM killer and loops right
there in the charge code until it succeeds";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" Comparably, any other task
that enters the charge path at this point will go to a waitqueue right
then and there and sleep until the OOM situation is resolved";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" The problem
is that these tasks may hold filesystem locks and the mmap_sem; locks that
the selected OOM victim may need to exit";Johannes Weiner;2013-09-12;0;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"For example, in one reported case, the task invoking the OOM killer was
about to charge a page cache page during a write(), which holds the
i_mutex";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" The OOM killer selected a task that was just entering truncate()
and trying to acquire the i_mutex";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;OOM invoking task;Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"  mem_cgroup_handle_oom+0x241/0x3b0
  mem_cgroup_cache_charge+0xbe/0xe0
  add_to_page_cache_locked+0x4c/0x140
  add_to_page_cache_lru+0x22/0x50
  grab_cache_page_write_begin+0x8b/0xe0
  ext3_write_begin+0x88/0x270
  generic_file_buffered_write+0x116/0x290
  __generic_file_aio_write+0x27c/0x480
  generic_file_aio_write+0x76/0xf0           # takes ->i_mutex
  do_sync_write+0xea/0x130
  vfs_write+0xf3/0x1f0
  sys_write+0x51/0x90
  system_call_fastpath+0x18/0x1d
OOM kill victim";Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"  do_truncate+0x58/0xa0              # takes i_mutex
  do_last+0x250/0xa30
  path_openat+0xd7/0x440
  do_filp_open+0x49/0xa0
  do_sys_open+0x106/0x240
  sys_open+0x20/0x30
  system_call_fastpath+0x18/0x1d
The OOM handling task will retry the charge indefinitely while the OOM
killed task is not releasing any resources";Johannes Weiner;2013-09-12;0;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"A similar scenario can happen when the kernel OOM killer for a memcg is
disabled and a userspace task is in charge of resolving OOM situations";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"In this case, ALL tasks that enter the OOM path will be made to sleep on
the OOM waitqueue and wait for userspace to free resources or increase
the group's limit";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" But a userspace OOM handler is prone to deadlock
itself on the locks held by the waiting tasks";Johannes Weiner;2013-09-12;0;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" For example one of the
sleeping tasks may be stuck in a brk() call with the mmap_sem held for
writing but the userspace handler, in order to pick an optimal victim,
may need to read files from /proc/<pid>, which tries to acquire the same
mmap_sem for reading and deadlocks";Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"This patch changes the way tasks behave after detecting a memcg OOM and
makes sure nobody loops or sleeps with locks held";Johannes Weiner;2013-09-12;1;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;1;Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"When OOMing in a user fault, invoke the OOM killer and restart the
   fault instead of looping on the charge attempt";Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" This way, the OOM
   victim can not get stuck on locks the looping task may hold";Johannes Weiner;2013-09-12;1;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;2;Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;"When OOMing in a user fault but somebody else is handling it
   (either the kernel OOM killer or a userspace handler), don't go to
   sleep in the charge context";Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" Instead, remember the OOMing memcg in
   the task struct and then fully unwind the page fault stack with
   -ENOMEM";Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" pagefault_out_of_memory() will then call back into the
   memcg code to check if the -ENOMEM came from the memcg, and then
   either put the task to sleep on the memcg's OOM waitqueue or just
   restart the fault";Johannes Weiner;2013-09-12;1;0
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;" The OOM victim can no longer get stuck on any
   lock a sleeping task may hold";Johannes Weiner;2013-09-12;1;1
MDY6Q29tbWl0MjMyNTI5ODozODEyYzhjOGYzOTUzOTIxZWYxODU0NDExMGRhZmMzNTA1YzFhYzYy;Debugged by Michal Hocko.;Johannes Weiner;2013-09-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YjRmMmI1NmE0OGM4ZWE5Nzc1YmQyYjI5NjgxNzI1ZDQ0NzQzNjdh;mm/oom_kill: remove weird use of ERR_PTR()/PTR_ERR().;Rusty Russell;2013-07-15;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YjRmMmI1NmE0OGM4ZWE5Nzc1YmQyYjI5NjgxNzI1ZDQ0NzQzNjdh;"The normal expectation for ERR_PTR() is to put a negative errno into a
pointer";Rusty Russell;2013-07-15;0;0
MDY6Q29tbWl0MjMyNTI5ODo2YjRmMmI1NmE0OGM4ZWE5Nzc1YmQyYjI5NjgxNzI1ZDQ0NzQzNjdh;" oom_kill puts the magic -1 in the result (and has since
pre-git), which is probably clearer with an explicit cast.";Rusty Russell;2013-07-15;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;memcg, oom: provide more precise dump info while memcg oom happening;Sha Zhengju;2013-02-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;"Currently when a memcg oom is happening the oom dump messages is still
global state and provides few useful info for users";Sha Zhengju;2013-02-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;" This patch prints
more pointed memcg page statistics for memcg-oom and take hierarchy into
consideration";Sha Zhengju;2013-02-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;"Based on Michal's advice, we take hierarchy into consideration: supppose
we trigger an OOM on A's limit
        root_memcg
            A (use_hierachy=1)
then the printed info will be";Sha Zhengju;2013-02-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;  Memory cgroup stats for /A:..;Sha Zhengju;2013-02-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;  Memory cgroup stats for /A/B:..;Sha Zhengju;2013-02-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;  Memory cgroup stats for /A/C:..;Sha Zhengju;2013-02-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;  Memory cgroup stats for /A/B/D:..;Sha Zhengju;2013-02-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;Following are samples of oom output;Sha Zhengju;2013-02-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;(1) Before change;Sha Zhengju;2013-02-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;"    mal-80 invoked oom-killer:gfp_mask=0xd0, order=0, oom_score_adj=0
    mal-80 cpuset=/ mems_allowed=0
    Pid: 2976, comm: mal-80 Not tainted 3.7.0+ #10
    We can see that messages dumped by show_free_areas() are longsome and can
provide so limited info for memcg that just happen oom";Sha Zhengju;2013-02-23;0;1
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;"(2) After change
    mal-80 invoked oom-killer: gfp_mask=0xd0, order=0, oom_score_adj=0
    mal-80 cpuset=/ mems_allowed=0
    Pid: 2704, comm: mal-80 Not tainted 3.7.0+ #10
    Call Trace";Sha Zhengju;2013-02-23;0;0
MDY6Q29tbWl0MjMyNTI5ODo1OGNmMTg4ZWQ2NDliNjU3MGRmZGM5YzYyMTU2Y2RmMzk2YzJlMzk1;"     [<ffffffff8167fd0b>] dump_header+0x83/0x1d1
     .......(call trace)
     [<ffffffff8168a918>] page_fault+0x28/0x30
    Task in /A/B/D killed as a result of limit of /A
                             <<<<<<<<<<<<<<<<<<<<< memcg specific information
    memory: usage 102400kB, limit 102400kB, failcnt 140
    memory+swap: usage 102400kB, limit 102400kB, failcnt 0
    kmem: usage 0kB, limit 9007199254740991kB, failcnt 0
    Memory cgroup stats for /A: cache:32KB rss:30984KB mapped_file:0KB swap:0KB inactive_anon:6912KB active_anon:24072KB inactive_file:32KB active_file:0KB unevictable:0KB
    Memory cgroup stats for /A/B: cache:0KB rss:0KB mapped_file:0KB swap:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB
    Memory cgroup stats for /A/C: cache:0KB rss:0KB mapped_file:0KB swap:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB
    Memory cgroup stats for /A/B/D: cache:32KB rss:71352KB mapped_file:0KB swap:0KB inactive_anon:6656KB active_anon:64696KB inactive_file:16KB active_file:16KB unevictable:0KB
    [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
    [ 2260]     0  2260     6006     1325      18        0             0 god
    [ 2383]     0  2383     6003     1319      17        0             0 god
    [ 2503]     0  2503     6004     1321      18        0             0 god
    [ 2622]     0  2622     6004     1321      16        0             0 god
    [ 2695]     0  2695     8720     7741      22        0             0 mal-30
    [ 2704]     0  2704    21520    17839      43        0             0 mal-80
    Memory cgroup out of memory: Kill process 2704 (mal-80) score 669 or sacrifice child
    Killed process 2704 (mal-80) total-vm:86080kB, anon-rss:71016kB, file-rss:340kB
This version provides more pointed info for memcg in ""Memory cgroup stats
for XXX"" section.";Sha Zhengju;2013-02-23;0;1
MDY6Q29tbWl0MjMyNTI5ODowZmE4NGE0YmZhMmFhYzhjMDRkNDUzNTFiNDA3NjVkNjFlMWZkMjBk;mm, oom: remove redundant sleep in pagefault oom handler;David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODowZmE4NGE0YmZhMmFhYzhjMDRkNDUzNTFiNDA3NjVkNjFlMWZkMjBk;"out_of_memory() will already cause current to schedule if it has not been
killed, so doing it again in pagefault_out_of_memory() is redundant";David Rientjes;2012-12-12;0;1
MDY6Q29tbWl0MjMyNTI5ODowZmE4NGE0YmZhMmFhYzhjMDRkNDUzNTFiNDA3NjVkNjFlMWZkMjBk;Remove it.;David Rientjes;2012-12-12;1;0
MDY6Q29tbWl0MjMyNTI5ODplZmFjZDAyZTRmNTdkOTRlOTM0YmE1Yzg0ZjEwZjhjZTkxMTU4Nzcw;mm, oom: cleanup pagefault oom handler;David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODplZmFjZDAyZTRmNTdkOTRlOTM0YmE1Yzg0ZjEwZjhjZTkxMTU4Nzcw;"To lock the entire system from parallel oom killing, it's possible to pass
in a zonelist with all zones rather than using for_each_populated_zone()
for the iteration";David Rientjes;2012-12-12;1;0
MDY6Q29tbWl0MjMyNTI5ODplZmFjZDAyZTRmNTdkOTRlOTM0YmE1Yzg0ZjEwZjhjZTkxMTU4Nzcw;" This obsoletes try_set_system_oom() and
clear_system_oom() so that they can be removed.";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODpiZDNhNjZjMWNkZjMxMjc0NDg5Y2MxYjVhY2U4Nzk2OTVhNWExNzk3;oom: use N_MEMORY instead N_HIGH_MEMORY;Lai Jiangshan;2012-12-12;1;0
MDY6Q29tbWl0MjMyNTI5ODpiZDNhNjZjMWNkZjMxMjc0NDg5Y2MxYjVhY2U4Nzk2OTVhNWExNzk3;N_HIGH_MEMORY stands for the nodes that has normal or high memory;Lai Jiangshan;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODpiZDNhNjZjMWNkZjMxMjc0NDg5Y2MxYjVhY2U4Nzk2OTVhNWExNzk3;N_MEMORY stands for the nodes that has any memory;Lai Jiangshan;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODpiZDNhNjZjMWNkZjMxMjc0NDg5Y2MxYjVhY2U4Nzk2OTVhNWExNzk3;"The code here need to handle with the nodes which have memory, we should
use N_MEMORY instead.";Lai Jiangshan;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;mm, oom: fix race when specifying a thread as the oom origin;David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"test_set_oom_score_adj() and compare_swap_oom_score_adj() are used to
specify that current should be killed first if an oom condition occurs in
between the two calls";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"The usage is
to store the thread's oom_score_adj, temporarily change it to the maximum
score possible, and then restore the old value if it is still the same";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"This happens to still be racy, however, if the user writes
OOM_SCORE_ADJ_MAX to /proc/pid/oom_score_adj in between the two calls";David Rientjes;2012-12-12;0;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"The compare_swap_oom_score_adj() will then incorrectly reset the old value
prior to the write of OOM_SCORE_ADJ_MAX";David Rientjes;2012-12-12;0;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"To fix this, introduce a new oom_flags_t member in struct signal_struct
that will be used for per-thread oom killer flags";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;" KSM and swapoff can
now use a bit in this member to specify that threads should be killed
first in oom conditions without playing around with oom_score_adj";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODplMWUxMmQyZjMxMDRiZTg4NjA3M2FjNmM1YzQ2NzhmMzBiMWI5ZTUx;"This also allows the correct oom_score_adj to always be shown when reading
/proc/pid/oom_score.";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODphOWM1OGI5MDdkYmM2ODIxNTMzZGZjMjk1YjYzY2FmMTExZmYxZjE2;mm, oom: change type of oom_score_adj to short;David Rientjes;2012-12-12;1;0
MDY6Q29tbWl0MjMyNTI5ODphOWM1OGI5MDdkYmM2ODIxNTMzZGZjMjk1YjYzY2FmMTExZmYxZjE2;"The maximum oom_score_adj is 1000 and the minimum oom_score_adj is -1000,
so this range can be represented by the signed short type with no
functional change";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODphOWM1OGI5MDdkYmM2ODIxNTMzZGZjMjk1YjYzY2FmMTExZmYxZjE2;" The extra space this frees up in struct signal_struct
will be used for per-thread oom kill flags in the next patch.";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;mm, oom: allow exiting threads to have access to memory reserves;David Rientjes;2012-12-12;1;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;"Exiting threads, those with PF_EXITING set, can pagefault and require
memory before they can make forward progress";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;" This happens, for instance,
when a process must fault task->robust_list, a userspace structure, before
detaching its memory";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;"These threads also aren't guaranteed to get access to memory reserves
unless oom killed or killed from userspace";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;" The oom killer won't grant
memory reserves if other threads are also exiting other than current and
stalling at the same point";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;" This prevents needlessly killing processes
when others are already exiting";David Rientjes;2012-12-12;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;"Instead of special casing all the possible situations between PF_EXITING
getting set and a thread detaching its mm where it may allocate memory,
which probably wouldn't get updated when a change is made to the exit
path, the solution is to give all exiting threads access to memory
reserves if they call the oom killer";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;" This allows them to quickly
allocate, detach its mm, and free the memory it represents";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;Summary of Luigi's bug report;David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;": He had an oom condition where threads were faulting on task->robust_list
: and repeatedly called the oom killer but it would defer killing a thread
: because it saw other PF_EXITING threads";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;" This can happen anytime we need
: if there are other threads in the same state then the oom killer won't do
: anything unless one of them happens to be killed from userspace";David Rientjes;2012-12-12;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ZmY0ODY4ZTMwNTFkOTEyOGEyNGRkMzMwYmVkMzIwMTFhMTE0MjFk;": So instead of only deferring for PF_EXITING and !task->robust_list, it's
: better to just give them access to memory reserves to prevent a potential
: livelock so that any other faults that may be introduced in the future in
: the exit path don't cause the same problem (and hopefully we don't allow
: too many of those!).";David Rientjes;2012-12-12;1;1
MDY6Q29tbWl0MjMyNTI5ODowMWRjNTJlYmRmNDcyZjc3Y2NhNjIzY2E2OTNjYTI0Y2ZjMGYxYmJl;oom: remove deprecated oom_adj;Davidlohr Bueso;2012-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODowMWRjNTJlYmRmNDcyZjc3Y2NhNjIzY2E2OTNjYTI0Y2ZjMGYxYmJl;The deprecated /proc/<pid>/oom_adj is scheduled for removal this month.;Davidlohr Bueso;2012-10-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NzZhYWZiZmQ5YmE1YmIzNTJmMWIxNDYyMmMyN2YzZmU5YTk5MDEz;mm, memcg: move all oom handling to memcontrol.c;David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NzZhYWZiZmQ5YmE1YmIzNTJmMWIxNDYyMmMyN2YzZmU5YTk5MDEz;"By globally defining check_panic_on_oom(), the memcg oom handler can be
moved entirely to mm/memcontrol.c";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NzZhYWZiZmQ5YmE1YmIzNTJmMWIxNDYyMmMyN2YzZmU5YTk5MDEz;" This removes the ugly #ifdef in the
oom killer and cleans up the code.";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;mm, oom: reduce dependency on tasklist_lock;David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;"Since exiting tasks require write_lock_irq(&tasklist_lock) several times,
try to reduce the amount of time the readside is held for oom kills";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;" This
makes the interface with the memcg oom handler more consistent since it
now never needs to take tasklist_lock unnecessarily";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;"The only time the oom killer now takes tasklist_lock is when iterating the
children of the selected task, everything else is protected by
rcu_read_lock()";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;"This requires that a reference to the selected process, p, is grabbed
before calling oom_kill_process()";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo2YjBjODFiM2JlMTE0YTkzZjc5YmQ0YzU2MzlhZGU1MTA3ZDc3YzIx;" It may release it and grab a reference
on another one of p's threads if !p->mm, but it also guarantees that it
will release the reference before returning.";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;mm, memcg: introduce own oom handler to iterate only over its own threads;David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"The global oom killer is serialized by the per-zonelist
try_set_zonelist_oom() which is used in the page allocator";David Rientjes;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;" Concurrent
oom kills are thus a rare event and only occur in systems using
mempolicies and with a large number of nodes";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"Memory controller oom kills, however, can frequently be concurrent since
there is no serialization once the oom killer is called for oom conditions
in several different memcgs in parallel";David Rientjes;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"This creates a massive contention on tasklist_lock since the oom killer
requires the readside for the tasklist iteration";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;" If several memcgs are
calling the oom killer, this lock can be held for a substantial amount of
time, especially if threads continue to enter it as other threads are
exiting";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"Since the exit path grabs the writeside of the lock with irqs disabled in
a few different places, this can cause a soft lockup on cpus as a result
of tasklist_lock starvation";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"The kernel lacks unfair writelocks, and successful calls to the oom killer
usually result in at least one thread entering the exit path, so an
alternative solution is needed";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"This patch introduces a seperate oom handler for memcgs so that they do
not require tasklist_lock for as much time";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;" Instead, it iterates only
over the threads attached to the oom memcg and grabs a reference to the
selected thread before calling oom_kill_process() to ensure it doesn't
prematurely exit";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;"This still requires tasklist_lock for the tasklist dump, iterating
children of the selected process, and killing all other threads on the
system sharing the same memory as the selected victim";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo5Y2JiNzhiYjMxNDM2MGE4NjBhOGIyMzcyMzk3MWNiNmZjYjU0MTc2;" So while this
isn't a complete solution to tasklist_lock starvation, it significantly
reduces the amount of time that it is held.";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;mm, oom: introduce helper function to process threads during scan;David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;"This patch introduces a helper function to process each thread during the
iteration over the tasklist";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;" A new return type, enum oom_scan_t, is
defined to determine the future behavior of the iteration";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;" - OOM_SCAN_OK: continue scanning the thread and find its badness,
 - OOM_SCAN_CONTINUE: do not consider this thread for oom kill, it's
   ineligible,
 - OOM_SCAN_ABORT: abort the iteration and return, or
 - OOM_SCAN_SELECT: always select this thread with the highest badness
   possible";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;There is no functional change with this patch;David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NjI2MDdlY2M1MTliMTk3ZjdiNWNjNmIwMjRhMWMyNmZhNmZjMGFj;" This new helper function
will be used in the next patch in the memory controller.";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMjU1YTQ1ODA1NWU0NTlmNjVlYjdiN2Y1MWRjNWRiZGQwY2FmMWQ4;memcg: rename config variables;Andrew Morton;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMjU1YTQ1ODA1NWU0NTlmNjVlYjdiN2Y1MWRjNWRiZGQwY2FmMWQ4;Sanity;Andrew Morton;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODpjMjU1YTQ1ODA1NWU0NTlmNjVlYjdiN2Y1MWRjNWRiZGQwY2FmMWQ4;"CONFIG_CGROUP_MEM_RES_CTLR -> CONFIG_MEMCG
CONFIG_CGROUP_MEM_RES_CTLR_SWAP -> CONFIG_MEMCG_SWAP
CONFIG_CGROUP_MEM_RES_CTLR_SWAP_ENABLED -> CONFIG_MEMCG_SWAP_ENABLED
CONFIG_CGROUP_MEM_RES_CTLR_KMEM -> CONFIG_MEMCG_KMEM";Andrew Morton;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZTM0ZDk2NWE4MGQwZjYxYTM1NGJkZWZhMGIxNWE4OGJjZmYyMDI4;mm, oom: replace some information in tasklist dump;David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZTM0ZDk2NWE4MGQwZjYxYTM1NGJkZWZhMGIxNWE4OGJjZmYyMDI4;"The number of ptes and swap entries are used in the oom killer's badness
heuristic, so they should be shown in the tasklist dump";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZTM0ZDk2NWE4MGQwZjYxYTM1NGJkZWZhMGIxNWE4OGJjZmYyMDI4;"This patch adds those fields and replaces cpu and oom_adj values that are
currently emitted";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZTM0ZDk2NWE4MGQwZjYxYTM1NGJkZWZhMGIxNWE4OGJjZmYyMDI4;" Cpu isn't interesting and oom_adj is deprecated and
will be removed later this year, the same information is already displayed
as oom_score_adj which is used internally";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZTM0ZDk2NWE4MGQwZjYxYTM1NGJkZWZhMGIxNWE4OGJjZmYyMDI4;"At the same time, make the documentation a little more clear to state this
information is helpful to determine why the oom killer chose the task it
did to kill.";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODoxMjFkMWJhMGEwMTllMTQ2NWE1MzUzM2FlYTEzM2IxYjBmNmI0NDJk;mm, oom: fix potential killing of thread that is disabled from oom killing;David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMjFkMWJhMGEwMTllMTQ2NWE1MzUzM2FlYTEzM2IxYjBmNmI0NDJk;"/proc/sys/vm/oom_kill_allocating_task will immediately kill current when
the oom killer is called to avoid a potentially expensive tasklist scan
for large systems";David Rientjes;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMjFkMWJhMGEwMTllMTQ2NWE1MzUzM2FlYTEzM2IxYjBmNmI0NDJk;"Currently, however, it is not checking current's oom_score_adj value which
may be OOM_SCORE_ADJ_MIN, meaning that it has been disabled from oom
killing";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODoxMjFkMWJhMGEwMTllMTQ2NWE1MzUzM2FlYTEzM2IxYjBmNmI0NDJk;"This patch avoids killing current in such a condition and simply falls
back to the tasklist scan since memory still needs to be freed.";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;mm, oom: do not schedule if current has been killed;David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;"The oom killer currently schedules away from current in an uninterruptible
sleep if it does not have access to memory reserves";David Rientjes;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;" It's possible that
current was killed because it shares memory with the oom killed thread or
because it was killed by the user in the interim, however";David Rientjes;2012-07-31;0;0
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;"This patch only schedules away from current if it does not have a pending
kill, i.e";David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw; if it does not share memory with the oom killed thread;David Rientjes;2012-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;" It's
possible that it will immediately retry its memory allocation and fail,
but it will immediately be given access to memory reserves if it calls the
oom killer again";David Rientjes;2012-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODo0Zjc3NGI5MTJkZDFkNTc1MmNkMzNiNjk2NTA5NTMxYjAzMjFjM2Uw;"This prevents the delay of memory freeing when threads that share memory
with the oom killed thread get unnecessarily scheduled.";David Rientjes;2012-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYWQ3NTU3ZWI3MDU2ODgwNDBhYWMxMzRlZmE1NDE4YjY2ZDVlZDky;mm: fix kernel-doc warnings;Wanpeng Li;2012-06-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYWQ3NTU3ZWI3MDU2ODgwNDBhYWMxMzRlZmE1NDE4YjY2ZDVlZDky;"Fix kernel-doc warnings such as
  Warning(../mm/page_cgroup.c:432): No description found for parameter 'id'
  Warning(../mm/page_cgroup.c:432): Excess function parameter 'mem' description in 'swap_cgroup_record'";Wanpeng Li;2012-06-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo2MWVhZmIwMGQ1NWRmYmNjZGZjZTU0M2M2YjYwZTM2OWZmNGY4ZjE4;mm, oom: fix and cleanup oom score calculations;David Rientjes;2012-06-20;1;1
MDY6Q29tbWl0MjMyNTI5ODo2MWVhZmIwMGQ1NWRmYmNjZGZjZTU0M2M2YjYwZTM2OWZmNGY4ZjE4;"The divide in p->signal->oom_score_adj * totalpages / 1000 within
oom_badness() was causing an overflow of the signed long data type";David Rientjes;2012-06-20;0;0
MDY6Q29tbWl0MjMyNTI5ODo2MWVhZmIwMGQ1NWRmYmNjZGZjZTU0M2M2YjYwZTM2OWZmNGY4ZjE4;"This adds both the root bias and p->signal->oom_score_adj before doing the
normalization which fixes the issue and also cleans up the calculation.";David Rientjes;2012-06-20;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZTExYWQ4ZGM0Mjk3NWQ1YzJiYWI3ZDQ3OGY2Y2Q4NzU2MDJlZGE0;mm, oom: fix badness score underflow;David Rientjes;2012-06-08;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZTExYWQ4ZGM0Mjk3NWQ1YzJiYWI3ZDQ3OGY2Y2Q4NzU2MDJlZGE0;"If the privileges given to root threads (3% of allowable memory) or a
negative value of /proc/pid/oom_score_adj happen to exceed the amount of
rss of a thread, its badness score overflows as a result of commit
a7f638f999ff (""mm, oom: normalize oom scores to oom_score_adj scale only
for userspace"")";David Rientjes;2012-06-08;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZTExYWQ4ZGM0Mjk3NWQ1YzJiYWI3ZDQ3OGY2Y2Q4NzU2MDJlZGE0;"Fix this by making the type signed and return 1, meaning the thread is
still eligible for kill, if the value is negative.";David Rientjes;2012-06-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;mm, oom: normalize oom scores to oom_score_adj scale only for userspace;David Rientjes;2012-05-29;1;0
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;"The oom_score_adj scale ranges from -1000 to 1000 and represents the
proportion of memory available to the process at allocation time";David Rientjes;2012-05-29;0;0
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;" This
means an oom_score_adj value of 300, for example, will bias a process as
though it was using an extra 30.0% of available memory and a value of
-350 will discount 35.0% of available memory from its usage";David Rientjes;2012-05-29;0;0
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;"The oom killer badness heuristic also uses this scale to report the oom
score for each eligible process in determining the ""best"" process to
kill";David Rientjes;2012-05-29;0;0
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;" Thus, it can only differentiate each process's memory usage by
0.1% of system RAM";David Rientjes;2012-05-29;0;1
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;"On large systems, this can end up being a large amount of memory: 256MB
on 256GB systems, for example";David Rientjes;2012-05-29;0;1
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;"This can be fixed by having the badness heuristic to use the actual
memory usage in scoring threads and then normalizing it to the
oom_score_adj scale for userspace";David Rientjes;2012-05-29;1;0
MDY6Q29tbWl0MjMyNTI5ODphN2Y2MzhmOTk5ZmY0MjMxMGU5NTgyMjczYjFmZTI1ZWE2ZTQ2OWJh;" This results in better comparison
between eligible threads for kill and no change from the userspace
perspective.";David Rientjes;2012-05-29;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzhkZTVmNzA2ZWNlMzZhZmQ3M2JiNGI4MjgzMzE0MTMyZDJkZmRm;userns: Store uid and gid values in struct cred with kuid_t and kgid_t types;Eric W. Biederman;2012-02-08;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzhkZTVmNzA2ZWNlMzZhZmQ3M2JiNGI4MjgzMzE0MTMyZDJkZmRm;cred.h and a few trivial users of struct cred are changed;Eric W. Biederman;2012-02-08;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzhkZTVmNzA2ZWNlMzZhZmQ3M2JiNGI4MjgzMzE0MTMyZDJkZmRm;" The rest of the users
of struct cred are left for other patches as there are too many changes to make
in one go and leave the change reviewable";Eric W. Biederman;2012-02-08;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzhkZTVmNzA2ZWNlMzZhZmQ3M2JiNGI4MjgzMzE0MTMyZDJkZmRm;" If the user namespace is disabled and
CONFIG_UIDGID_STRICT_TYPE_CHECKS are disabled the code will contiue to compile
and behave correctly.";Eric W. Biederman;2012-02-08;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMmQzOTMwOTlkZTIxZWRhOTFjNWVjNmEwNWQ2MGU1ZGVlNGQ1MTc1;signal: oom_kill_task: use SEND_SIG_FORCED instead of force_sig();Oleg Nesterov;2012-03-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMmQzOTMwOTlkZTIxZWRhOTFjNWVjNmEwNWQ2MGU1ZGVlNGQ1MTc1;"Change oom_kill_task() to use do_send_sig_info(SEND_SIG_FORCED) instead
of force_sig(SIGKILL)";Oleg Nesterov;2012-03-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMmQzOTMwOTlkZTIxZWRhOTFjNWVjNmEwNWQ2MGU1ZGVlNGQ1MTc1;" With the recent changes we do not need force_ to
kill the CLONE_NEWPID tasks";Oleg Nesterov;2012-03-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMmQzOTMwOTlkZTIxZWRhOTFjNWVjNmEwNWQ2MGU1ZGVlNGQ1MTc1;And this is more correct;Oleg Nesterov;2012-03-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMmQzOTMwOTlkZTIxZWRhOTFjNWVjNmEwNWQ2MGU1ZGVlNGQ1MTc1;" force_sig() can race with the exiting thread
even if oom_kill_task() checks p->mm != NULL, while
do_send_sig_info(group => true) kille the whole process.";Oleg Nesterov;2012-03-23;0;1
MDY6Q29tbWl0MjMyNTI5ODplODQ1ZTE5OTM2MmNjNTcxMmJhMGU3ZWVkYzE0ZWVkNzBlMTQ0MjU4;mm, memcg: pass charge order to oom killer;David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODplODQ1ZTE5OTM2MmNjNTcxMmJhMGU3ZWVkYzE0ZWVkNzBlMTQ0MjU4;"The oom killer typically displays the allocation order at the time of oom
as a part of its diangostic messages (for global, cpuset, and mempolicy
ooms)";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODplODQ1ZTE5OTM2MmNjNTcxMmJhMGU3ZWVkYzE0ZWVkNzBlMTQ0MjU4;"The memory controller may also pass the charge order to the oom killer so
it can emit the same information";David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODplODQ1ZTE5OTM2MmNjNTcxMmJhMGU3ZWVkYzE0ZWVkNzBlMTQ0MjU4;" This is useful in determining how large
the memory allocation is that triggered the oom killer.";David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;mm, oom: force oom kill on sysrq+f;David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;The oom killer chooses not to kill a thread if;David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;" - an eligible thread has already been oom killed and has yet to exit,
 - an eligible thread is exiting but has yet to free all its memory and
   is not the thread attempting to currently allocate memory";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;"SysRq+F manually invokes the global oom killer to kill a memory-hogging
task";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;" This is normally done as a last resort to free memory when no
progress is being made or to test the oom killer itself";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;For both uses, we always want to kill a thread and never defer;David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODowOGFiOWIxMGQ0M2FjYTA5MWZkZmY1OGI2OWZjMWVjODljNWI4YTgz;" This
patch causes SysRq+F to always kill an eligible thread and can be used to
force a kill even if another oom killed thread has failed to exit.";David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzNmMjFlYWRlZWE2ZDk4OTgyNzFmZjMyZDM1ZDVlMDBjNjg3MmVh;mm, oom: introduce independent oom killer ratelimit state;David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYzNmMjFlYWRlZWE2ZDk4OTgyNzFmZjMyZDM1ZDVlMDBjNjg3MmVh;printk_ratelimit() uses the global ratelimit state for all printks;David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzNmMjFlYWRlZWE2ZDk4OTgyNzFmZjMyZDM1ZDVlMDBjNjg3MmVh;" The
oom killer should not be subjected to this state just because another
subsystem or driver may be flooding the kernel log";David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYzNmMjFlYWRlZWE2ZDk4OTgyNzFmZjMyZDM1ZDVlMDBjNjg3MmVh;This patch introduces printk ratelimiting specifically for the oom killer.;David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;mm, oom: do not emit oom killer warning if chosen thread is already exiting;David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;"If a thread is chosen for oom kill and is already PF_EXITING, then the oom
killer simply sets TIF_MEMDIE and returns";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;" This allows the thread to have
access to memory reserves so that it may quickly exit";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;" This logic is
preceeded with a comment saying there's no need to alarm the sysadmin";David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;This patch adds truth to that statement;David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;"There's no need to emit any warning about the oom condition if the thread
is already exiting since it will not be killed";David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo4NDQ3ZDk1MGU3NDQ1Y2FlNzFhZDY2ZDBlMzM3ODRmODM4OGFhZjlk;" In this condition, just
silently return the oom killer since its only giving access to memory
reserves and is otherwise a no-op.";David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NDdmMmJkZjRhMDBkYmNhYTg5NjQyODY1MDFkNjhlN2QyZTZkYTkz;mm, oom: fold oom_kill_task() into oom_kill_process();David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NDdmMmJkZjRhMDBkYmNhYTg5NjQyODY1MDFkNjhlN2QyZTZkYTkz;"oom_kill_task() has a single caller, so fold it into its parent function,
oom_kill_process()";David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo2NDdmMmJkZjRhMDBkYmNhYTg5NjQyODY1MDFkNjhlN2QyZTZkYTkz;" Slightly reduces the number of lines in the oom
killer.";David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;mm, oom: avoid looping when chosen thread detaches its mm;David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;"oom_kill_task() returns non-zero iff the chosen process does not have any
threads with an attached ->mm";David Rientjes;2012-03-21;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;"In such a case, it's better to just return to the page allocator and retry
the allocation because memory could have been freed in the interim and the
oom condition may no longer exist";David Rientjes;2012-03-21;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;" It's unnecessary to loop in the oom
killer and find another thread to kill";David Rientjes;2012-03-21;0;1
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;"This allows both oom_kill_task() and oom_kill_process() to be converted to
void functions";David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYTFjOWIxZmMwYTBlYTJlMzBjZGViNjkwNjI2NDdjNWM1YWU2NjFm;" If the oom condition persists, the oom killer will be
recalled.";David Rientjes;2012-03-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo3MjgzNWM4NmNhMTVkMDEyNjM1NGI3M2Q1ZjI5Y2U5MTk0OTMxYzli;mm: unify remaining mem_cont, mem, etc. variable names to memcg;Johannes Weiner;2012-01-13;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MjgzNWM4NmNhMTVkMDEyNjM1NGI3M2Q1ZjI5Y2U5MTk0OTMxYzli;;Johannes Weiner;2012-01-13;0;0
MDY6Q29tbWl0MjMyNTI5ODplYzBmZmZkODRiMTYyZTA1NjNhMjhhODFhYTA0OWY5NDZiMzFhOGUy;mm: oom_kill: remove memcg argument from oom_kill_task();Johannes Weiner;2012-01-13;1;0
MDY6Q29tbWl0MjMyNTI5ODplYzBmZmZkODRiMTYyZTA1NjNhMjhhODFhYTA0OWY5NDZiMzFhOGUy;"The memcg argument of oom_kill_task() hasn't been used since 341aea2
'oom-kill: remove boost_dying_task_prio()'";Johannes Weiner;2012-01-13;0;1
MDY6Q29tbWl0MjMyNTI5ODplYzBmZmZkODRiMTYyZTA1NjNhMjhhODFhYTA0OWY5NDZiMzFhOGUy; Kill it.;Johannes Weiner;2012-01-13;1;0
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;tracepoint: add tracepoints for debugging oom_score_adj;KAMEZAWA Hiroyuki;2012-01-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;oom_score_adj is used for guarding processes from OOM-Killer;KAMEZAWA Hiroyuki;2012-01-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;" One of
problem is that it's inherited at fork()";KAMEZAWA Hiroyuki;2012-01-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;" When a daemon set oom_score_adj
and make children, it's hard to know where the value is set";KAMEZAWA Hiroyuki;2012-01-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;This patch adds some tracepoints useful for debugging;KAMEZAWA Hiroyuki;2012-01-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;"This patch adds
3 trace points";KAMEZAWA Hiroyuki;2012-01-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;"  - creating new task
  - renaming a task (exec)
  - set oom_score_adj
To debug, users need to enable some trace pointer";KAMEZAWA Hiroyuki;2012-01-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0M2QyYjExMzI0MWQ2Nzk3Yjg5MDMxODc2N2UwYWY3OGUzMTM0MTRi;"Maybe filtering is useful as
# EVENT=/sys/kernel/debug/tracing/events/task/
# EVENT=/sys/kernel/debug/tracing/events/oom/
output will be like this.";KAMEZAWA Hiroyuki;2012-01-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;oom: fix integer overflow of points in oom_badness;Frantisek Hrbata;2011-12-20;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;"An integer overflow will happen on 64bit archs if task's sum of rss,
swapents and nr_ptes exceeds (2^31)/1000 value";Frantisek Hrbata;2011-12-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;" This was introduced by
commit
f755a04 oom: use pte pages in OOM score
where the oom score computation was divided into several steps and it's no
longer computed as one expression in unsigned long(rss, swapents, nr_pte
are unsigned long), where the result value assigned to points(int) is in
range(1..1000)";Frantisek Hrbata;2011-12-20;0;0
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;" So there could be an int overflow while computing
and points may have negative value";Frantisek Hrbata;2011-12-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;"Meaning the oom score for a mem hog task
will be one";Frantisek Hrbata;2011-12-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;For example;Frantisek Hrbata;2011-12-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;"[ 3366]     0  3366 35390480 24303939   5       0             0 oom01
Out of memory: Kill process 3366 (oom01) score 1 or sacrifice child
Here the oom1 process consumes more than 24303939(rss)*4096~=92GB physical
memory, but it's oom score is one";Frantisek Hrbata;2011-12-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;"In this situation the mem hog task is skipped and oom killer kills another and
most probably innocent task with oom score greater than one";Frantisek Hrbata;2011-12-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjA1YjZmN2FlNzYyYjZlYjQ2NDE4M2VlYzk5NGIyOGVhMDlmNmRk;"The points variable should be of type long instead of int to prevent the
int overflow.";Frantisek Hrbata;2011-12-20;1;1
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;freezer: rename thaw_process() to __thaw_task() and simplify the implementation;Tejun Heo;2011-11-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;"thaw_process() now has only internal users - system and cgroup
freezers";Tejun Heo;2011-11-21;0;0
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;" Remove the unnecessary return value, rename, unexport and
collapse __thaw_process() into it";Tejun Heo;2011-11-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;" This will help further updates to
the freezer code";Tejun Heo;2011-11-21;0;1
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;"-v3: oom_kill grew a use of thaw_process() while this patch was
     pending";Tejun Heo;2011-11-21;1;1
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj; Convert it to use __thaw_task() for now;Tejun Heo;2011-11-21;1;0
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;" In the longer
     term, this should be handled by allowing tasks to die if killed
     even if it's frozen";Tejun Heo;2011-11-21;1;0
MDY6Q29tbWl0MjMyNTI5ODphNWJlMmQwZDFhODc0NmU3YmU1MjEwZTNkNmI5MDQ0NTUwMDA0NDNj;-v2: minor style update as suggested by Matt.;Tejun Heo;2011-11-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;oom: do not kill tasks with oom_score_adj OOM_SCORE_ADJ_MIN;Michal Hocko;2011-11-15;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;"Commit c9f01245 (""oom: remove oom_disable_count"") has removed the
oom_disable_count counter which has been used for early break out from
oom_badness so we could never select a task with oom_score_adj set to
OOM_SCORE_ADJ_MIN (oom disabled)";Michal Hocko;2011-11-15;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;"Now that the counter is gone we are always going through heuristics
calculation and we always return a non zero positive value";Michal Hocko;2011-11-15;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;" This means
that we can end up killing a task with OOM disabled because it is
indistinguishable from regular tasks with 1% resp";Michal Hocko;2011-11-15;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;" CAP_SYS_ADMIN tasks
with 3% usage of memory or tasks with oom_score_adj set but OOM enabled";Michal Hocko;2011-11-15;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YWVjYzg1YWJkYjlhYzJiMGU2NTQ4ZDEzNjUyYTM0MTQyZTdhZTg5;Let's break out early if the task should have OOM disabled.;Michal Hocko;2011-11-15;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;oom: fix race while temporarily setting current's oom_score_adj;David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;"test_set_oom_score_adj() was introduced in 72788c385604 (""oom: replace
PF_OOM_ORIGIN with toggling oom_score_adj"") to temporarily elevate
current's oom_score_adj for ksm and swapoff without requiring an
additional per-process flag";David Rientjes;2011-11-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;"Using that function to both set oom_score_adj to OOM_SCORE_ADJ_MAX and
then reinstate the previous value is racy since it's possible that
userspace can set the value to something else itself before the old value
is reinstated";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;" That results in userspace setting current's oom_score_adj
to a different value and then the kernel immediately setting it back to
its previous value without notification";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;"To fix this, a new compare_swap_oom_score_adj() function is introduced
with the same semantics as the compare and swap CAS instruction, or
CMPXCHG on x86";David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzM2MmE0OTc3ZTM3ZGI0NmY4NmY3ZTZhYjkzNWYwMDA2OTU2NjMy;" It is used to reinstate the previous value of
oom_score_adj if and only if the present value is the same as the old
value.";David Rientjes;2011-11-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;oom: remove oom_disable_count;David Rientjes;2011-11-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;"This removes mm->oom_disable_count entirely since it's unnecessary and
currently buggy";David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;" The counter was intended to be per-process but it's
currently decremented in the exit path for each thread that exits, causing
it to underflow";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;"The count was originally intended to prevent oom killing threads that
share memory with threads that cannot be killed since it doesn't lead to
future memory freeing";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;" The counter could be fixed to represent all
threads sharing the same mm, but it's better to remove the count since";David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpjOWYwMTI0NWI2YTdkNzdkMTdkZWFhNzFhZjEwZjZhY2ExNGZhMjRl;" - it is possible that the OOM_DISABLE thread sharing memory with the
   victim is waiting on that thread to exit and will actually cause
   future memory freeing, and
 - there is no guarantee that a thread is disabled from oom killing just
   because another thread sharing its mm is oom disabled.";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;oom: avoid killing kthreads if they assume the oom killed thread's mm;David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;"After selecting a task to kill, the oom killer iterates all processes and
kills all other threads that share the same mm_struct in different thread
groups";David Rientjes;2011-11-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;" It would not otherwise be helpful to kill a thread if its memory
would not be subsequently freed";David Rientjes;2011-11-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;"A kernel thread, however, may assume a user thread's mm by using
use_mm()";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;" This is only temporary and should not result in sending a
SIGKILL to that kthread";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YjBkNDRmYTQ5YjFkY2ZkY2Y0ODk3ZjEyZGRkMTJkZGVhYjFhOWQ3;"This patch ensures that only user threads and not kthreads are sent a
SIGKILL if they share the same mm_struct as the oom killed task.";David Rientjes;2011-11-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNjYwZGFhYzQ3NGM2ZjdjMmQ3MTAxMDBlMjliMzI3NmE2ZjRkYjBh;oom: thaw threads if oom killed thread is frozen before deferring;David Rientjes;2011-11-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNjYwZGFhYzQ3NGM2ZjdjMmQ3MTAxMDBlMjliMzI3NmE2ZjRkYjBh;"If a thread has been oom killed and is frozen, thaw it before returning to
the page allocator";David Rientjes;2011-11-01;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNjYwZGFhYzQ3NGM2ZjdjMmQ3MTAxMDBlMjliMzI3NmE2ZjRkYjBh;" Otherwise, it can stay frozen indefinitely and no
memory will be freed.";David Rientjes;2011-11-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpiOTVmMWIzMWI3NTU4ODMwNmUzMmIyYWZkMzIxNjZjYWQ0OGY2NzBi;mm: Map most files to use export.h instead of module.h;Paul Gortmaker;2011-10-16;1;0
MDY6Q29tbWl0MjMyNTI5ODpiOTVmMWIzMWI3NTU4ODMwNmUzMmIyYWZkMzIxNjZjYWQ0OGY2NzBi;"The files changed within are only using the EXPORT_SYMBOL
macro variants";Paul Gortmaker;2011-10-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpiOTVmMWIzMWI3NTU4ODMwNmUzMmIyYWZkMzIxNjZjYWQ0OGY2NzBi;" They are not using core modular infrastructure
and hence don't need module.h but only the export.h header.";Paul Gortmaker;2011-10-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMDI3YTQ3NGE2ODA2NTM5MWM4NzczZjZlODNlZDU0MTI2NTdlMzY5;oom: task->mm == NULL doesn't mean the memory was freed;Oleg Nesterov;2011-07-30;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMDI3YTQ3NGE2ODA2NTM5MWM4NzczZjZlODNlZDU0MTI2NTdlMzY5;"exit_mm() sets ->mm == NULL then it does mmput()->exit_mmap() which
frees the memory";Oleg Nesterov;2011-07-30;0;0
MDY6Q29tbWl0MjMyNTI5ODpjMDI3YTQ3NGE2ODA2NTM5MWM4NzczZjZlODNlZDU0MTI2NTdlMzY5;"However select_bad_process() checks ->mm != NULL before TIF_MEMDIE,
so it continues to kill other tasks even if we have the oom-killed
task freeing its memory";Oleg Nesterov;2011-07-30;0;1
MDY6Q29tbWl0MjMyNTI5ODpjMDI3YTQ3NGE2ODA2NTM5MWM4NzczZjZlODNlZDU0MTI2NTdlMzY5;"Change select_bad_process() to check ->mm after TIF_MEMDIE, but skip
the tasks which have already passed exit_notify() to ensure a zombie
with TIF_MEMDIE set can't block oom-killer";Oleg Nesterov;2011-07-30;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMDI3YTQ3NGE2ODA2NTM5MWM4NzczZjZlODNlZDU0MTI2NTdlMzY5;"Alternatively we could
probably clear TIF_MEMDIE after exit_mmap().";Oleg Nesterov;2011-07-30;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMTIzOTgzNmMwNGI1MGJhODQ1M2VjNThjYTdhN2JkNzE2ZWYwMmMx;oom: remove references to old badness() function;David Rientjes;2011-07-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoxMTIzOTgzNmMwNGI1MGJhODQ1M2VjNThjYTdhN2JkNzE2ZWYwMmMx;"The badness() function in the oom killer was renamed to oom_badness() in
a63d83f427fb (""oom: badness heuristic rewrite"") since it is a globally
exported function for clarity";David Rientjes;2011-07-26;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMTIzOTgzNmMwNGI1MGJhODQ1M2VjNThjYTdhN2JkNzE2ZWYwMmMx;"The prototype for the old function still existed in linux/oom.h, so remove
it";David Rientjes;2011-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMTIzOTgzNmMwNGI1MGJhODQ1M2VjNThjYTdhN2JkNzE2ZWYwMmMx; There are no existing users;David Rientjes;2011-07-26;0;0
MDY6Q29tbWl0MjMyNTI5ODoxMTIzOTgzNmMwNGI1MGJhODQ1M2VjNThjYTdhN2JkNzE2ZWYwMmMx;"Also fixes documentation and comment references to badness() and adjusts
them accordingly.";David Rientjes;2011-07-26;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMjExNDJlY2U0MTRjZTEwODhjZmNhZTc2MDY4OWFhNjBkNmZlZTgw;ptrace: kill task_ptrace();Tejun Heo;2011-06-17;1;0
MDY6Q29tbWl0MjMyNTI5ODpkMjExNDJlY2U0MTRjZTEwODhjZmNhZTc2MDY4OWFhNjBkNmZlZTgw;"task_ptrace(task) simply dereferences task->ptrace and isn't even used
consistently only adding confusion";Tejun Heo;2011-06-17;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMjExNDJlY2U0MTRjZTEwODhjZmNhZTc2MDY4OWFhNjBkNmZlZTgw;" Kill it and directly access
->ptrace instead";Tejun Heo;2011-06-17;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMjExNDJlY2U0MTRjZTEwODhjZmNhZTc2MDY4OWFhNjBkNmZlZTgw;This doesn't introduce any behavior change.;Tejun Heo;2011-06-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;oom: replace PF_OOM_ORIGIN with toggling oom_score_adj;David Rientjes;2011-05-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;"There's a kernel-wide shortage of per-process flags, so it's always
helpful to trim one when possible without incurring a significant penalty";David Rientjes;2011-05-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;" It's even more important when you're planning on adding a per- process
flag yourself, which I plan to do shortly for transparent hugepages";David Rientjes;2011-05-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;"PF_OOM_ORIGIN is used by ksm and swapoff to prefer current since it has a
tendency to allocate large amounts of memory and should be preferred for
killing over other tasks";David Rientjes;2011-05-25;0;0
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;" We'd rather immediately kill the task making
the errant syscall rather than penalizing an innocent task";David Rientjes;2011-05-25;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;"This patch removes PF_OOM_ORIGIN since its behavior is equivalent to
setting the process's oom_score_adj to OOM_SCORE_ADJ_MAX";David Rientjes;2011-05-25;1;1
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;"The process's old oom_score_adj is stored and then set to
OOM_SCORE_ADJ_MAX during the time it used to have PF_OOM_ORIGIN";David Rientjes;2011-05-25;1;0
MDY6Q29tbWl0MjMyNTI5ODo3Mjc4OGMzODU2MDQ1MjM0MjI1OTIyNDljMTljYmEwMTg3MDIxZTli;" The old
value is then reinstated when the process should no longer be considered a
high priority for oom killing.";David Rientjes;2011-05-25;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNzU1YTA0MmQ4MmI1MWI1NGYzYmRkMDg5MGU1ZWE1NmMwZmI2ODA3;oom: use pte pages in OOM score;KOSAKI Motohiro;2011-04-27;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNzU1YTA0MmQ4MmI1MWI1NGYzYmRkMDg5MGU1ZWE1NmMwZmI2ODA3;"PTE pages eat up memory just like anything else, but we do not account for
them in any way in the OOM scores";KOSAKI Motohiro;2011-04-27;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNzU1YTA0MmQ4MmI1MWI1NGYzYmRkMDg5MGU1ZWE1NmMwZmI2ODA3;" They are also _guaranteed_ to get
freed up when a process is OOM killed, while RSS is not.";KOSAKI Motohiro;2011-04-27;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;oom-kill: remove boost_dying_task_prio();KOSAKI Motohiro;2011-04-14;1;0
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;"This is an almost-revert of commit 93b43fa (""oom: give the dying task a
higher priority"")";KOSAKI Motohiro;2011-04-14;1;0
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;"That commit dramatically improved oom killer logic when a fork-bomb
occurs";KOSAKI Motohiro;2011-04-14;0;0
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3; But I've found that it has nasty corner case;KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;" Now cpu cgroup has
strange default RT runtime";KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;" It's 0!  That said, if a process under cpu
cgroup promote RT scheduling class, the process never run at all";KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;"If an admin inserts a !RT process into a cpu cgroup by setting
rtruntime=0, usually it runs perfectly because a !RT task isn't affected
by the rtruntime knob";KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;" But if it promotes an RT task via an explicit
setscheduler() syscall or an OOM, the task can't run at all";KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;" In short,
the oom killer doesn't work at all if admins are using cpu cgroup and don't
touch the rtruntime knob";KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;Eventually, kernel may hang up when oom kill occur;KOSAKI Motohiro;2011-04-14;0;1
MDY6Q29tbWl0MjMyNTI5ODozNDFhZWEyYmM0OGJmNjUyNzc3ZmIwMTVjYzJiM2RmYTlhNDUxODE3;" I and the original
author Luis agreed to disable this logic.";KOSAKI Motohiro;2011-04-14;1;0
MDY6Q29tbWl0MjMyNTI5ODpiMmI3NTViNWYxMGViMzJmYmRjNzNhOTkwN2MwNzAwNmIxN2Y3MTRi;lib, arch: add filter argument to show_mem and fix private implementations;David Rientjes;2011-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMmI3NTViNWYxMGViMzJmYmRjNzNhOTkwN2MwNzAwNmIxN2Y3MTRi;"Commit ddd588b5dd55 (""oom: suppress nodes that are not allowed from
meminfo on oom kill"") moved lib/show_mem.o out of lib/lib.a, which
resulted in build warnings on all architectures that implement their own
versions of show_mem()";David Rientjes;2011-03-24;0;1
MDY6Q29tbWl0MjMyNTI5ODpiMmI3NTViNWYxMGViMzJmYmRjNzNhOTkwN2MwNzAwNmIxN2Y3MTRi;	lib/lib.a(show_mem.o): In function `show_mem';David Rientjes;2011-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODpiMmI3NTViNWYxMGViMzJmYmRjNzNhOTkwN2MwNzAwNmIxN2Y3MTRi;"	show_mem.c:(.text+0x1f4): multiple definition of `show_mem'
	arch/sparc/mm/built-in.o:(.text+0xd70): first defined here
The fix is to remove __show_mem() and add its argument to show_mem() in
all implementations to prevent this breakage";David Rientjes;2011-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpiMmI3NTViNWYxMGViMzJmYmRjNzNhOTkwN2MwNzAwNmIxN2Y3MTRi;"Architectures that implement their own show_mem() actually don't do
anything with the argument yet, but they could be made to filter nodes
that aren't allowed in the current context in the future just like the
generic implementation.";David Rientjes;2011-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODpmOTQzNGFkMTU1MjQyN2ZhYjQ5MzM2ZTFhNmUzZWYxMjE4OTViOWQx;memcg: give current access to memory reserves if it's trying to die;David Rientjes;2011-03-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmOTQzNGFkMTU1MjQyN2ZhYjQ5MzM2ZTFhNmUzZWYxMjE4OTViOWQx;"When a memcg is oom and current has already received a SIGKILL, then give
it access to memory reserves with a higher scheduling priority so that it
may quickly exit and free its memory";David Rientjes;2011-03-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpmOTQzNGFkMTU1MjQyN2ZhYjQ5MzM2ZTFhNmUzZWYxMjE4OTViOWQx;"This is identical to the global oom killer and is done even before
checking for panic_on_oom: a pending SIGKILL here while panic_on_oom is
selected is guaranteed to have come from userspace; the thread only needs
access to memory reserves to exit and thus we don't unnecessarily panic
the machine until the kernel has no last resort to free memory.";David Rientjes;2011-03-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;oom: suppress nodes that are not allowed from meminfo on oom kill;David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;"The oom killer is extremely verbose for machines with a large number of
cpus and/or nodes";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;" This verbosity can often be harmful if it causes other
important messages to be scrolled from the kernel log and incurs a
signicant time delay, specifically for kernels with CONFIG_NODES_SHIFT >
This patch causes only memory information to be displayed for nodes that
are allowed by current's cpuset when dumping the VM state";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;" Information
for all other nodes is irrelevant to the oom condition; we don't care if
there's an abundance of memory elsewhere if we can't access it";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;"This only affects the behavior of dumping memory information when an oom
is triggered";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;" Other dumps, such as for sysrq+m, still display the
unfiltered form when using the existing show_mem() interface";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;"Additionally, the per-cpu pageset statistics are extremely verbose in oom
killer output, so it is now suppressed";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;" This removes
	nodes_weight(current->mems_allowed) * (1 + nr_cpus)
lines from the oom killer output";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZGQ1ODhiNWRkNTVmMTQzMjAzNzk5NjFlNDc2ODNkYjRlNGMxZDkw;"Callers may use __show_mem(SHOW_MEM_FILTER_NODES) to filter disallowed
nodes.";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;oom: avoid deferring oom killer if exiting task is being traced;David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;"The oom killer naturally defers killing anything if it finds an eligible
task that is already exiting and has yet to detach its ->mm";David Rientjes;2011-03-22;0;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;" This avoids
unnecessarily killing tasks when one is already in the exit path and may
free enough memory that the oom killer is no longer needed";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;" This is
detected by PF_EXITING since threads that have already detached its ->mm
are no longer considered at all";David Rientjes;2011-03-22;0;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;"The problem with always deferring when a thread is PF_EXITING, however, is
that it may never actually exit when being traced, specifically if another
task is tracing it with PTRACE_O_TRACEEXIT";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;" The oom killer does not want
to defer in this case since there is no guarantee that thread will ever
exit without intervention";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;"This patch will now only defer the oom killer when a thread is PF_EXITING
and no ptracer has stopped its progress in the exit path";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODplZGQ0NTU0NGM2ZjA5NTUwZGYwYTU0OTFhYThhMDdhZjI0NzY3ZTcz;" It also ensures
that a child is sacrificed for the chosen parent only if it has a
different ->mm as the comment implies: this ensures that the thread group
leader is always targeted appropriately.";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozMGUyYjQxZjIwYjYyMzhmNTFlN2NmZmI4NzljN2EwZjAwNzNmNWZl;oom: skip zombies when iterating tasklist;Andrey Vagin;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozMGUyYjQxZjIwYjYyMzhmNTFlN2NmZmI4NzljN2EwZjAwNzNmNWZl;"We shouldn't defer oom killing if a thread has already detached its ->mm
and still has TIF_MEMDIE set";Andrey Vagin;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozMGUyYjQxZjIwYjYyMzhmNTFlN2NmZmI4NzljN2EwZjAwNzNmNWZl;" Memory needs to be freed, so find kill
other threads that pin the same ->mm or find another task to kill.";Andrey Vagin;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;oom: prevent unnecessary oom kills or kernel panics;David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"This patch prevents unnecessary oom kills or kernel panics by reverting
two commits";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"	495789a5 (oom: make oom_score to per-process value)
	cef1d352 (oom: multi threaded process coredump don't make deadlock)
First, 495789a5 (oom: make oom_score to per-process value) ignores the
fact that all threads in a thread group do not necessarily exit at the
same time";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"It is imperative that select_bad_process() detect threads that are in the
exit path, specifically those with PF_EXITING set, to prevent needlessly
killing additional tasks";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;" If a process is oom killed and the thread group
leader exits, select_bad_process() cannot detect the other threads that
are PF_EXITING by iterating over only processes";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;" Thus, it currently
chooses another task unnecessarily for oom kill or panics the machine when
nothing else is eligible";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"By iterating over threads instead, it is possible to detect threads that
are exiting and nominate them for oom kill so they get access to memory
reserves";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"Second, cef1d352 (oom: multi threaded process coredump don't make
deadlock) erroneously avoids making the oom killer a no-op when an
eligible thread other than current isfound to be exiting";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;" We want to
detect this situation so that we may allow that exiting thread time to
exit and free its memory; if it is able to exit on its own, that should
free memory so current is no loner oom";David Rientjes;2011-03-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;" If it is not able to exit on its
own, the oom killer will nominate it for oom kill which, in this case,
only means it will get access to memory reserves";David Rientjes;2011-03-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozYTVkZGE3YTE3Y2YzNzA2Zjc5Yjg2MjkzZjI5ZGIwMmQ2MWUwZDQ4;"Without this change, it is easy for the oom killer to unnecessarily target
tasks when all threads of a victim don't exit before the thread group
leader or, in the worst case, panic the machine.";David Rientjes;2011-03-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MmQzYzAzNjc1ZmRiZTE5NjViOWIxOTA5MDcyYjQwYWQyZjgwMDYz;"Revert ""oom: oom_kill_process: fix the child_points logic""";Linus Torvalds;2011-03-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MmQzYzAzNjc1ZmRiZTE5NjViOWIxOTA5MDcyYjQwYWQyZjgwMDYz;This reverts the parent commit;Linus Torvalds;2011-03-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1MmQzYzAzNjc1ZmRiZTE5NjViOWIxOTA5MDcyYjQwYWQyZjgwMDYz;" I hate doing that, but it's generating
some discussion (""half of it is right""), and since I am planning on
doing the 2.6.38 release later today we can punt it to stable if
required";Linus Torvalds;2011-03-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MmQzYzAzNjc1ZmRiZTE5NjViOWIxOTA5MDcyYjQwYWQyZjgwMDYz;Let's not rock the boat right now.;Linus Torvalds;2011-03-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;oom: oom_kill_process: fix the child_points logic;Oleg Nesterov;2011-03-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;oom_kill_process() starts with victim_points == 0;Oleg Nesterov;2011-03-14;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;" This means that
(most likely) any child has more points and can be killed erroneously";Oleg Nesterov;2011-03-14;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;"Also, ""children has a different mm"" doesn't match the reality, we should
check child->mm != t->mm";Oleg Nesterov;2011-03-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;" This check is not exactly correct if t->mm ==
NULL but this doesn't really matter, oom_kill_task() will kill them
anyway";Oleg Nesterov;2011-03-14;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYzFiODNhYjA4ZjE5NTQzMzU2OTJjZGNkNDk5Zjc4Yzk0ZjRjNDJh;"Note: ""Kill all processes sharing p->mm"" in oom_kill_task() is wrong
too.";Oleg Nesterov;2011-03-14;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;oom: kill all threads sharing oom killed task's mm;David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"It's necessary to kill all threads that share an oom killed task's mm if
the goal is to lead to future memory freeing";David Rientjes;2010-10-26;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"This patch reintroduces the code removed in 8c5cd6f3 (oom: oom_kill
doesn't kill vfork parent (or child)) since it is obsoleted";David Rientjes;2010-10-26;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"It's now guaranteed that any task passed to oom_kill_task() does not share
an mm with any thread that is unkillable";David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;" Thus, we're safe to issue a
SIGKILL to any thread sharing the same mm";David Rientjes;2010-10-26;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"This is especially necessary to solve an mm->mmap_sem livelock issue
whereas an oom killed thread must acquire the lock in the exit path while
another thread is holding it in the page allocator while trying to
allocate memory itself (and will preempt the oom killer since a task was
already killed)";David Rientjes;2010-10-26;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;" Since tasks with pending fatal signals are now granted
access to memory reserves, the thread holding the lock may quickly
allocate and release the lock so that the oom killed task may exit";David Rientjes;2010-10-26;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"This mainly is for threads that are cloned with CLONE_VM but not
CLONE_THREAD, so they are in a different thread group";David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;" Non-NPTL threads
exist in the wild and this change is necessary to prevent the livelock in
such cases";David Rientjes;2010-10-26;0;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;" We care more about preventing the livelock than incurring the
additional tasklist in the oom killer when a task has been killed";David Rientjes;2010-10-26;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"Systems that are sufficiently large to not want the tasklist scan in the
oom killer in the first place already have the option of enabling
/proc/sys/vm/oom_kill_allocating_task, which was designed specifically for
that purpose";David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZTk5YmFkMGQ5YzEyYTRhYWE2MGNkODEyYzg0ZWYxNTI1NjRiY2Y1;"This code had existed in the oom killer for over eight years dating back
to the 2.4 kernel.";David Rientjes;2010-10-26;0;0
MDY6Q29tbWl0MjMyNTI5ODplMTg2NDFlMTlhOTIwNGYyNDFmMDRhNWFjNzAwMTY4ZGNkMThkZTRm;oom: avoid killing a task if a thread sharing its mm cannot be killed;David Rientjes;2010-10-26;1;1
MDY6Q29tbWl0MjMyNTI5ODplMTg2NDFlMTlhOTIwNGYyNDFmMDRhNWFjNzAwMTY4ZGNkMThkZTRm;"The oom killer's goal is to kill a memory-hogging task so that it may
exit, free its memory, and allow the current context to allocate the
memory that triggered it in the first place";David Rientjes;2010-10-26;0;0
MDY6Q29tbWl0MjMyNTI5ODplMTg2NDFlMTlhOTIwNGYyNDFmMDRhNWFjNzAwMTY4ZGNkMThkZTRm;" Thus, killing a task is
pointless if other threads sharing its mm cannot be killed because of its
/proc/pid/oom_adj or /proc/pid/oom_score_adj value";David Rientjes;2010-10-26;0;1
MDY6Q29tbWl0MjMyNTI5ODplMTg2NDFlMTlhOTIwNGYyNDFmMDRhNWFjNzAwMTY4ZGNkMThkZTRm;"This patch checks whether any other thread sharing p->mm has an
oom_score_adj of OOM_SCORE_ADJ_MIN";David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODplMTg2NDFlMTlhOTIwNGYyNDFmMDRhNWFjNzAwMTY4ZGNkMThkZTRm;" If so, the thread cannot be killed
and oom_badness(p) returns 0, meaning it's unkillable.";David Rientjes;2010-10-26;1;0
MDY6Q29tbWl0MjMyNTI5ODplODViZmQzYWE3YTM0ZmE5NjNiYjI2OGE2NzZiNDE2OTRlNmRjZjk2;oom: filter unkillable tasks from tasklist dump;David Rientjes;2010-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODplODViZmQzYWE3YTM0ZmE5NjNiYjI2OGE2NzZiNDE2OTRlNmRjZjk2;"/proc/sys/vm/oom_dump_tasks is enabled by default, so it's necessary to
limit as much information as possible that it should emit";David Rientjes;2010-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODplODViZmQzYWE3YTM0ZmE5NjNiYjI2OGE2NzZiNDE2OTRlNmRjZjk2;"The tasklist dump should be filtered to only those tasks that are eligible
for oom kill";David Rientjes;2010-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODplODViZmQzYWE3YTM0ZmE5NjNiYjI2OGE2NzZiNDE2OTRlNmRjZjk2;" This is already done for memcg ooms, but this patch extends
it to both cpuset and mempolicy ooms as well as init";David Rientjes;2010-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODplODViZmQzYWE3YTM0ZmE5NjNiYjI2OGE2NzZiNDE2OTRlNmRjZjk2;"In addition to suppressing irrelevant information, this also reduces
confusion since users currently don't know which tasks in the tasklist
aren't eligible for kill (such as those attached to cpusets or bound to
mempolicies with a disjoint set of mems or nodes, respectively) since that
information is not shown.";David Rientjes;2010-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;oom: always return a badness score of non-zero for eligible tasks;David Rientjes;2010-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;"A task's badness score is roughly a proportion of its rss and swap
compared to the system's capacity";David Rientjes;2010-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;" The scale ranges from 0 to 1000 with
the highest score chosen for kill";David Rientjes;2010-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;" Thus, this scale operates on a
resolution of 0.1% of RAM + swap";David Rientjes;2010-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;" Admin tasks are also given a 3% bonus,
so the badness score of an admin task using 3% of memory, for example,
would still be 0";David Rientjes;2010-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;"It's possible that an exceptionally large number of tasks will combine to
exhaust all resources but never have a single task that uses more than
0.1% of RAM and swap (or 3.0% for admin tasks)";David Rientjes;2010-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODpmMTllOGFhMTFhZmEyNDAzNmM2MjczNDI4ZGE1MTk0OWI1YWNmMzBj;"This patch ensures that the badness score of any eligible task is never 0
so the machine doesn't unnecessarily panic because it cannot find a task
to kill.";David Rientjes;2010-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;oom: __task_cred() need rcu_read_lock();KOSAKI Motohiro;2010-08-19;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;"dump_tasks() needs to hold the RCU read lock around its access of the
target task's UID";KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;" To this end it should use task_uid() as it only needs
that one thing from the creds";KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;"The fact that dump_tasks() holds tasklist_lock is insufficient to prevent the
target process replacing its credentials on another CPU";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;Then, this patch change to call rcu_read_lock() explicitly;KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;	[ INFO: suspicious rcu_dereference_check() usage;KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;"]
	mm/oom_kill.c:410 invoked rcu_dereference_check() without protection!
	other info that might help us debug this";KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;"	rcu_scheduler_active = 1, debug_locks = 1
	4 locks held by kworker/1:2/651";KOSAKI Motohiro;2010-08-19;1;0
MDY6Q29tbWl0MjMyNTI5ODo4ZDZjODNmMGJhNWUxYmQxZThiYjJlM2M3ZGU0YzI3NmRjMjQ3Zjk5;"	process_one_work+0x137/0x4a0
	process_one_work+0x137/0x4a0
	out_of_memory+0x164/0x3f0
	find_lock_task_mm+0x2e/0x70";KOSAKI Motohiro;2010-08-19;0;0
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;oom: fix tasklist_lock leak;KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;"Commit 0aad4b3124 (""oom: fold __out_of_memory into out_of_memory"")
introduced a tasklist_lock leak";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;" Then it caused following obvious
danger warnings and panic";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;"    [ BUG: lock held when returning to user space! ]
    rsyslogd/1422 is leaving the kernel with locks still held!
    1 lock held by rsyslogd/1422";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;"    BUG: scheduling while atomic: rsyslogd/1422/0x00000002
    INFO: lockdep is turned off";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNTI3MjNjNTYwN2Y3Njg0YzJjMGMwNzVmODZmODZkYTBkN2ZiNmQw;This patch fixes it.;KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiZTcxY2YyMjAyOTcxZTUwY2U0OTUzZDQ3MzY0OWM3MjQ3OTllYjhh;oom: fix NULL pointer dereference;KOSAKI Motohiro;2010-08-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiZTcxY2YyMjAyOTcxZTUwY2U0OTUzZDQ3MzY0OWM3MjQ3OTllYjhh;"Commit b940fd7035 (""oom: remove unnecessary code and cleanup"") added an
unnecessary NULL pointer dereference";KOSAKI Motohiro;2010-08-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiZTcxY2YyMjAyOTcxZTUwY2U0OTUzZDQ3MzY0OWM3MjQ3OTllYjhh; remove it.;KOSAKI Motohiro;2010-08-19;1;0
MDY6Q29tbWl0MjMyNTI5ODoxNThlMGEyZDFiM2NmZmVkOGI0NmNiYzU2MzkzYTEzOTQ2NzJlZjc5;memcg: use find_lock_task_mm() in memory cgroups oom;KAMEZAWA Hiroyuki;2010-08-11;1;0
MDY6Q29tbWl0MjMyNTI5ODoxNThlMGEyZDFiM2NmZmVkOGI0NmNiYzU2MzkzYTEzOTQ2NzJlZjc5;"When the OOM killer scans task, it check a task is under memcg or
not when it's called via memcg's context";KAMEZAWA Hiroyuki;2010-08-11;0;0
MDY6Q29tbWl0MjMyNTI5ODoxNThlMGEyZDFiM2NmZmVkOGI0NmNiYzU2MzkzYTEzOTQ2NzJlZjc5;"But, as Oleg pointed out, a thread group leader may have NULL ->mm
and task_in_mem_cgroup() may do wrong decision";KAMEZAWA Hiroyuki;2010-08-11;0;1
MDY6Q29tbWl0MjMyNTI5ODoxNThlMGEyZDFiM2NmZmVkOGI0NmNiYzU2MzkzYTEzOTQ2NzJlZjc5;"We have to use
find_lock_task_mm() in memcg as generic OOM-Killer does.";KAMEZAWA Hiroyuki;2010-08-11;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;oom: badness heuristic rewrite;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"This a complete rewrite of the oom killer's badness() heuristic which is
used to determine which task to kill in oom conditions";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" The goal is to
make it as simple and predictable as possible so the results are better
understood and we end up killing the task which will lead to the most
memory freeing while still respecting the fine-tuning from userspace";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"Instead of basing the heuristic on mm->total_vm for each task, the task's
rss and swap space is used instead";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" This is a better indication of the
amount of memory that will be freeable if the oom killed task is chosen
and subsequently exits";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" This helps specifically in cases where KDE or
GNOME is chosen for oom kill on desktop systems instead of a memory
hogging task";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"The baseline for the heuristic is a proportion of memory that each task is
currently using in memory plus swap compared to the amount of ""allowable""
memory";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" ""Allowable,"" in this sense, means the system-wide resources for
unconstrained oom conditions, the set of mempolicy nodes, the mems
attached to current's cpuset, or a memory controller's limit";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" The
proportion is given on a scale of 0 (never kill) to 1000 (always kill),
roughly meaning that if a task has a badness() score of 500 that the task
consumes approximately 50% of allowable memory resident in RAM or in swap
space";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"The proportion is always relative to the amount of ""allowable"" memory and
not the total amount of RAM systemwide so that mempolicies and cpusets may
operate in isolation; they shall not need to know the true size of the
machine on which they are running if they are bound to a specific set of
nodes or mems, respectively";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"Root tasks are given 3% extra memory just like __vm_enough_memory()
provides in LSMs";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" In the event of two tasks consuming similar amounts of
memory, it is generally better to save root's task";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"Because of the change in the badness() heuristic's baseline, it is also
necessary to introduce a new user interface to tune it";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" It's not possible
to redefine the meaning of /proc/pid/oom_adj with a new scale since the
ABI cannot be changed for backward compatability";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" Instead, a new tunable,
/proc/pid/oom_score_adj, is added that ranges from -1000 to +1000";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" It may
be used to polarize the heuristic such that certain tasks are never
considered for oom kill while others may always be considered";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" The value
is added directly into the badness() score so a value of -500, for
example, means to discount 50% of its memory consumption in comparison to
other tasks either on the system, bound to the mempolicy, in the cpuset,
or sharing the same memory controller";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;"/proc/pid/oom_adj is changed so that its meaning is rescaled into the
units used by /proc/pid/oom_score_adj, and vice versa";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" Changing one of
these per-task tunables will rescale the value of the other to an
equivalent meaning";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" Although /proc/pid/oom_adj was originally defined as
a bitshift on the badness score, it now shares the same linear growth as
/proc/pid/oom_score_adj but with different granularity";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjNkODNmNDI3ZmJjZTk3YTZjZWEwZGIyZTY0YjBlYjg0MzVjZDEw;" This is required
so the ABI is not broken with userspace applications and allows oom_adj to
be deprecated for future removal.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;oom: multi threaded process coredump don't make deadlock;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;Oleg pointed out current PF_EXITING check is wrong;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;"Because PF_EXITING
is per-thread flag, not per-process flag";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;"He said,
   Two threads, group-leader L and its sub-thread T";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;T dumps the code;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;   In this case both threads have ->mm != NULL, L has PF_EXITING;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;"   The first problem is, select_bad_process() always return -1 in this
   case (even if the caller is T, this doesn't matter)";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;   The second problem is that we should add TIF_MEMDIE to T, not L;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;I think we can remove this dubious PF_EXITING check;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjZWYxZDM1MjNkMzNlYmMzNWZjMjllNDU0YjFmNGJhYjk1M2ZhYmJm;"but as first step,
This patch add the protection of multi threaded issue.";KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;oom: give the dying task a higher priority;Luis Claudio R. Goncalves;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;"In a system under heavy load it was observed that even after the
oom-killer selects a task to die, the task may take a long time to die";Luis Claudio R. Goncalves;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;"Right after sending a SIGKILL to the task selected by the oom-killer this
task has its priority increased so that it can exit() soon, freeing
memory";Luis Claudio R. Goncalves;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy; That is accomplished by;Luis Claudio R. Goncalves;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;"It sounds plausible giving the dying task an even higher priority to be
sure it will be scheduled sooner and free the desired memory";Luis Claudio R. Goncalves;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;" It was
suggested on LKML using SCHED_FIFO:1, the lowest RT priority so that this
task won't interfere with any running RT task";Luis Claudio R. Goncalves;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;If the dying task is already an RT task, leave it untouched;Luis Claudio R. Goncalves;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo5M2I0M2ZhNTUwODhmZTk3NzUwM2ExNTZkMTA5N2NjMjA1NTQ0OWEy;" Another good
suggestion, implemented here, was to avoid boosting the dying task
priority in case of mem_cgroup OOM.";Luis Claudio R. Goncalves;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxOWI0NTg2Y2Q5YzhlZDY0Mjc5ODkwMmU1NWM2ZjYxZWQ1NzZhZDkz;oom: remove child->mm check from oom_kill_process();KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxOWI0NTg2Y2Q5YzhlZDY0Mjc5ODkwMmU1NWM2ZjYxZWQ1NzZhZDkz;"The current ""child->mm == p->mm"" check prevents selection of vfork()ed
task";KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxOWI0NTg2Y2Q5YzhlZDY0Mjc5ODkwMmU1NWM2ZjYxZWQ1NzZhZDkz; But we don't have any reason to don't consider vfork();KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxOWI0NTg2Y2Q5YzhlZDY0Mjc5ODkwMmU1NWM2ZjYxZWQ1NzZhZDkz;Removed.;KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZjEwOTBhOGRkYTQwYjZlMTFkOGNkMDllOGZjOTAwY2ZlOTEzYjM4;oom: cleanup has_intersects_mems_allowed();KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZjEwOTBhOGRkYTQwYjZlMTFkOGNkMDllOGZjOTAwY2ZlOTEzYjM4;"presently has_intersects_mems_allowed() has own thread iterate logic, but
it should use while_each_thread()";KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZjEwOTBhOGRkYTQwYjZlMTFkOGNkMDllOGZjOTAwY2ZlOTEzYjM4;It slightly improve the code readability.;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphOTZjZmQ2ZTkxNzZhZDQ0MjIzMzAwMWI3ZDE1ZTllZDQyMjM0MzIw;oom: move OOM_DISABLE check from oom_kill_task to out_of_memory();KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphOTZjZmQ2ZTkxNzZhZDQ0MjIzMzAwMWI3ZDE1ZTllZDQyMjM0MzIw;"Presently if oom_kill_allocating_task is enabled and current have
OOM_DISABLED, following printk in oom_kill_process is called twice";KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODphOTZjZmQ2ZTkxNzZhZDQ0MjIzMzAwMWI3ZDE1ZTllZDQyMjM0MzIw;"    pr_err(""%s: Kill process %d (%s) score %lu or sacrifice child\n"",
So, OOM_DISABLE check should be more early.";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoxMTNlMjdmMzZkZmY5ODk1MDQ5ZGYzMjRmMjkyNDc0ODU0NzUwZDIx;oom: kill duplicate OOM_DISABLE check;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxMTNlMjdmMzZkZmY5ODk1MDQ5ZGYzMjRmMjkyNDc0ODU0NzUwZDIx;select_bad_process() and badness() have the same OOM_DISABLE check;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoxMTNlMjdmMzZkZmY5ODk1MDQ5ZGYzMjRmMjkyNDc0ODU0NzUwZDIx;" This
patch kills one.";KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;oom: /proc/<pid>/oom_score treat kernel thread honestly;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;If a kernel thread is using use_mm(), badness() returns a positive value;KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;This is not a big issue because caller take care of it correctly;KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;" But
there is one exception, /proc/<pid>/oom_score calls badness() directly and
doesn't care that the task is a regular process";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;Another example, /proc/1/oom_score return !0 value;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy; But it's unkillable;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;This incorrectness makes administration a little confusing;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODoyNmViYzk4NDkxM2I2YThkODZkNzI0YjNhNzlkMmVkNGVkNTc0NjEy;This patch fixes it.;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpmODhjY2FkNTg4NmQ1YTg2NGI4YjBkNDhjNjY2ZWU5OTk4ZGVjNTNm;oom: oom_kill_process() needs to check that p is unkillable;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpmODhjY2FkNTg4NmQ1YTg2NGI4YjBkNDhjNjY2ZWU5OTk4ZGVjNTNm;"When oom_kill_allocating_task is enabled, an argument task of
oom_kill_process is not selected by select_bad_process(), It's just
out_of_memory() caller task";KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpmODhjY2FkNTg4NmQ1YTg2NGI4YjBkNDhjNjY2ZWU5OTk4ZGVjNTNm; It mean the task can be unkillable;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpmODhjY2FkNTg4NmQ1YTg2NGI4YjBkNDhjNjY2ZWU5OTk4ZGVjNTNm;" check
it first.";KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODphYjI5MGFkYmFmOGY0Njc3MGYwMTRlYTg3OTY4ZGU1YmFjYTI5YzMw;oom: make oom_unkillable_task() helper function;KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphYjI5MGFkYmFmOGY0Njc3MGYwMTRlYTg3OTY4ZGU1YmFjYTI5YzMw;Presently we have the same task check in two places;KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODphYjI5MGFkYmFmOGY0Njc3MGYwMTRlYTg3OTY4ZGU1YmFjYTI5YzMw;Unify it.;KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYzVlYTUzY2U0NmViYjIzMmUwZDlhNDc1ZmRkMmIxNjZkMmE1MTZi;oom: oom_kill_process() doesn't select kthread child;KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYzVlYTUzY2U0NmViYjIzMmUwZDlhNDc1ZmRkMmIxNjZkMmE1MTZi;"Presently select_bad_process() has a PF_KTHREAD check, but
oom_kill_process doesn't";KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYzVlYTUzY2U0NmViYjIzMmUwZDlhNDc1ZmRkMmIxNjZkMmE1MTZi;" It mean oom_kill_process() may choose wrong
task, especially, when the child are using use_mm().";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YzU5YWVjODMwYzdlZDZjNzQ1YmQ1MTM5ODJjZWUzNTYzZWQyMGMx;oom: don't try to kill oom_unkillable child;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YzU5YWVjODMwYzdlZDZjNzQ1YmQ1MTM5ODJjZWUzNTYzZWQyMGMx;Presently, badness() doesn't care about either CPUSET nor mempolicy;KOSAKI Motohiro;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YzU5YWVjODMwYzdlZDZjNzQ1YmQ1MTM5ODJjZWUzNTYzZWQyMGMx;" Then
if the victim child process have disjoint nodemask, OOM Killer might kill
innocent process";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo3YzU5YWVjODMwYzdlZDZjNzQ1YmQ1MTM5ODJjZWUzNTYzZWQyMGMx;This patch fixes it.;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODowYWFkNGIzMTI0ODUwZTg1ZmU1NGU2MTA4MDJmMDkxN2NlNDZhMWFl;oom: fold __out_of_memory into out_of_memory;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODowYWFkNGIzMTI0ODUwZTg1ZmU1NGU2MTA4MDJmMDkxN2NlNDZhMWFl;"__out_of_memory() only has a single caller, so fold it into
out_of_memory() and add a comment about locking for its call to
oom_kill_process().";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDQyMDAzMjBiMTBjNzYwMDMxMDFkZWUyMWM1Zjk2MWU4MGZhZjBi;oom: remove constraint argument from select_bad_process and __out_of_memory;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNDQyMDAzMjBiMTBjNzYwMDMxMDFkZWUyMWM1Zjk2MWU4MGZhZjBi;"select_bad_process() and __out_of_memory() doe not need their enum
oom_constraint arguments: it's possible to pass a NULL nodemask if
constraint == CONSTRAINT_MEMORY_POLICY in the caller, out_of_memory().";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjMyMWZlYWMyMjMxM2NmNTNmZmNlYjY5MjI0YjA5YWMxOWZmMjJi;mm: rename try_set_zone_oom() to try_set_zonelist_oom();Minchan Kim;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZjMyMWZlYWMyMjMxM2NmNTNmZmNlYjY5MjI0YjA5YWMxOWZmMjJi;We have been used naming try_set_zone_oom and clear_zonelist_oom;Minchan Kim;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjMyMWZlYWMyMjMxM2NmNTNmZmNlYjY5MjI0YjA5YWMxOWZmMjJi;"The role of functions is to lock of zonelist for preventing parallel
OOM";Minchan Kim;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpmZjMyMWZlYWMyMjMxM2NmNTNmZmNlYjY5MjI0YjA5YWMxOWZmMjJi;"So clear_zonelist_oom makes sense but try_set_zone_oome is rather
awkward and unmatched with clear_zonelist_oom";Minchan Kim;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZjMyMWZlYWMyMjMxM2NmNTNmZmNlYjY5MjI0YjA5YWMxOWZmMjJi;Let's change it with try_set_zonelist_oom.;Minchan Kim;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpiOTQwZmQ3MDM1NzJmN2Y5ZTVmODk0YzY4MmM5MWMzY2JkODRjMTFl;oom: remove unnecessary code and cleanup;David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpiOTQwZmQ3MDM1NzJmN2Y5ZTVmODk0YzY4MmM5MWMzY2JkODRjMTFl;Remove the redundancy in __oom_kill_task() since;David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpiOTQwZmQ3MDM1NzJmN2Y5ZTVmODk0YzY4MmM5MWMzY2JkODRjMTFl;" - init can never be passed to this function: it will never be PF_EXITING
   or selectable from select_bad_process(), and
 - it will never be passed a task from oom_kill_task() without an ->mm
   and we're unconcerned about detachment from exiting tasks, there's no
   reason to protect them against SIGKILL or access to memory reserves";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpiOTQwZmQ3MDM1NzJmN2Y5ZTVmODk0YzY4MmM5MWMzY2JkODRjMTFl;"Also moves the kernel log message to a higher level since the verbosity is
not always emitted here; we need not print an error message if an exiting
task is given a longer timeslice";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpiOTQwZmQ3MDM1NzJmN2Y5ZTVmODk0YzY4MmM5MWMzY2JkODRjMTFl;"__oom_kill_task() only has a single caller, so it can be merged into that
function at the same time.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODplMzY1ODkzMjM2Y2E3OGZhMWZlMjQ4MmNjYmRjMzBlOWFiZGU2MDI3;oom: remove special handling for pagefault ooms;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODplMzY1ODkzMjM2Y2E3OGZhMWZlMjQ4MmNjYmRjMzBlOWFiZGU2MDI3;"It is possible to remove the special pagefault oom handler by simply oom
locking all system zones and then calling directly into out_of_memory()";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODplMzY1ODkzMjM2Y2E3OGZhMWZlMjQ4MmNjYmRjMzBlOWFiZGU2MDI3;"All populated zones must have ZONE_OOM_LOCKED set, otherwise there is a
parallel oom killing in progress that will lead to eventual memory freeing
so it's not necessary to needlessly kill another task";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODplMzY1ODkzMjM2Y2E3OGZhMWZlMjQ4MmNjYmRjMzBlOWFiZGU2MDI3;" The context in
which the pagefault is allocating memory is unknown to the oom killer, so
this is done on a system-wide level";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODplMzY1ODkzMjM2Y2E3OGZhMWZlMjQ4MmNjYmRjMzBlOWFiZGU2MDI3;"If a task has already been oom killed and hasn't fully exited yet, this
will be a no-op since select_bad_process() recognizes tasks across the
system with TIF_MEMDIE set.";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODozMDllZDg4MjUwOGNjNDcxMzIwZmY3OTI2NWU3MzQwNzc0ZDY3NDZj;oom: extract panic helper function;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODozMDllZDg4MjUwOGNjNDcxMzIwZmY3OTI2NWU3MzQwNzc0ZDY3NDZj;"There are various points in the oom killer where the kernel must determine
whether to panic or not";David Rientjes;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODozMDllZDg4MjUwOGNjNDcxMzIwZmY3OTI2NWU3MzQwNzc0ZDY3NDZj;" It's better to extract this to a helper function
to remove all the confusion as to its semantics";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODozMDllZDg4MjUwOGNjNDcxMzIwZmY3OTI2NWU3MzQwNzc0ZDY3NDZj;"Also fix a call to dump_header() where tasklist_lock is not read- locked,
as required";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODozMDllZDg4MjUwOGNjNDcxMzIwZmY3OTI2NWU3MzQwNzc0ZDY3NDZj;There's no functional change with this patch.;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphZDkxNWM0MzJlY2NiNDgyNDI3YzFiYmQ3N2M3NGU2ZjdiZmU2MGIz;oom: enable oom tasklist dump by default;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODphZDkxNWM0MzJlY2NiNDgyNDI3YzFiYmQ3N2M3NGU2ZjdiZmU2MGIz;"The oom killer tasklist dump, enabled with the oom_dump_tasks sysctl, is
very helpful information in diagnosing why a user's task has been killed";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODphZDkxNWM0MzJlY2NiNDgyNDI3YzFiYmQ3N2M3NGU2ZjdiZmU2MGIz;"It emits useful information such as each eligible thread's memory usage
that can determine why the system is oom, so it should be enabled by
default.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjQ4ZDBlYmQ5MDdhZTQxOTM4N2YyN2I2MDJlZTk4ODcwY2ZhN2Ji;oom: select task from tasklist for mempolicy ooms;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjQ4ZDBlYmQ5MDdhZTQxOTM4N2YyN2I2MDJlZTk4ODcwY2ZhN2Ji;"The oom killer presently kills current whenever there is no more memory
free or reclaimable on its mempolicy's nodes";David Rientjes;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjQ4ZDBlYmQ5MDdhZTQxOTM4N2YyN2I2MDJlZTk4ODcwY2ZhN2Ji;" There is no guarantee that
current is a memory-hogging task or that killing it will free any
substantial amount of memory, however";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZjQ4ZDBlYmQ5MDdhZTQxOTM4N2YyN2I2MDJlZTk4ODcwY2ZhN2Ji;"In such situations, it is better to scan the tasklist for nodes that are
allowed to allocate on current's set of nodes and kill the task with the
highest badness() score";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZjQ4ZDBlYmQ5MDdhZTQxOTM4N2YyN2I2MDJlZTk4ODcwY2ZhN2Ji;" This ensures that the most memory-hogging task,
or the one configured by the user with /proc/pid/oom_adj, is always
selected in such scenarios.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;oom: sacrifice child with highest badness score for parent;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;"When a task is chosen for oom kill, the oom killer first attempts to
sacrifice a child not sharing its parent's memory instead";David Rientjes;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" Unfortunately,
this often kills in a seemingly random fashion based on the ordering of
the selected task's child list";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" Additionally, it is not guaranteed at all
to free a large amount of memory that we need to prevent additional oom
killing in the very near future";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;"Instead, we now only attempt to sacrifice the worst child not sharing its
parent's memory, if one exists";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" The worst child is indicated with the
highest badness() score";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" This serves two advantages: we kill a
memory-hogging task more often, and we allow the configurable
/proc/pid/oom_adj value to be considered as a factor in which child to
kill";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;"Reviewers may observe that the previous implementation would iterate
through the children and attempt to kill each until one was successful and
then the parent if none were found while the new code simply kills the
most memory-hogging task or the parent";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" Note that the only time
oom_kill_task() fails, however, is when a child does not have an mm or has
a /proc/pid/oom_adj of OOM_DISABLE";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo1ZTlkODM0YTBlMGMwNDg1ZGZhNDg3MjgxYWI5NjUwZmMzN2EzYmI1;" badness() returns 0 for both cases,
so the final oom_kill_task() will always succeed.";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx;oom: filter tasks not sharing the same cpuset;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx;"Tasks that do not share the same set of allowed nodes with the task that
triggered the oom should not be considered as candidates for oom kill";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx;"Tasks in other cpusets with a disjoint set of mems would be unfairly
penalized otherwise because of oom conditions elsewhere; an extreme
example could unfairly kill all other applications on the system if a
single task in a user's cpuset sets itself to OOM_DISABLE and then uses
more memory than allowed";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx;"Killing tasks outside of current's cpuset rarely would free memory for
current anyway";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx;" To use a sane heuristic, we must ensure that killing a
task would likely free memory for current and avoid needlessly killing
others at all costs just because their potential memory freeing is
unknown";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo2Y2Y4NmFjNmYzNmI2Mzg0NTlhOWE2YzI1NzZkNWU2NTVkNDFkNDUx; It is better to kill current than another task needlessly.;David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzU4OTk3YWUzOGExOTAxNDk4ZDEyOGQ2NTA4MTE5ZDlmMzE4YjM2;oom: avoid sending exiting tasks a SIGKILL;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzU4OTk3YWUzOGExOTAxNDk4ZDEyOGQ2NTA4MTE5ZDlmMzE4YjM2;"It's unnecessary to SIGKILL a task that is already PF_EXITING and can
actually cause a NULL pointer dereference of the sighand if it has already
been detached";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzU4OTk3YWUzOGExOTAxNDk4ZDEyOGQ2NTA4MTE5ZDlmMzE4YjM2;" Instead, simply set TIF_MEMDIE so it has access to memory
reserves and can quickly exit as the comment implies.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;oom: give current access to memory reserves if it has been killed;David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;"It's possible to livelock the page allocator if a thread has mm->mmap_sem
and fails to make forward progress because the oom killer selects another
thread sharing the same ->mm to kill that cannot exit until the semaphore
is dropped";David Rientjes;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;"The oom killer will not kill multiple tasks at the same time; each oom
killed task must exit before another task may be killed";David Rientjes;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;" Thus, if one
thread is holding mm->mmap_sem and cannot allocate memory, all threads
sharing the same ->mm are blocked from exiting as well";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;" In the oom kill
case, that means the thread holding mm->mmap_sem will never free
additional memory since it cannot get access to memory reserves and the
thread that depends on it with access to memory reserves cannot exit
because it cannot acquire the semaphore";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;" Thus, the page allocators
livelocks";David Rientjes;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;"When the oom killer is called and current happens to have a pending
SIGKILL, this patch automatically gives it access to memory reserves and
returns";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;" Upon returning to the page allocator, its allocation will
hopefully succeed so it can quickly exit and free its memory";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3Yjk4YzJlNDAyZWFhMWYyYmVlYzE4YjFiZGUxN2Y3NDk0OGExOWRi;" If not, the
page allocator will fail the allocation if it is not __GFP_NOFAIL.";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpjODFmYWM1Y2I4YzkyYjhiNDc5NWFjMjUwYTQ2Yzc1MTRkMWZjZTA2;oom: dump_tasks use find_lock_task_mm too fix;David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjODFmYWM1Y2I4YzkyYjhiNDc5NWFjMjUwYTQ2Yzc1MTRkMWZjZTA2;"When find_lock_task_mm() returns a thread other than p in dump_tasks(),
its name should be displayed instead";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjODFmYWM1Y2I4YzkyYjhiNDc5NWFjMjUwYTQ2Yzc1MTRkMWZjZTA2;" This is the thread that will be
targeted by the oom killer, not its mm-less parent";David Rientjes;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpjODFmYWM1Y2I4YzkyYjhiNDc5NWFjMjUwYTQ2Yzc1MTRkMWZjZTA2;"This also allows us to safely dereference task->comm without needing
get_task_comm()";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjODFmYWM1Y2I4YzkyYjhiNDc5NWFjMjUwYTQ2Yzc1MTRkMWZjZTA2;While we're here, remove the cast on task_cpu(task) as Andrew suggested.;David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NGFiN2YxZDNmMjJjY2IwMmY4YjE0ZjFmMjM3NTQxNmIxYWIwYWRi;oom: improve commentary in dump_tasks();David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NGFiN2YxZDNmMjJjY2IwMmY4YjE0ZjFmMjM3NTQxNmIxYWIwYWRi;"The comments in dump_tasks() should be updated to be more clear about why
tasks are filtered and how they are filtered by its argument";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NGFiN2YxZDNmMjJjY2IwMmY4YjE0ZjFmMjM3NTQxNmIxYWIwYWRi;"An unnecessary comment concerning a check for is_global_init() is removed
since it isn't of importance.";David Rientjes;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNTVkYjk1Nzg4YTJhNTVhNzdmNWEzY2VkMWU1OTU3ODcxMDQ0MGIy;oom: dump_tasks use find_lock_task_mm too;KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpjNTVkYjk1Nzg4YTJhNTVhNzdmNWEzY2VkMWU1OTU3ODcxMDQ0MGIy;dump_task() should use find_lock_task_mm() too;KOSAKI Motohiro;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpjNTVkYjk1Nzg4YTJhNTVhNzdmNWEzY2VkMWU1OTU3ODcxMDQ0MGIy;"It is necessary for
protecting task-exiting race";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjNTVkYjk1Nzg4YTJhNTVhNzdmNWEzY2VkMWU1OTU3ODcxMDQ0MGIy;"dump_tasks() currently filters any task that does not have an attached
->mm since it incorrectly assumes that it must either be in the process of
multithreaded tasks may actually have subthreads that have a valid ->mm
pointer and thus those threads should actually be displayed";KOSAKI Motohiro;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpjNTVkYjk1Nzg4YTJhNTVhNzdmNWEzY2VkMWU1OTU3ODcxMDQ0MGIy;" This change
finds those threads, if they exist, and emit their information along with
the rest of the candidate tasks for kill.";KOSAKI Motohiro;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;oom: introduce find_lock_task_mm() to fix !mm false positives;Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;Almost all ->mm == NULL checks in oom_kill.c are wrong;Oleg Nesterov;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"The current code assumes that the task without ->mm has already released
its memory and ignores the process";Oleg Nesterov;2010-08-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;" However this is not necessarily true
when this process is multithreaded, other live sub-threads can use this
->mm";Oleg Nesterov;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"- Remove the ""if (!p->mm)"" check in select_bad_process(), it is
  just wrong";Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"- Add the new helper, find_lock_task_mm(), which finds the live
  thread which uses the memory and takes task_lock() to pin ->mm
- change oom_badness() to use this helper instead of just checking
  ->mm != NULL";Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"- As David pointed out, select_bad_process() must never choose the
  task without ->mm, but no matter what oom_badness() returns the
  task can be chosen if nothing else has been found yet";Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"  Change oom_badness() to return int, change it to return -1 if
  find_lock_task_mm() fails, and change select_bad_process() to
  check points >= 0";Oleg Nesterov;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;Note! This patch is not enough, we need more changes;Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDhlOGY0MDVjYTM4NmM3Y2U3Y2JiOTk2Y2NkOTg1ZDI4M2IwZTAz;"	- oom_badness() was fixed, but oom_kill_task() still ignores
	  the task without ->mm
	- oom_forkbomb_penalty() should use find_lock_task_mm() too,
	  and it also needs other changes to actually find the first
	  first-descendant children
This will be addressed later.";Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNTIyNzk0MDZlNzdiZTcxMWMwNjhmOWE4ZTk3MGVhNjQ3MWUwODlj;oom: PF_EXITING check should take mm into account;Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNTIyNzk0MDZlNzdiZTcxMWMwNjhmOWE4ZTk3MGVhNjQ3MWUwODlj;"select_bad_process() checks PF_EXITING to detect the task which is going
to release its memory, but the logic is very wrong";Oleg Nesterov;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNTIyNzk0MDZlNzdiZTcxMWMwNjhmOWE4ZTk3MGVhNjQ3MWUwODlj;"	- a single process P with the dead group leader disables
	  select_bad_process() completely, it will always return
	  ERR_PTR() while P can live forever
	- if the PF_EXITING task has already released its ->mm
	  it doesn't make sense to expect it is goiing to free
	  more memory (except task_struct/etc)
Change the code to ignore the PF_EXITING tasks without ->mm.";Oleg Nesterov;2010-08-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo0NTVjMGU1ZmIwM2I2N2ZhNjJiZDEyZTNhYmUzZmE0ODRiOTk2MGM1;oom: check PF_KTHREAD instead of !mm to skip kthreads;Oleg Nesterov;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo0NTVjMGU1ZmIwM2I2N2ZhNjJiZDEyZTNhYmUzZmE0ODRiOTk2MGM1;"select_bad_process() thinks a kernel thread can't have ->mm != NULL, this
is not true due to use_mm()";Oleg Nesterov;2010-08-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo0NTVjMGU1ZmIwM2I2N2ZhNjJiZDEyZTNhYmUzZmE0ODRiOTk2MGM1;Change the code to check PF_KTHREAD.;Oleg Nesterov;2010-08-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZjY0ZjgxYmIxZTAxY2JlZjk2N2E5NjY0MmRhY2YyMDhhY2I3ZTcy;memcg: make oom killer a no-op when no killable task can be found;David Rientjes;2010-05-26;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZjY0ZjgxYmIxZTAxY2JlZjk2N2E5NjY0MmRhY2YyMDhhY2I3ZTcy;"It's pointless to try to kill current if select_bad_process() did not find
an eligible task to kill in mem_cgroup_out_of_memory() since it's
guaranteed that current is a member of the memcg that is oom and it is, by
definition, unkillable.";David Rientjes;2010-05-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;include cleanup: Update gfp.h and slab.h includes to prepare for breaking implicit slab.h inclusion from percpu.h;Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"percpu.h is included by sched.h and module.h and thus ends up being
included when building most .c files";Tejun Heo;2010-03-24;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" percpu.h includes slab.h which
in turn includes gfp.h making everything defined by the two files
universally available and complicating inclusion dependencies";Tejun Heo;2010-03-24;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;percpu.h -> slab.h dependency is about to be removed;Tejun Heo;2010-03-24;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" Prepare for
this change by updating users of gfp and slab facilities include those
headers directly instead of assuming availability";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" As this conversion
needs to touch large number of source files, the following script is
used as the basis of conversion";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;The script does the followings;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;  only the necessary includes are there;Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1; ie;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"if only gfp is used,
  gfp.h, if slab is used, slab.h";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"  blocks and try to put the new include such that its order conforms
  to its surrounding";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" It's put in the include block which contains
  core kernel includes, in the same order that the rest are ordered -
  alphabetical, Christmas tree, rev-Xmas-tree or at the end if there
  doesn't seem to be any matching order";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"  because the file doesn't have fitting include block), it prints out
  an error message indicating which .h file needs to be added to the
  file";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;The conversion was done in the following steps;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;1;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"The initial automatic conversion of all .c files updated slightly
   over 4000 files, deleting around 700 includes and adding ~480 gfp.h
   and ~3000 slab.h inclusions";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" The script emitted errors for ~400
   files";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;2;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;Each error was manually checked;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" Some didn't need the inclusion,
   some needed manual addition while adding it to implementation .h or
   embedding .c file was more appropriate for others";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" This step added
   inclusions to around 150 files";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;3;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"The script was run again and the output was compared to the edits
   from #2 to make sure no file was left behind";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;4;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;Several build tests were done and a couple of problems were fixed;Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;   e.g;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"lib/decompress_*.c used malloc/free() wrappers around slab
   APIs requiring slab.h to be added manually";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;5;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"The script was run on all .h files but without automatically
   editing them as sprinkling gfp.h and slab.h inclusions around .h
   files could easily lead to inclusion dependency hell";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" Most gfp.h
   inclusion directives were ignored as stuff from gfp.h was usually
   wildly available and often used in preprocessor macros";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" Each
   slab.h inclusion directive was examined and added manually as
   necessary";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;6;Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;percpu.h was updated not to include slab.h;Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;7;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"Build test were done on the following configurations and failures
   were fixed";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;" CONFIG_GCOV_KERNEL was turned off for all tests (as my
   distributed build env didn't work with gcov compiles) and a few
   more options had to be turned off depending on archs to make things
   build (like ipr on powerpc/64 which failed due to missing writeq)";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;8;Tejun Heo;2010-03-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"percpu.h modifications were reverted so that it could be applied as
   a separate patch and serve as bisection point";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"Given the fact that I had only a couple of failures from tests on step
6, I'm fairly confident about the coverage of this conversion patch";Tejun Heo;2010-03-24;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTBlM2FkNmFmODY2MGJlMjFjYTk4YTk3MWNkMDBmMzMxMzE4YzA1;"If there is a breakage, it's likely to be something in one of the arch
headers which should be easily discoverable easily on most builds of
the specific arch.";Tejun Heo;2010-03-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;memcg: fix oom kill behavior;KAMEZAWA Hiroyuki;2010-03-10;1;1
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;"In current page-fault code,
	handle_mm_fault()
		-> mem_cgroup_charge()
		-> map page or handle error";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;	-> check return code;KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;"If page fault's return code is VM_FAULT_OOM, page_fault_out_of_memory() is
called";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;" But if it's caused by memcg, OOM should have been already
invoked";KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;Then, I added a patch: a636b327f731143ccc544b966cfd8de6cb6d72c6;KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;" That
patch records last_oom_jiffies for memcg's sub-hierarchy and prevents
page_fault_out_of_memory from being invoked in near future";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;"But Nishimura-san reported that check by jiffies is not enough when the
system is terribly heavy";KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;This patch changes memcg's oom logic as;KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;"Something more sophisticated can be added but this pactch does
fundamental things";KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;TODO;KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2;" - add oom notifier
 - add permemcg disable-oom-kill flag and freezer at oom";KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODo4Njc1NzhjYmNjYjA4OTNjYzE0ZmMyOWM2NzBmNzE4NTgwOWM5MGQ2; - more chances for wake up oom waiter (when changing memory limit etc..);KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;memcg: handle panic_on_oom=always case;KAMEZAWA Hiroyuki;2010-03-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;"Presently, if panic_on_oom=2, the whole system panics even if the oom
happend in some special situation (as cpuset, mempolicy....)";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;" Then,
panic_on_oom=2 means painc_on_oom_always";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;Now, memcg doesn't check panic_on_oom flag;KAMEZAWA Hiroyuki;2010-03-10;1;1
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;This patch adds a check;KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;"BTW, how it's useful ?
kdump+panic_on_oom=2 is the last tool to investigate what happens in
oom-ed system";KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;" When a task is killed, the sysytem recovers and there will
be few hint to know what happnes";KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;" In mission critical system, oom should
never happen";KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;" Then, panic_on_oom=2+kdump is useful to avoid next OOM by
knowing precise information via snapshot";KAMEZAWA Hiroyuki;2010-03-10;0;1
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;TODO;KAMEZAWA Hiroyuki;2010-03-10;0;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;" - For memcg, it's for isolate system's memory usage, oom-notiifer and
   freeze_at_oom (or rest_at_oom) should be implemented";KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkYWFmMWU2ODg3NGMwNzhhMTVhZTZhZTgyNzc1MTgzOWM0ZDgxNzM5;"Then, management
   daemon can do similar jobs (as kdump) or taking snapshot per cgroup.";KAMEZAWA Hiroyuki;2010-03-10;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNTU5ZGIwODZmZjViZTliY2MyNTllNWFhNTBiZjNkODgxZWFmMWQx;mm: clean up mm_counter;KAMEZAWA Hiroyuki;2010-03-05;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNTU5ZGIwODZmZjViZTliY2MyNTllNWFhNTBiZjNkODgxZWFmMWQx;"Presently, per-mm statistics counter is defined by macro in sched.h
This patch modifies it to
  - defined in mm.h as inlinf functions
  - use array instead of macro's name creation";KAMEZAWA Hiroyuki;2010-03-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpkNTU5ZGIwODZmZjViZTliY2MyNTllNWFhNTBiZjNkODgxZWFmMWQx;"This patch is for reducing patch size in future patch to modify
implementation of per-mm counter.";KAMEZAWA Hiroyuki;2010-03-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0;memcg: fix oom killing a child process in an other cgroup;KAMEZAWA Hiroyuki;2010-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0;"Presently the oom-killer is memcg aware and it finds the worst process
from processes under memcg(s) in oom";KAMEZAWA Hiroyuki;2010-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0;" Then, it kills victim's child
first";KAMEZAWA Hiroyuki;2010-02-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0;"It may kill a child in another cgroup and may not be any help for
recovery";KAMEZAWA Hiroyuki;2010-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0; And it will break the assumption users have;KAMEZAWA Hiroyuki;2010-02-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo1YTJkNDE5NjFkZDY4MTViODc0YjVjMGFmZWMwYWM5NmNkOTBlZWE0;This patch fixes it.;KAMEZAWA Hiroyuki;2010-02-22;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;memcg: avoid oom-killing innocent task in case of use_hierarchy;Daisuke Nishimura;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;"task_in_mem_cgroup(), which is called by select_bad_process() to check
whether a task can be a candidate for being oom-killed from memcg's limit,
checks ""curr->use_hierarchy""(""curr"" is the mem_cgroup the task belongs
to)";Daisuke Nishimura;2009-12-16;0;0
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;But this check return true(it's false positive) when;Daisuke Nishimura;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;"	<some path>/aa		use_hierarchy == 0	<- hitting limit
	  <some path>/aa/00	use_hierarchy == 1	<- the task belongs to
This leads to killing an innocent task in aa/00";Daisuke Nishimura;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;" This patch is a fix for
this bug";Daisuke Nishimura;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;" And this patch also fixes the arg for
mem_cgroup_print_oom_info()";Daisuke Nishimura;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODpkMzFmNTZkYmY4YmFmYWFjYjBjNjE3ZjlhNmYxMzc0OThkNWM3YWVk;" We should print information of mem_cgroup
which the task being killed, not current, belongs to.";Daisuke Nishimura;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;oom-kill: fix NUMA constraint check with nodemask;KAMEZAWA Hiroyuki;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"Fix node-oriented allocation handling in oom-kill.c I myself think of this
as a bugfix not as an ehnancement";KAMEZAWA Hiroyuki;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"In these days, things are changed as
  - alloc_pages() eats nodemask as its arguments, __alloc_pages_nodemask()";KAMEZAWA Hiroyuki;2009-12-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;  - mempolicy don't maintain its own private zonelists;KAMEZAWA Hiroyuki;2009-12-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"  (And cpuset doesn't use nodemask for __alloc_pages_nodemask())
So, current oom-killer's check function is wrong";KAMEZAWA Hiroyuki;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"This patch does
  - check nodemask, if nodemask && nodemask doesn't cover all
    node_states[N_HIGH_MEMORY], this is CONSTRAINT_MEMORY_POLICY";KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"  - Scan all zonelist under nodemask, if it hits cpuset's wall
    this faiulre is from cpuset";KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;  - modifies the caller of out_of_memory not to call oom if __GFP_THISNODE;KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"    This doesn't change ""current"" behavior";KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;"If callers use __GFP_THISNODE
    it should handle ""page allocation failure"" by itself";KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;  - handle __GFP_NOFAIL+__GFP_THISNODE path;KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo0MzY1YTU2NzZmYTNhYTFkNWFlNmM5MGMyMmEwMDQ0ZjA5YmE1ODRl;    This is something like a FIXME but this gfpmask is not used now.;KAMEZAWA Hiroyuki;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;oom-kill: show virtual size and rss information of the killed process;KOSAKI Motohiro;2009-12-16;1;0
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;"In a typical oom analysis scenario, we frequently want to know whether the
killed process has a memory leak or not at the first step";KOSAKI Motohiro;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;" This patch
adds vsz and rss information to the oom log to help this analysis";KOSAKI Motohiro;2009-12-16;1;1
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;" To
save time for the debugging";KOSAKI Motohiro;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;example;KOSAKI Motohiro;2009-12-16;0;1
MDY6Q29tbWl0MjMyNTI5ODozYjQ3OThjYmMxM2RkOGQxMTUwYWE2Mzc3Zjk3ZjBlMTE0NTBhNjdk;"rsyslogd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0
Pid: 1308, comm: rsyslogd Not tainted 2.6.32-rc6 #24
(snip)
492283 pages non-shared
Out of memory: kill process 2341 (memhog) score 527276 or a child
Killed process 2341 (memhog) vsz:1054552kB, anon-rss:970588kB, file-rss:4kB
                            here";KOSAKI Motohiro;2009-12-16;0;0
MDY6Q29tbWl0MjMyNTI5ODoxYjYwNGQ3NWJiYjZlMjg2MjhjNWE5NWE0MzM0MzI5NzNjMzNkNTgx;oom: dump stack and VM state when oom killer panics;David Rientjes;2009-12-15;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYjYwNGQ3NWJiYjZlMjg2MjhjNWE5NWE0MzM0MzI5NzNjMzNkNTgx;"The oom killer header, including information such as the allocation order
and gfp mask, current's cpuset and memory controller, call trace, and VM
state information is currently only shown when the oom killer has selected
a task to kill";David Rientjes;2009-12-15;0;0
MDY6Q29tbWl0MjMyNTI5ODoxYjYwNGQ3NWJiYjZlMjg2MjhjNWE5NWE0MzM0MzI5NzNjMzNkNTgx;"This information is omitted, however, when the oom killer panics either
because of panic_on_oom sysctl settings or when no killable task was
found";David Rientjes;2009-12-15;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYjYwNGQ3NWJiYjZlMjg2MjhjNWE5NWE0MzM0MzI5NzNjMzNkNTgx;" It is still relevant to know crucial pieces of information such as
the allocation order and VM state when diagnosing such issues, especially
at boot";David Rientjes;2009-12-15;0;1
MDY6Q29tbWl0MjMyNTI5ODoxYjYwNGQ3NWJiYjZlMjg2MjhjNWE5NWE0MzM0MzI5NzNjMzNkNTgx;"This patch displays the oom killer header whenever it panics so that bug
reports can include pertinent information to debug the issue, if possible.";David Rientjes;2009-12-15;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;oom: oom_kill doesn't kill vfork parent (or child);KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;"Current oom_kill doesn't only kill the victim process, but also kill all
thas shread the same mm";KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy; it mean vfork parent will be killed;KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;This is definitely incorrect;KOSAKI Motohiro;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy; another process have another oom_adj;KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;" we
shouldn't ignore their oom_adj (it might have OOM_DISABLE)";KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;following caller hit the minefield;KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;"                oom_kill_process(current, gfp_mask, order, 0, NULL,
Note: force_sig(SIGKILL) send SIGKILL to all thread in the process";KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YzVjZDZmM2ExNzIxMDg1NjUyZGEyMDRkNDU0YWY0ZjhiOTJlZGEy;We don't need to care multi thread in here.;KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU3ODlhNTFhOTFjYjhjMDE1ZDhkNzdmZWNiYWMxY2FmMjBiMTg2;oom: make oom_score to per-process value;KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU3ODlhNTFhOTFjYjhjMDE1ZDhkNzdmZWNiYWMxY2FmMjBiMTg2;oom-killer kills a process, not task;KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo0OTU3ODlhNTFhOTFjYjhjMDE1ZDhkNzdmZWNiYWMxY2FmMjBiMTg2;" Then oom_score should be calculated
as per-process too";KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo0OTU3ODlhNTFhOTFjYjhjMDE1ZDhkNzdmZWNiYWMxY2FmMjBiMTg2;" it makes consistency more and makes speed up
select_bad_process().";KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;oom: move oom_adj value from task_struct to signal_struct;KOSAKI Motohiro;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;Currently, OOM logic callflow is here;KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;"    __out_of_memory()
        select_bad_process()            for each task
            badness()                   calculate badness of one task
                oom_kill_process()      search child
                    oom_kill_task()     kill target task and mm shared tasks with it
example, process-A have two thread, thread-A and thread-B and it have very
fat memory and each thread have following oom_adj and oom_score";KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;"     thread-A: oom_adj = OOM_DISABLE, oom_score = 0
     thread-B: oom_adj = 0,           oom_score = very-high
Then, select_bad_process() select thread-B, but oom_kill_task() refuse
kill the task because thread-A have OOM_DISABLE";KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" Thus __out_of_memory()
call select_bad_process() again";KOSAKI Motohiro;2009-09-22;0;0
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" but select_bad_process() select the same
task";KOSAKI Motohiro;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4; It mean kernel fall in livelock;KOSAKI Motohiro;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;The fact is, select_bad_process() must select killable task;KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" otherwise
OOM logic go into livelock";KOSAKI Motohiro;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;And root cause is, oom_adj shouldn't be per-thread value;KOSAKI Motohiro;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" it should be
per-process value because OOM-killer kill a process, not thread";KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" Thus
This patch moves oomkilladj (now more appropriately named oom_adj) from
struct task_struct to struct signal_struct";KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODoyOGI4M2M1MTkzZTdhYjk1MWU0MDIyNTIyNzhmMmNjNzlkYzRkMjk4;" it naturally prevent
select_bad_process() choose wrong task.";KOSAKI Motohiro;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODozNTQ1MWJlZWNiZDdjODZjZTMyNDlkNTQzNTk0NTE3YTVmZTlhMGNk;ksm: unmerge is an origin of OOMs;Hugh Dickins;2009-09-22;1;0
MDY6Q29tbWl0MjMyNTI5ODozNTQ1MWJlZWNiZDdjODZjZTMyNDlkNTQzNTk0NTE3YTVmZTlhMGNk;"Just as the swapoff system call allocates many pages of RAM to various
processes, perhaps triggering OOM, so ""echo 2 >/sys/kernel/mm/ksm/run""
(unmerge) is liable to allocate many pages of RAM to various processes,
perhaps triggering OOM; and each is normally run from a modest admin
process (swapoff or shell), easily repeated until it succeeds";Hugh Dickins;2009-09-22;0;1
MDY6Q29tbWl0MjMyNTI5ODozNTQ1MWJlZWNiZDdjODZjZTMyNDlkNTQzNTk0NTE3YTVmZTlhMGNk;"So treat unmerge_and_remove_all_rmap_items() in the same way that we treat
try_to_unuse(): generalize PF_SWAPOFF to PF_OOM_ORIGIN, and bracket both
with that, to ask the OOM killer to kill them first, to prevent them from
spawning more and more OOM kills.";Hugh Dickins;2009-09-22;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;"mm: revert ""oom: move oom_adj value""";KOSAKI Motohiro;2009-08-18;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;"The commit 2ff05b2b (oom: move oom_adj value) moveed the oom_adj value to
the mm_struct";KOSAKI Motohiro;2009-08-18;0;0
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk; It was a very good first step for sanitize OOM;KOSAKI Motohiro;2009-08-18;0;0
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;"However Paul Menage reported the commit makes regression to his job
scheduler";KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk; Current OOM logic can kill OOM_DISABLED process;KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;Why? His program has the code of similar to the following;KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;vfork() parent and child are shared the same mm_struct;KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;" then above
set_oom_adj(0) doesn't only change oom_adj for vfork() child, it's also
change oom_adj for vfork() parent";KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;" Then, vfork() parent (job scheduler)
lost OOM immune and it was killed";KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;Actually, fork-setting-exec idiom is very frequently used in userland program;KOSAKI Motohiro;2009-08-18;0;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;We must not break this assumption;KOSAKI Motohiro;2009-08-18;1;1
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;Then, this patch revert commit 2ff05b2b and related commit;KOSAKI Motohiro;2009-08-18;1;0
MDY6Q29tbWl0MjMyNTI5ODowNzUzYmEwMWUxMjYwMjBiZjBmODE1MDkzNDkwM2I0ODkzNWI2OTdk;"Reverted commit list
- commit 2ff05b2b4e (oom: move oom_adj value from task_struct to mm_struct)
- commit 4d8b9135c3 (oom: avoid unnecessary mm locking and scanning for OOM_DISABLE)
- commit 8123681022 (oom: only oom kill exiting tasks with attached memory)
- commit 933b787b57 (mm: copy over oom_adj value at fork time)";KOSAKI Motohiro;2009-08-18;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MTIzNjgxMDIyNmY3MWJkOWZmNzczMjFjOGU4Mjc2ZGFlN2VmYzYx;oom: only oom kill exiting tasks with attached memory;David Rientjes;2009-06-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo4MTIzNjgxMDIyNmY3MWJkOWZmNzczMjFjOGU4Mjc2ZGFlN2VmYzYx;"When a task is chosen for oom kill and is found to be PF_EXITING,
__oom_kill_task() is called to elevate the task's timeslice and give it
access to memory reserves so that it may quickly exit";David Rientjes;2009-06-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo4MTIzNjgxMDIyNmY3MWJkOWZmNzczMjFjOGU4Mjc2ZGFlN2VmYzYx;"This privilege is unnecessary, however, if the task has already detached
its mm";David Rientjes;2009-06-16;0;1
MDY6Q29tbWl0MjMyNTI5ODo4MTIzNjgxMDIyNmY3MWJkOWZmNzczMjFjOGU4Mjc2ZGFlN2VmYzYx;" Although its possible for the mm to become detached later since
task_lock() is not held, __oom_kill_task() will simply be a no-op in such
circumstances";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo4MTIzNjgxMDIyNmY3MWJkOWZmNzczMjFjOGU4Mjc2ZGFlN2VmYzYx;"Subsequently, it is no longer necessary to warn about killing mm-less
tasks since it is a no-op.";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDhiOTEzNWMzMGNjYmU0NmU2MjFmZWZkODYyOTY5ODE5MDAzZmQ2;oom: avoid unnecessary mm locking and scanning for OOM_DISABLE;David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDhiOTEzNWMzMGNjYmU0NmU2MjFmZWZkODYyOTY5ODE5MDAzZmQ2;"This moves the check for OOM_DISABLE to the badness heuristic so it is
only necessary to hold task_lock() once";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDhiOTEzNWMzMGNjYmU0NmU2MjFmZWZkODYyOTY5ODE5MDAzZmQ2;" If the mm is OOM_DISABLE, the
score is 0, which is also correctly exported via /proc/pid/oom_score";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDhiOTEzNWMzMGNjYmU0NmU2MjFmZWZkODYyOTY5ODE5MDAzZmQ2;"This requires that tasks with badness scores of 0 are prohibited from
being oom killed, which makes sense since they would not allow for future
memory freeing anyway";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZDhiOTEzNWMzMGNjYmU0NmU2MjFmZWZkODYyOTY5ODE5MDAzZmQ2;"Since the oom_adj value is a characteristic of an mm and not a task, it is
no longer necessary to check the oom_adj value for threads sharing the
same memory (except when simply issuing SIGKILLs for threads in other
thread groups).";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;oom: move oom_adj value from task_struct to mm_struct;David Rientjes;2009-06-16;1;0
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;"The per-task oom_adj value is a characteristic of its mm more than the
task itself since it's not possible to oom kill any thread that shares the
mm";David Rientjes;2009-06-16;0;0
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;" If a task were to be killed while attached to an mm that could not be
freed because another thread were set to OOM_DISABLE, it would have
needlessly been terminated since there is no potential for future memory
freeing";David Rientjes;2009-06-16;0;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;"This patch moves oomkilladj (now more appropriately named oom_adj) from
struct task_struct to struct mm_struct";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;" This requires task_lock() on a
task to check its oom_adj value to protect against exec, but it's already
necessary to take the lock when dereferencing the mm to find the total VM
size for the badness heuristic";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;"This fixes a livelock if the oom killer chooses a task and another thread
sharing the same memory has an oom_adj value of OOM_DISABLE";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;" This occurs
because oom_kill_task() repeatedly returns 1 and refuses to kill the
chosen task while select_bad_process() will repeatedly choose the same
task during the next retry";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;"Taking task_lock() in select_bad_process() to check for OOM_DISABLE and in
oom_kill_task() to check for threads sharing the same memory will be
removed in the next patch in this series where it will no longer be
necessary";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;"Writing to /proc/pid/oom_adj for a kthread will now return -EINVAL since
these threads are immune from oom killing already";David Rientjes;2009-06-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZmYwNWIyYjRlYWMyZTYzZDM0NWZjNzMxZWExNTFhMDYwMjQ3ZjUz;" They simply report an
oom_adj value of OOM_DISABLE.";David Rientjes;2009-06-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo2ZDI2NjFlZGU1ZjIwZjk2ODQyMmU3OTBhZjMzMzQ5MDhjM2JjODU3;oom: fix possible oom_dump_tasks NULL pointer;David Rientjes;2009-05-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo2ZDI2NjFlZGU1ZjIwZjk2ODQyMmU3OTBhZjMzMzQ5MDhjM2JjODU3;"When /proc/sys/vm/oom_dump_tasks is enabled, it is possible to get a NULL
pointer for tasks that have detached mm's since task_lock() is not held
during the tasklist scan";David Rientjes;2009-05-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo2ZDI2NjFlZGU1ZjIwZjk2ODQyMmU3OTBhZjMzMzQ5MDhjM2JjODU3; Add the task_lock().;David Rientjes;2009-05-28;1;0
MDY6Q29tbWl0MjMyNTI5ODoxODQxMDFiZjE0M2FjOTZkNjJiM2RjYzE3ZTdiMzU1MGY5OGQzMzUw;oom: prevent livelock when oom_kill_allocating_task is set;David Rientjes;2009-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoxODQxMDFiZjE0M2FjOTZkNjJiM2RjYzE3ZTdiMzU1MGY5OGQzMzUw;"When /proc/sys/vm/oom_kill_allocating_task is set for large systems that
want to avoid the lengthy tasklist scan, it's possible to livelock if
current is ineligible for oom kill";David Rientjes;2009-05-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoxODQxMDFiZjE0M2FjOTZkNjJiM2RjYzE3ZTdiMzU1MGY5OGQzMzUw;" This normally happens when it is set
to OOM_DISABLE, but is also possible if any threads are sharing the same
->mm with a different tgid";David Rientjes;2009-05-06;0;0
MDY6Q29tbWl0MjMyNTI5ODoxODQxMDFiZjE0M2FjOTZkNjJiM2RjYzE3ZTdiMzU1MGY5OGQzMzUw;"So change __out_of_memory() to fall back to the full task-list scan if it
was unable to kill `current'.";David Rientjes;2009-05-06;1;0
MDY6Q29tbWl0MjMyNTI5ODplMjIyNDMyYmZhN2RjZjZlYzAwODYyMmE5NzhjOWYyODRlZDVlM2E5;memcg: show memcg information during OOM;Balbir Singh;2009-04-02;1;0
MDY6Q29tbWl0MjMyNTI5ODplMjIyNDMyYmZhN2RjZjZlYzAwODYyMmE5NzhjOWYyODRlZDVlM2E5;"Add RSS and swap to OOM output from memcg
Display memcg values like failcnt, usage and limit when an OOM occurs due
to memcg";Balbir Singh;2009-04-02;1;0
MDY6Q29tbWl0MjMyNTI5ODplMjIyNDMyYmZhN2RjZjZlYzAwODYyMmE5NzhjOWYyODRlZDVlM2E5;"Thanks to Johannes Weiner, Li Zefan, David Rientjes, Kamezawa Hiroyuki,
Daisuke Nishimura and KOSAKI Motohiro for review";Balbir Singh;2009-04-02;0;0
MDY6Q29tbWl0MjMyNTI5ODplMjIyNDMyYmZhN2RjZjZlYzAwODYyMmE5NzhjOWYyODRlZDVlM2E5;"Sample output
Task in /a/x killed as a result of limit of /a
memory: usage 1048576kB, limit 1048576kB, failcnt 4183
memory+swap: usage 1400964kB, limit 9007199254740991kB, failcnt 0";Balbir Singh;2009-04-02;1;0
MDY6Q29tbWl0MjMyNTI5ODphMTI4ODhmNzcyZGFiNGJmNWU2ZjczNjY4ZGM0ZjVmNjAyNmE3MDE0;oom_kill: don't call for int_sqrt(0);Cyrill Gorcunov;2009-03-31;1;0
MDY6Q29tbWl0MjMyNTI5ODphMTI4ODhmNzcyZGFiNGJmNWU2ZjczNjY4ZGM0ZjVmNjAyNmE3MDE0;There is no need to call for int_sqrt if argument is 0.;Cyrill Gorcunov;2009-03-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;memcg: avoid deadlock caused by race between oom and cpuset_attach;Daisuke Nishimura;2009-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;"mpol_rebind_mm(), which can be called from cpuset_attach(), does
down_write(mm->mmap_sem)";Daisuke Nishimura;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;" This means down_write(mm->mmap_sem) can be
called under cgroup_mutex";Daisuke Nishimura;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;"OTOH, page fault path does down_read(mm->mmap_sem) and calls
mem_cgroup_try_charge_xxx(), which may eventually calls
mem_cgroup_out_of_memory()";Daisuke Nishimura;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;" And mem_cgroup_out_of_memory() calls
cgroup_lock()";Daisuke Nishimura;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;" This means cgroup_lock() can be called under
down_read(mm->mmap_sem)";Daisuke Nishimura;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;If those two paths race, deadlock can happen;Daisuke Nishimura;2009-01-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;This patch avoid this deadlock by;Daisuke Nishimura;2009-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;  - remove cgroup_lock() from mem_cgroup_out_of_memory();Daisuke Nishimura;2009-01-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo3ZjRkNDU0ZGVlMmUwYmRkMjFiYWZkNDEzZDFjNTNlNDQzYTI2NTQw;"  - define new mutex (memcg_tasklist) and serialize mem_cgroup_move_task()
    (->attach handler of memory cgroup) and mem_cgroup_out_of_memory.";Daisuke Nishimura;2009-01-08;1;0
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;memcg: avoid unnecessary system-wide-oom-killer;KAMEZAWA Hiroyuki;2009-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;Current mmtom has new oom function as pagefault_out_of_memory();KAMEZAWA Hiroyuki;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;" It's
added for select bad process rathar than killing current";KAMEZAWA Hiroyuki;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;"When memcg hit limit and calls OOM at page_fault, this handler called and
system-wide-oom handling happens";KAMEZAWA Hiroyuki;2009-01-08;0;0
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;" (means kernel panics if panic_on_oom is
true....)
To avoid overkill, check memcg's recent behavior before starting
system-wide-oom";KAMEZAWA Hiroyuki;2009-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2;"And this patch also fixes to guarantee ""don't accnout against process with
TIF_MEMDIE""";KAMEZAWA Hiroyuki;2009-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODphNjM2YjMyN2Y3MzExNDNjY2M1NDRiOTY2Y2ZkOGRlNmNiNmQ3MmM2; This is necessary for smooth OOM.;KAMEZAWA Hiroyuki;2009-01-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo3NWFhMTk5NDEwMzU5ZGM1ZmJjZjkwMjVmZjdhZjk4YTlkMjBmMGQ1;oom: print triggering task's cpuset and mems allowed;David Rientjes;2009-01-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo3NWFhMTk5NDEwMzU5ZGM1ZmJjZjkwMjVmZjdhZjk4YTlkMjBmMGQ1;"When cpusets are enabled, it's necessary to print the triggering task's
set of allowable nodes so the subsequently printed meminfo can be
interpreted correctly";David Rientjes;2009-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo3NWFhMTk5NDEwMzU5ZGM1ZmJjZjkwMjVmZjdhZjk4YTlkMjBmMGQ1;We also print the task's cpuset name for informational purposes.;David Rientjes;2009-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjN2Q0Y2FlYjFkNjhkMDdmNzdjYzA5ZmMyMGI3NzU5ZDZkN2FhM2Ix;oom: fix zone_scan_mutex name;David Rientjes;2009-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpjN2Q0Y2FlYjFkNjhkMDdmNzdjYzA5ZmMyMGI3NzU5ZDZkN2FhM2Ix;zone_scan_mutex is actually a spinlock, so name it appropriately.;David Rientjes;2009-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYzBmZTZlM2JkYTA0NjQ3MjhjMjNjOGQ4NGFhNDc1NjdlOGI3MTZj;mm: invoke oom-killer from page fault;Nick Piggin;2009-01-06;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYzBmZTZlM2JkYTA0NjQ3MjhjMjNjOGQ4NGFhNDc1NjdlOGI3MTZj;"Rather than have the pagefault handler kill a process directly if it gets
a VM_FAULT_OOM, have it call into the OOM killer";Nick Piggin;2009-01-06;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYzBmZTZlM2JkYTA0NjQ3MjhjMjNjOGQ4NGFhNDc1NjdlOGI3MTZj;"With increasingly sophisticated oom behaviour (cpusets, memory cgroups,
oom killing throttling, oom priority adjustment or selective disabling,
panic on oom, etc), it's silly to unconditionally kill the faulting
process at page fault time";Nick Piggin;2009-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYzBmZTZlM2JkYTA0NjQ3MjhjMjNjOGQ4NGFhNDc1NjdlOGI3MTZj;" Create a hook for pagefault oom path to call
into instead";Nick Piggin;2009-01-06;1;0
MDY6Q29tbWl0MjMyNTI5ODoxYzBmZTZlM2JkYTA0NjQ3MjhjMjNjOGQ4NGFhNDc1NjdlOGI3MTZj;Only converted x86 and uml so far.;Nick Piggin;2009-01-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpjNjllOGQ5YzAxZGIyYWRjNTAzNDY0OTkzYzM1ODkwMWM5YWY5ZGU0;CRED: Use RCU to access another task's creds and to release a task's own creds;David Howells;2008-11-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpjNjllOGQ5YzAxZGIyYWRjNTAzNDY0OTkzYzM1ODkwMWM5YWY5ZGU0;Use RCU to access another task's creds and to release a task's own creds;David Howells;2008-11-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpjNjllOGQ5YzAxZGIyYWRjNTAzNDY0OTkzYzM1ODkwMWM5YWY5ZGU0;"This means that it will be possible for the credentials of a task to be
replaced without another task (a) requiring a full lock to read them, and (b)
seeing deallocated memory.";David Howells;2008-11-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNmRmZjNlYzVlMTE2ZTNhZjZmNTM3ZDRjYWVkY2FkNmI5ZTUwODJh;CRED: Separate task security context from task_struct;David Howells;2008-11-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNmRmZjNlYzVlMTE2ZTNhZjZmNTM3ZDRjYWVkY2FkNmI5ZTUwODJh;Separate the task security context from task_struct;David Howells;2008-11-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNmRmZjNlYzVlMTE2ZTNhZjZmNTM3ZDRjYWVkY2FkNmI5ZTUwODJh;" At this point, the
security data is temporarily embedded in the task_struct with two pointers
pointing to it";David Howells;2008-11-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNmRmZjNlYzVlMTE2ZTNhZjZmNTM3ZDRjYWVkY2FkNmI5ZTUwODJh;"Note that the Alpha arch is altered as it refers to (E)UID and (E)GID in
entry.S via asm-offsets";David Howells;2008-11-13;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNmRmZjNlYzVlMTE2ZTNhZjZmNTM3ZDRjYWVkY2FkNmI5ZTUwODJh;With comment fixes ;David Howells;2008-11-13;1;1
MDY6Q29tbWl0MjMyNTI5ODphMmYyOTQ1YTk5MDU3YzdkNDQwNDM0NjU5MDZjNmJiNjNjMzM2OGEw;The oomkiller calculations make decisions based on capabilities.  Since;Eric Paris;2008-11-11;0;0
MDY6Q29tbWl0MjMyNTI5ODphMmYyOTQ1YTk5MDU3YzdkNDQwNDM0NjU5MDZjNmJiNjNjMzM2OGEw;"these are not security decisions and LSMs should not record if they fall
the request they should use the new has_capability_noaudit() interface so
the denials will not be recorded.";Eric Paris;2008-11-11;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYmRkMTI2NzZjODNkZjc3NDgwZjAwZWJkMzJmYzk4ZmJlM2JmODM2;mm/oom_kill.c: fix badness() kerneldoc;Qinghuang Feng;2008-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYmRkMTI2NzZjODNkZjc3NDgwZjAwZWJkMzJmYzk4ZmJlM2JmODM2;Paramter @mem has been removed since v2.6.26, now delete it's comment.;Qinghuang Feng;2008-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNDQxNmQyYmVhMDA3ZjA3ZjJlNzRjZGM0Y2I2NDA0MmVjOTk2Yzgz;oom: do not dump task state for non thread group leaders;David Rientjes;2008-11-06;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDQxNmQyYmVhMDA3ZjA3ZjJlNzRjZGM0Y2I2NDA0MmVjOTk2Yzgz;"When /proc/sys/vm/oom_dump_tasks is enabled, it's only necessary to dump
task state information for thread group leaders";David Rientjes;2008-11-06;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNDQxNmQyYmVhMDA3ZjA3ZjJlNzRjZGM0Y2I2NDA0MmVjOTk2Yzgz;" The kernel log gets
quickly overwhelmed on machines with a massive number of threads by
dumping non-thread group leaders.";David Rientjes;2008-11-06;0;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;security: Fix setting of PF_SUPERPRIV by __capable();David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;"Fix the setting of PF_SUPERPRIV by __capable() as it could corrupt the flags
the target process if that is not the current process and it is trying to
change its own flags in a different way at the same time";David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;__capable() is using neither atomic ops nor locking to protect t->flags;David Howells;2008-08-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" This
patch removes __capable() and introduces has_capability() that doesn't set
PF_SUPERPRIV on the process being queried";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;This patch further splits security_ptrace() in two;David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw; (1) security_ptrace_may_access();David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" This passes judgement on whether one
     process may access another only (PTRACE_MODE_ATTACH for ptrace() and
     PTRACE_MODE_READ for /proc), and takes a pointer to the child process";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;     current is the parent;David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw; (2) security_ptrace_traceme();David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" This passes judgement on PTRACE_TRACEME only,
     and takes only a pointer to the parent process";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw; current is the child;David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;"     In Smack and commoncap, this uses has_capability() to determine whether
     the parent will be permitted to use PTRACE_ATTACH if normal checks fail";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;     This does not set PF_SUPERPRIV;David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;"Two of the instances of __capable() actually only act on current, and so have
been changed to calls to capable()";David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;Of the places that were using __capable();David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" (1) The OOM killer calls __capable() thrice when weighing the killability of a
     process";David Howells;2008-08-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw; All of these now use has_capability();David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" (2) cap_ptrace() and smack_ptrace() were using __capable() to check to see
     whether the parent was allowed to trace any process";David Howells;2008-08-14;0;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" As mentioned above,
     these have been split";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" For PTRACE_ATTACH and /proc, capable() is now
     used, and for PTRACE_TRACEME, has_capability() is used";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw; (3) cap_safe_nice() only ever saw current, so now uses capable();David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" (4) smack_setprocattr() rejected accesses to tasks other than current just
     after calling __capable(), so the order of these two tests have been
     switched and capable() is used instead";David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" (5) In smack_file_send_sigiotask(), we need to allow privileged processes to
     receive SIGIO on files they're manipulating";David Howells;2008-08-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;" (6) In smack_task_wait(), we let a process wait for a privileged process,
     whether or not the process doing the waiting is privileged";David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1Y2Q5YzU4ZmJlOWVjOTJiNDViMjdlMTMxNzE5YWY0ZjJiZDllYjQw;I've tested this with the LTP SELinux and syscalls testscripts.;David Howells;2008-08-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo5N2Q4N2M5NzEwYmM2YzVmMjU4NWZiOWRjNThmNWJlZGJlOTk2ZjEw;oom_kill: remove unused parameter in badness();Li Zefan;2008-04-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2Q4N2M5NzEwYmM2YzVmMjU4NWZiOWRjNThmNWJlZGJlOTk2ZjEw;"In commit 4c4a22148909e4c003562ea7ffe0a06e26919e3c, we moved the
memcontroller-related code from badness() to select_bad_process(), so the
parameter 'mem' in badness() is unused now.";Li Zefan;2008-04-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;mm: have zonelist contains structs with both a zone pointer and zone_idx;Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;Filtering zonelists requires very frequent use of zone_idx();Mel Gorman;2008-04-28;0;0
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;" This is costly
as it involves a lookup of another structure and a substraction operation";Mel Gorman;2008-04-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;" As
the zone_idx is often required, it should be quickly accessible";Mel Gorman;2008-04-28;0;1
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;" The node idx
could also be stored here if it was found that accessing zone->node is
significant which may be the case on workloads where nodemasks are heavily
used";Mel Gorman;2008-04-28;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;"This patch introduces a struct zoneref to store a zone pointer and a zone
index";Mel Gorman;2008-04-28;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;" The zonelist then consists of an array of these struct zonerefs which
are looked up as necessary";Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZDFhMjM5ZjZmMmQ0ZDNlZWRkMzE4NTgzZWMzMTlhYTE0NWIzMjRj;" Helpers are given for accessing the zone index as
well as the node index.";Mel Gorman;2008-04-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;mm: use two zonelist that are filtered by GFP mask;Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;"Currently a node has two sets of zonelists, one for each zone type in the
system and a second set for GFP_THISNODE allocations";Mel Gorman;2008-04-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;" Based on the zones
allowed by a gfp mask, one of these zonelists is selected";Mel Gorman;2008-04-28;0;0
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;" All of these
zonelists consume memory and occupy cache lines";Mel Gorman;2008-04-28;0;1
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;This patch replaces the multiple zonelists per-node with two zonelists;Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;" The
first contains all populated zones in the system, ordered by distance, for
fallback allocations when the target/preferred node has no free pages";Mel Gorman;2008-04-28;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;" The
second contains all populated zones in the node suitable for GFP_THISNODE
allocations";Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NGE2ZWI1YzQ3NjVhYTU3M2EwMzBjZWViYTJjMTRlM2QyZWE1NzA2;"An iterator macro is introduced called for_each_zone_zonelist() that interates
through each zone allowed by the GFP flags in the selected zonelist.";Mel Gorman;2008-04-28;1;0
MDY6Q29tbWl0MjMyNTI5ODplMTE1ZjJkODkyNTM0OTBmYjJkYmYzMDRiNjI3ZjhkOTA4ZGYyNmYx;memcg: fix oops in oom handling;Li Zefan;2008-04-15;1;1
MDY6Q29tbWl0MjMyNTI5ODplMTE1ZjJkODkyNTM0OTBmYjJkYmYzMDRiNjI3ZjhkOTA4ZGYyNmYx;"When I used a test program to fork mass processes and immediately move them to
a cgroup where the memory limit is low enough to trigger oom kill, I got oops";Li Zefan;2008-04-15;0;1
MDY6Q29tbWl0MjMyNTI5ODplMTE1ZjJkODkyNTM0OTBmYjJkYmYzMDRiNjI3ZjhkOTA4ZGYyNmYx;"BUG: unable to handle kernel NULL pointer dereference at 0000000000000808
IP: [<ffffffff8045c47f>] _spin_lock_irqsave+0x8/0x18
PGD 4c95f067 PUD 4406c067 PMD 0
Oops: 0002 [1] SMP
CPU 2
Modules linked in";Li Zefan;2008-04-15;0;1
MDY6Q29tbWl0MjMyNTI5ODplMTE1ZjJkODkyNTM0OTBmYjJkYmYzMDRiNjI3ZjhkOTA4ZGYyNmYx;"Pid: 11973, comm: a.out Not tainted 2.6.25-rc7 #5
RIP: 0010:[<ffffffff8045c47f>]  [<ffffffff8045c47f>] _spin_lock_irqsave+0x8/0x18
RSP: 0018:ffff8100448c7c30  EFLAGS: 00010002
RAX: 0000000000000202 RBX: 0000000000000009 RCX: 000000000001c9f3
RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000808
RBP: ffff81007e444080 R08: 0000000000000000 R09: ffff8100448c7900
R10: ffff81000105f480 R11: 00000100ffffffff R12: ffff810067c84140
R13: 0000000000000001 R14: ffff8100441d0018 R15: ffff81007da56200
FS:  00007f70eb1856f0(0000) GS:ffff81007fbad3c0(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
CR2: 0000000000000808 CR3: 000000004498a000 CR4: 00000000000006e0
DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
Process a.out (pid: 11973, threadinfo ffff8100448c6000, task ffff81007da533e0)
Stack:  ffffffff8023ef5a 00000000000000d0 ffffffff80548dc0 00000000000000d0
 ffff810067c84140 ffff81007e444080 ffffffff8026cef9 00000000000000d0
 ffff8100441d0000 00000000000000d0 ffff8100441d0000 ffff8100505445c0
Code: 00 00 01 48 8b 3c 24 e9 46 d4 dd ff f0 ff 07 48 8b 3c 24 e9 3a d4 dd ff fe 07 48 8b 3c 24 e9 2f d4 dd ff 9c 58 fa ba 00 01 00 00 <f0> 66 0f c1 17 38 f2 74 06 f3 90 8a 17 eb f6 c3 fa b8 00 01 00
RIP  [<ffffffff8045c47f>] _spin_lock_irqsave+0x8/0x18
 RSP <ffff8100448c7c30>
CR2: 0000000000000808
---[ end trace c3702fa668021ea4 ]---
It's reproducable in a x86_64 box, but doesn't happen in x86_32";Li Zefan;2008-04-15;0;0
MDY6Q29tbWl0MjMyNTI5ODplMTE1ZjJkODkyNTM0OTBmYjJkYmYzMDRiNjI3ZjhkOTA4ZGYyNmYx;"This is because tsk->sighand is not guarded by RCU, so we have to
hold tasklist_lock, just as what out_of_memory() does.";Li Zefan;2008-04-15;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYjU3OGRmMDIyMDdhNjdhMjllOGNlZDRkYjNiMzZkODlkZjUyZmVm;mm/oom_kill: fix kernel-doc;Randy Dunlap;2008-03-20;1;1
MDY6Q29tbWl0MjMyNTI5ODoxYjU3OGRmMDIyMDdhNjdhMjllOGNlZDRkYjNiMzZkODlkZjUyZmVm;Fix kernel-doc notation in oom_kill.c.;Randy Dunlap;2008-03-20;1;1
MDY6Q29tbWl0MjMyNTI5ODowMGYwYjgyNTllNDg5NzljMzcyMTI5OTVkNzk4ZjNmYmQwMzc0Njkw;Memory controller: rename to Memory Resource Controller;Balbir Singh;2008-03-04;1;0
MDY6Q29tbWl0MjMyNTI5ODowMGYwYjgyNTllNDg5NzljMzcyMTI5OTVkNzk4ZjNmYmQwMzc0Njkw;Rename Memory Controller to Memory Resource Controller;Balbir Singh;2008-03-04;1;0
MDY6Q29tbWl0MjMyNTI5ODowMGYwYjgyNTllNDg5NzljMzcyMTI5OTVkNzk4ZjNmYmQwMzc0Njkw;" Reflect the same
changes in the CONFIG definition for the Memory Resource Controller";Balbir Singh;2008-03-04;1;1
MDY6Q29tbWl0MjMyNTI5ODowMGYwYjgyNTllNDg5NzljMzcyMTI5OTVkNzk4ZjNmYmQwMzc0Njkw;" Group
together the config options for Resource Counters and Memory Resource
Controller.";Balbir Singh;2008-03-04;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;oom: add sysctl to enable task memory dump;David Rientjes;2008-02-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;"Adds a new sysctl, 'oom_dump_tasks', that enables the kernel to produce a
dump of all system tasks (excluding kernel threads) when performing an
OOM-killing";David Rientjes;2008-02-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;" Information includes pid, uid, tgid, vm size, rss, cpu,
oom_adj score, and name";David Rientjes;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;"This is helpful for determining why there was an OOM condition and which
rogue task caused it";David Rientjes;2008-02-07;0;1
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;"It is configurable so that large systems, such as those with several
thousand tasks, do not incur a performance penalty associated with dumping
data they may not desire";David Rientjes;2008-02-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZWYxYmRkNjhjODFiNzE4ODJjY2I2ZjQ3YzcwOTgwYTAzMTgyMDYz;"If an OOM was triggered as a result of a memory controller, the tasklist
shall be filtered to exclude tasks that are not a member of the same
cgroup.";David Rientjes;2008-02-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YzRhMjIxNDg5MDllNGMwMDM1NjJlYTdmZmUwYTA2ZTI2OTE5ZTNj;memcontrol: move oom task exclusion to tasklist scan;David Rientjes;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo0YzRhMjIxNDg5MDllNGMwMDM1NjJlYTdmZmUwYTA2ZTI2OTE5ZTNj;"Creates a helper function to return non-zero if a task is a member of a
memory controller";David Rientjes;2008-02-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YzRhMjIxNDg5MDllNGMwMDM1NjJlYTdmZmUwYTA2ZTI2OTE5ZTNj;"	int task_in_mem_cgroup(const struct task_struct *task,
When the OOM killer is constrained by the memory controller, the exclusion
of tasks that are not a member of that controller was previously misplaced
and appeared in the badness scoring function";David Rientjes;2008-02-07;0;1
MDY6Q29tbWl0MjMyNTI5ODo0YzRhMjIxNDg5MDllNGMwMDM1NjJlYTdmZmUwYTA2ZTI2OTE5ZTNj;" It should be excluded
during the tasklist scan in select_bad_process() instead.";David Rientjes;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;Memory controller: OOM handling;Pavel Emelianov;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;Out of memory handling for cgroups over their limit;Pavel Emelianov;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;"A task from the
cgroup over limit is chosen using the existing OOM logic and killed";Pavel Emelianov;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;TODO;Pavel Emelianov;2008-02-07;0;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;1;Pavel Emelianov;2008-02-07;0;0
MDY6Q29tbWl0MjMyNTI5ODpjN2JhNWM5ZTgxNzY3MDRiZmFjMDcyOTg3NWZhNjI3OTgwMzc1ODRk;"As discussed in the OLS BOF session, consider implementing a user
space policy for OOM handling.";Pavel Emelianov;2008-02-07;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;oom_kill: remove uid==0 checks;Serge E. Hallyn;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;"Root processes are considered more important when out of memory and killing
proceses";Serge E. Hallyn;2008-02-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;" The check for CAP_SYS_ADMIN was augmented with a check for
uid==0 or euid==0";Serge E. Hallyn;2008-02-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;There are several possible ways to look at this;Serge E. Hallyn;2008-02-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;	1;Serge E. Hallyn;2008-02-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;"uid comparisons are unnecessary, trust CAP_SYS_ADMIN
	   alone";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;" However CAP_SYS_RESOURCE is the one that really
	   means ""give me extra resources"" so allow for that as
	   well";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;	2;Serge E. Hallyn;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;"Any privileged code should be protected, but uid is not
	   an indication of privilege";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;" So we should check whether
	   any capabilities are raised";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;	3;Serge E. Hallyn;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;"uid==0 makes processes on the host as well as in containers
	   more important, so we should keep the existing checks";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;	4;Serge E. Hallyn;2008-02-05;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;"uid==0 makes processes only on the host more important,
	   even without any capabilities";Serge E. Hallyn;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;" So we should be keeping
	   the (uid==0||euid==0) check but only when
	   userns==&init_user_ns";Serge E. Hallyn;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NzgyOTk1NWFkMjkxYWNlYzFkOGI5NGU5OTExYjNjZWIxMTE4YmIx;I'm following number 1 here.;Serge E. Hallyn;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODplMzM4ZDI2M2E3NmFmNzhmZThmMzhhNzIxMzExODhiNThmY2ViNTkx;Add 64-bit capability support to the kernel;Andrew Morgan;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODplMzM4ZDI2M2E3NmFmNzhmZThmMzhhNzIxMzExODhiNThmY2ViNTkx;"The patch supports legacy (32-bit) capability userspace, and where possible
translates 32-bit capabilities to/from userspace and the VFS to 64-bit
kernel space capabilities";Andrew Morgan;2008-02-05;1;1
MDY6Q29tbWl0MjMyNTI5ODplMzM4ZDI2M2E3NmFmNzhmZThmMzhhNzIxMzExODhiNThmY2ViNTkx;" If a capability set cannot be compressed into
32-bits for consumption by user space, the system call fails, with -ERANGE";Andrew Morgan;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODplMzM4ZDI2M2E3NmFmNzhmZThmMzhhNzIxMzExODhiNThmY2ViNTkx;FWIW libcap-2.00 supports this change (and earlier capability formats);Andrew Morgan;2008-02-05;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYTcxNzA2MGYxYWI3ZWI2NTcwZjJmYjQ5MTM2ZjgzOGZjOTE5NWE5;sched: sched_rt_entity;Peter Zijlstra;2008-01-25;0;0
MDY6Q29tbWl0MjMyNTI5ODpmYTcxNzA2MGYxYWI3ZWI2NTcwZjJmYjQ5MTM2ZjgzOGZjOTE5NWE5;Move the task_struct members specific to rt scheduling together;Peter Zijlstra;2008-01-25;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYTcxNzA2MGYxYWI3ZWI2NTcwZjJmYjQ5MTM2ZjgzOGZjOTE5NWE5;"A future optimization could be to put sched_entity and sched_rt_entity
into a union.";Peter Zijlstra;2008-01-25;1;0
MDY6Q29tbWl0MjMyNTI5ODplOTFhODEwZTg4NDg1MDc4MWExY2FkYTJlYTgxYjgwMTY4ODFkMjQ0;oom_kill bug;Al Viro;2007-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODplOTFhODEwZTg4NDg1MDc4MWExY2FkYTJlYTgxYjgwMTY4ODFkMjQ0;Wrong order of arguments;Al Viro;2007-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYTI1ZjlkY2M0ZWE2ZTMwODM5ZmNhYjVhNTUxNmYyMTc2ZDViZmVk;Use helpers to obtain task pid in printks;Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYTI1ZjlkY2M0ZWE2ZTMwODM5ZmNhYjVhNTUxNmYyMTc2ZDViZmVk;"The task_struct->pid member is going to be deprecated, so start
using the helpers (task_pid_nr/task_pid_vnr/task_pid_nr_ns) in
the kernel";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYTI1ZjlkY2M0ZWE2ZTMwODM5ZmNhYjVhNTUxNmYyMTc2ZDViZmVk;"The first thing to start with is the pid, printed to dmesg - in
this case we may safely use task_pid_nr()";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYTI1ZjlkY2M0ZWE2ZTMwODM5ZmNhYjVhNTUxNmYyMTc2ZDViZmVk;"Besides, printks produce
more (much more) than a half of all the explicit pid usage.";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYWMwYWJkNjE3NGU0Mjc0MDRkZDE5N2NkYmVmZWNlMzFlOTczMjli;Isolate some explicit usage of task->tgid;Pavel Emelyanov;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYWMwYWJkNjE3NGU0Mjc0MDRkZDE5N2NkYmVmZWNlMzFlOTczMjli;"With pid namespaces this field is now dangerous to use explicitly, so hide
it behind the helpers";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYWMwYWJkNjE3NGU0Mjc0MDRkZDE5N2NkYmVmZWNlMzFlOTczMjli;"Also the pid and pgrp fields o task_struct and signal_struct are to be
deprecated";Pavel Emelyanov;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYWMwYWJkNjE3NGU0Mjc0MDRkZDE5N2NkYmVmZWNlMzFlOTczMjli;" Unfortunately this patch cannot be sent right now as this
leads to tons of warnings, so start isolating them, and deprecate later";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYWMwYWJkNjE3NGU0Mjc0MDRkZDE5N2NkYmVmZWNlMzFlOTczMjli;"Actually the p->tgid == pid has to be changed to has_group_leader_pid(),
but Oleg pointed out that in case of posix cpu timers this is the same, and
thread_group_leader() is more preferable.";Pavel Emelyanov;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YjE5MTVhOTg5ZWE0ZDQyNmQwZmQ5ODk3NGFiODBmMzBlZjFkNzc5;mm/oom_kill.c: Use list_for_each_entry instead of list_for_each;Matthias Kaehlcke;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODo3YjE5MTVhOTg5ZWE0ZDQyNmQwZmQ5ODk3NGFiODBmMzBlZjFkNzc5;"mm/oom_kill.c: Convert list_for_each to list_for_each_entry in
oom_kill_process()";Matthias Kaehlcke;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;pid namespaces: define is_global_init() and is_container_init();Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;is_init() is an ambiguous name for the pid==1 check;Serge E. Hallyn;2007-10-19;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;" Split it into
is_global_init() and is_container_init()";Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;A cgroup init has it's tsk->pid == 1;Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;"A global init also has it's tsk->pid == 1 and it's active pid namespace
is the init_pid_ns";Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;" But rather than check the active pid namespace,
compare the task structure with 'init_pid_ns.child_reaper', which is
initialized during boot to the /sbin/init process and never changes";Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;Changelog;Serge E. Hallyn;2007-10-19;0;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;	2.6.22-rc4-mm2-pidns1;Serge E. Hallyn;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;"	- Use 'init_pid_ns.child_reaper' to determine if a given task is the
	  global init (/sbin/init) process";Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;"This would improve performance
	  and remove dependence on the task_pid()";Serge E. Hallyn;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;	2.6.21-mm2-pidns2;Serge E. Hallyn;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;	  ppc,avr32}/traps.c for the _exception() call to is_global_init();Serge E. Hallyn;2007-10-19;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNDYwY2JjNTgxYTUzY2MwODhjZWJhODA2MDgwMjFkZDQ5YzYzYzQz;"	  This way, we kill only the cgroup if the cgroup's init has a
	  bug rather than force a kernel panic.";Serge E. Hallyn;2007-10-19;1;1
MDY6Q29tbWl0MjMyNTI5ODphZTc0MTM4ZGE2MDljNTc2YjIyMWM3NjVlZmE4YjgxYjIzNjVmNDY1;oom: convert zone_scan_lock from mutex to spinlock;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODphZTc0MTM4ZGE2MDljNTc2YjIyMWM3NjVlZmE4YjgxYjIzNjVmNDY1;"There's no reason to sleep in try_set_zone_oom() or clear_zonelist_oom() if
the lock can't be acquired; it will be available soon enough once the zonelist
scanning is done";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODphZTc0MTM4ZGE2MDljNTc2YjIyMWM3NjVlZmE4YjgxYjIzNjVmNDY1;" All other threads waiting for the OOM killer are also
contingent on the exiting task being able to acquire the lock in
clear_zonelist_oom() so it doesn't make sense to put it to sleep.";David Rientjes;2007-10-17;0;1
MDY6Q29tbWl0MjMyNTI5ODozZmY1NjY5NjNjZTgwNDgwOWFmOWUzMjMzMWIyODdlZWRlZWZmNTAx;oom: do not take callback_mutex;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODozZmY1NjY5NjNjZTgwNDgwOWFmOWUzMjMzMWIyODdlZWRlZWZmNTAx;"Since no task descriptor's 'cpuset' field is dereferenced in the execution of
the OOM killer anymore, it is no longer necessary to take callback_mutex.";David Rientjes;2007-10-17;0;1
MDY6Q29tbWl0MjMyNTI5ODpiYmUzNzNmMmM2MGIyYWEzNmMzMjMxNzM0YTVhZmM1MjcxYTA2NzE4;oom: compare cpuset mems_allowed instead of exclusive ancestors;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODpiYmUzNzNmMmM2MGIyYWEzNmMzMjMxNzM0YTVhZmM1MjcxYTA2NzE4;"Instead of testing for overlap in the memory nodes of the the nearest
exclusive ancestor of both current and the candidate task, it is better to
simply test for intersection between the task's mems_allowed in their task
descriptors";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYmUzNzNmMmM2MGIyYWEzNmMzMjMxNzM0YTVhZmM1MjcxYTA2NzE4;" This does not require taking callback_mutex since it is only
used as a hint in the badness scoring";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODpiYmUzNzNmMmM2MGIyYWEzNmMzMjMxNzM0YTVhZmM1MjcxYTA2NzE4;"Tasks that do not have an intersection in their mems_allowed with the current
task are not explicitly restricted from being OOM killed because it is quite
possible that the candidate task has allocated memory there before and has
since changed its mems_allowed.";David Rientjes;2007-10-17;0;1
MDY6Q29tbWl0MjMyNTI5ODo3MjEzZjUwNjZmYzhhMTdjNzgzODlmZTI0NWRlNTIyYjVjZjA2NDhh;oom: suppress extraneous stack and memory dump;David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MjEzZjUwNjZmYzhhMTdjNzgzODlmZTI0NWRlNTIyYjVjZjA2NDhh;"Suppresses the extraneous stack and memory dump when a parallel OOM killing
has been found";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODo3MjEzZjUwNjZmYzhhMTdjNzgzODlmZTI0NWRlNTIyYjVjZjA2NDhh;" There's no need to fill the ring buffer with this information
if its already been printed and the condition that triggered the previous OOM
killer has not yet been alleviated.";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTA3MWQ3ZThhYWU1NzQ1YzAwOWM4MDhiYjg5MzNmMjJhOWUzMDVh;oom: add oom_kill_allocating_task sysctl;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODpmZTA3MWQ3ZThhYWU1NzQ1YzAwOWM4MDhiYjg5MzNmMjJhOWUzMDVh;"Adds a new sysctl, 'oom_kill_allocating_task', which will automatically kill
the OOM-triggering task instead of scanning through the tasklist to find a
memory-hogging target";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODpmZTA3MWQ3ZThhYWU1NzQ1YzAwOWM4MDhiYjg5MzNmMjJhOWUzMDVh;" This is helpful for systems with an insanely large
number of tasks where scanning the tasklist significantly degrades
performance.";David Rientjes;2007-10-17;0;1
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;oom: add per-zone locking;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;"OOM killer synchronization should be done with zone granularity so that memory
policy and cpuset allocations may have their corresponding zones locked and
allow parallel kills for other OOM conditions that may exist elsewhere in the
system";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;" DMA allocations can be targeted at the zone level, which would not be
possible if locking was done in nodes or globally";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;"Synchronization shall be done with a variation of ""trylocks."" The goal is to
put the current task to sleep and restart the failed allocation attempt later
if the trylock fails";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw; Otherwise, the OOM killer is invoked;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;"Each zone in the zonelist that __alloc_pages() was called with is checked for
the newly-introduced ZONE_OOM_LOCKED flag";David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;" If any zone has this flag present,
the ""trylock"" to serialize the OOM killer fails and returns zero";David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODowOThkN2YxMjhhNGU1M2NiNjQ5MzA2Mjg5MTVhYzc2Nzc4NWUwZTYw;" Otherwise,
all the zones have ZONE_OOM_LOCKED set and the try_set_zone_oom() function
returns non-zero.";David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo3MGUyNGJkZjZkMmZlYWQxNDYzMWU3MmEwN2ZiYTAxMjQwMGM1MjFl;oom: move constraints to enum;David Rientjes;2007-10-17;1;0
MDY6Q29tbWl0MjMyNTI5ODo3MGUyNGJkZjZkMmZlYWQxNDYzMWU3MmEwN2ZiYTAxMjQwMGM1MjFl;"The OOM killer's CONSTRAINT definitions are really more appropriate in an
enum, so define them in include/linux/oom.h.";David Rientjes;2007-10-17;1;1
MDY6Q29tbWl0MjMyNTI5ODplZTMxYWY1ZDY0OWQ4YWE2YWM3OTQ4YTZkOTdhZTQ4MzY3ZmYyZDdl;Memoryless nodes: OOM: use N_HIGH_MEMORY map instead of constructing one on the fly;Christoph Lameter;2007-10-16;1;0
MDY6Q29tbWl0MjMyNTI5ODplZTMxYWY1ZDY0OWQ4YWE2YWM3OTQ4YTZkOTdhZTQ4MzY3ZmYyZDdl;constrained_alloc() builds its own memory map for nodes with memory;Christoph Lameter;2007-10-16;0;0
MDY6Q29tbWl0MjMyNTI5ODplZTMxYWY1ZDY0OWQ4YWE2YWM3OTQ4YTZkOTdhZTQ4MzY3ZmYyZDdl;" We have
that available in N_HIGH_MEMORY now";Christoph Lameter;2007-10-16;0;1
MDY6Q29tbWl0MjMyNTI5ODplZTMxYWY1ZDY0OWQ4YWE2YWM3OTQ4YTZkOTdhZTQ4MzY3ZmYyZDdl; So simplify the code.;Christoph Lameter;2007-10-16;1;1
MDY6Q29tbWl0MjMyNTI5ODphNWU1OGE2MTQyMGU5OWRkMDg2ODVmNjIyZDRkYzY2NmJmMDdlOWE1;oom: print points as unsigned long;David Rientjes;2007-07-31;1;0
MDY6Q29tbWl0MjMyNTI5ODphNWU1OGE2MTQyMGU5OWRkMDg2ODVmNjIyZDRkYzY2NmJmMDdlOWE1;In badness(), the automatic variable 'points' is unsigned long;David Rientjes;2007-07-31;0;1
MDY6Q29tbWl0MjMyNTI5ODphNWU1OGE2MTQyMGU5OWRkMDg2ODVmNjIyZDRkYzY2NmJmMDdlOWE1;" Print it
as such.";David Rientjes;2007-07-31;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;Remove fs.h from mm.h;Alexey Dobriyan;2007-07-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;Remove fs.h from mm.h;Alexey Dobriyan;2007-07-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;"For this,
 1) Uninline vma_wants_writenotify()";Alexey Dobriyan;2007-07-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;It's pretty huge anyway;Alexey Dobriyan;2007-07-29;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0; 2) Add back fs.h or less bloated headers (err.h) to files that need it;Alexey Dobriyan;2007-07-29;1;1
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;"As result, on x86_64 allyesconfig, fs.h dependencies cut down from 3929 files
rebuilt down to 3444 (-12.3%)";Alexey Dobriyan;2007-07-29;0;1
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;Cross-compile tested without regressions on my two usual configs and (sigh);Alexey Dobriyan;2007-07-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo0ZTk1MGY2ZjAxODlmNjVmOGJmMDY5Y2YyMjcyNjQ5ZWY0MThmNWU0;"alpha              arm-mx1ads        mips-bigsur          powerpc-ebony
alpha-allnoconfig  arm-neponset      mips-capcella        powerpc-g5
alpha-defconfig    arm-netwinder     mips-cobalt          powerpc-holly
alpha-up           arm-netx          mips-db1000          powerpc-iseries
arm                arm-ns9xxx        mips-db1100          powerpc-linkstation
arm-assabet        arm-omap_h2_1610  mips-db1200          powerpc-lite5200
arm-at91rm9200dk   arm-onearm        mips-db1500          powerpc-maple
arm-at91rm9200ek   arm-picotux200    mips-db1550          powerpc-mpc7448_hpc2
arm-at91sam9260ek  arm-pleb          mips-ddb5477         powerpc-mpc8272_ads
arm-at91sam9261ek  arm-pnx4008       mips-decstation      powerpc-mpc8313_rdb
arm-at91sam9263ek  arm-pxa255-idp    mips-e55             powerpc-mpc832x_mds
arm-at91sam9rlek   arm-realview      mips-emma2rh         powerpc-mpc832x_rdb
arm-ateb9200       arm-realview-smp  mips-excite          powerpc-mpc834x_itx
arm-badge4         arm-rpc           mips-fulong          powerpc-mpc834x_itxgp
arm-carmeva        arm-s3c2410       mips-ip22            powerpc-mpc834x_mds
arm-cerfcube       arm-shannon       mips-ip27            powerpc-mpc836x_mds
arm-clps7500       arm-shark         mips-ip32            powerpc-mpc8540_ads
arm-collie         arm-simpad        mips-jazz            powerpc-mpc8544_ds
arm-corgi          arm-spitz         mips-jmr3927         powerpc-mpc8560_ads
arm-csb337         arm-trizeps4      mips-malta           powerpc-mpc8568mds
arm-csb637         arm-versatile     mips-mipssim         powerpc-mpc85xx_cds
arm-ebsa110        i386              mips-mpc30x          powerpc-mpc8641_hpcn
arm-edb7211        i386-allnoconfig  mips-msp71xx         powerpc-mpc866_ads
arm-em_x270        i386-defconfig    mips-ocelot          powerpc-mpc885_ads
arm-ep93xx         i386-up           mips-pb1100          powerpc-pasemi
arm-footbridge     ia64              mips-pb1500          powerpc-pmac32
arm-fortunet       ia64-allnoconfig  mips-pb1550          powerpc-ppc64
arm-h3600          ia64-bigsur       mips-pnx8550-jbs     powerpc-prpmc2800
arm-h7201          ia64-defconfig    mips-pnx8550-stb810  powerpc-ps3
arm-h7202          ia64-gensparse    mips-qemu            powerpc-pseries
arm-hackkit        ia64-sim          mips-rbhma4200       powerpc-up
arm-integrator     ia64-sn2          mips-rbhma4500       s390
arm-iop13xx        ia64-tiger        mips-rm200           s390-allnoconfig
arm-iop32x         ia64-up           mips-sb1250-swarm    s390-defconfig
arm-iop33x         ia64-zx1          mips-sead            s390-up
arm-ixp2000        m68k              mips-tb0219          sparc
arm-ixp23xx        m68k-amiga        mips-tb0226          sparc-allnoconfig
arm-ixp4xx         m68k-apollo       mips-tb0287          sparc-defconfig
arm-jornada720     m68k-atari        mips-workpad         sparc-up
arm-kafa           m68k-bvme6000     mips-wrppmc          sparc64
arm-kb9202         m68k-hp300        mips-yosemite        sparc64-allnoconfig
arm-ks8695         m68k-mac          parisc               sparc64-defconfig
arm-lart           m68k-mvme147      parisc-allnoconfig   sparc64-up
arm-lpd270         m68k-mvme16x      parisc-defconfig     um-x86_64
arm-lpd7a400       m68k-q40          parisc-up            x86_64
arm-lpd7a404       m68k-sun3         powerpc              x86_64-allnoconfig
arm-lubbock        m68k-sun3x        powerpc-cell         x86_64-defconfig
arm-lusl7200       mips              powerpc-celleb       x86_64-up
arm-mainstone      mips-atlas        powerpc-chrp32";Alexey Dobriyan;2007-07-29;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;oom: fix constraint deadlock;David Rientjes;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;"Fixes a deadlock in the OOM killer for allocations that are not
__GFP_HARDWALL";David Rientjes;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;"Before the OOM killer checks for the allocation constraint, it takes
callback_mutex";David Rientjes;2007-05-06;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;"constrained_alloc() iterates through each zone in the allocation zonelist
and calls cpuset_zone_allowed_softwall() to determine whether an allocation
for gfp_mask is possible";David Rientjes;2007-05-06;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;" If a zone's node is not in the OOM-triggering
task's mems_allowed, it is not exiting, and we did not fail on a
__GFP_HARDWALL allocation, cpuset_zone_allowed_softwall() attempts to take
callback_mutex to check the nearest exclusive ancestor of current's cpuset";David Rientjes;2007-05-06;0;0
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh; This results in deadlock;David Rientjes;2007-05-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoyYjQ1YWIzMzk4YTBiYTExOWIxZjY3MmM3YzU2ZmQ1YTQzMWI3ZjBh;"We now take callback_mutex after iterating through the zonelist since we
don't need it yet.";David Rientjes;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYjc0NGMwMWE1NGZlMGM5OTc0ZmYxYjI5NTIyZjI1ZjA3MDg0MDUz;mm: fix handling of panic_on_oom when cpusets are in use;Yasunori Goto;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYjc0NGMwMWE1NGZlMGM5OTc0ZmYxYjI5NTIyZjI1ZjA3MDg0MDUz;"The current panic_on_oom may not work if there is a process using
cpusets/mempolicy, because other nodes' memory may remain";Yasunori Goto;2007-05-06;0;1
MDY6Q29tbWl0MjMyNTI5ODoyYjc0NGMwMWE1NGZlMGM5OTc0ZmYxYjI5NTIyZjI1ZjA3MDg0MDUz;" But some people
want failover by panic ASAP even if they are used";Yasunori Goto;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODoyYjc0NGMwMWE1NGZlMGM5OTc0ZmYxYjI5NTIyZjI1ZjA3MDg0MDUz;" This patch makes new
setting for its request";Yasunori Goto;2007-05-06;1;0
MDY6Q29tbWl0MjMyNTI5ODoyYjc0NGMwMWE1NGZlMGM5OTc0ZmYxYjI5NTIyZjI1ZjA3MDg0MDUz;This is tested on my ia64 box which has 3 nodes.;Yasunori Goto;2007-05-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YTgyNzgyZjhmNTgyMTlkMGM2ZGM1ZjAyMTFjZTMwMWFkZjZjNmY0;allow oom_adj of saintly processes;Joshua N Pritikin;2007-05-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YTgyNzgyZjhmNTgyMTlkMGM2ZGM1ZjAyMTFjZTMwMWFkZjZjNmY0;If the badness of a process is zero then oom_adj>0 has no effect;Joshua N Pritikin;2007-05-06;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YTgyNzgyZjhmNTgyMTlkMGM2ZGM1ZjAyMTFjZTMwMWFkZjZjNmY0;" This
patch makes sure that the oom_adj shift actually increases badness points
appropriately.";Joshua N Pritikin;2007-05-06;1;1
MDY6Q29tbWl0MjMyNTI5ODozZDEyNGNiYmEzMTY3MzdhZjhmM2E2OTU5ZWRiOTViYmQxMzBhNGQ4;fix OOM killing processes wrongly thought MPOL_BIND;Hugh Dickins;2007-04-23;1;1
MDY6Q29tbWl0MjMyNTI5ODozZDEyNGNiYmEzMTY3MzdhZjhmM2E2OTU5ZWRiOTViYmQxMzBhNGQ4;"I only have CONFIG_NUMA=y for build testing: surprised when trying a memhog
to see lots of other processes killed with ""No available memory
(MPOL_BIND)""";Hugh Dickins;2007-04-23;0;1
MDY6Q29tbWl0MjMyNTI5ODozZDEyNGNiYmEzMTY3MzdhZjhmM2E2OTU5ZWRiOTViYmQxMzBhNGQ4;" memhog is killed correctly once we initialize nodemask in
constrained_alloc().";Hugh Dickins;2007-04-23;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NTBhN2M5NzRmMWI5MWRlOTczMmMwZjcyMGU3OTI4MzdmOGFiZmQ2;oom: kill all threads that share mm with killed task;David Rientjes;2007-04-24;1;0
MDY6Q29tbWl0MjMyNTI5ODo2NTBhN2M5NzRmMWI5MWRlOTczMmMwZjcyMGU3OTI4MzdmOGFiZmQ2;oom_kill_task() calls __oom_kill_task() to OOM kill a selected task;David Rientjes;2007-04-24;0;0
MDY6Q29tbWl0MjMyNTI5ODo2NTBhN2M5NzRmMWI5MWRlOTczMmMwZjcyMGU3OTI4MzdmOGFiZmQ2;"When finding other threads that share an mm with that task, we need to
kill those individual threads and not the same one";David Rientjes;2007-04-24;0;1
MDY6Q29tbWl0MjMyNTI5ODo2NTBhN2M5NzRmMWI5MWRlOTczMmMwZjcyMGU3OTI4MzdmOGFiZmQ2;(Bug introduced by f2a2a7108aa0039ba7a5fe7a0d2ecef2219a7584);David Rientjes;2007-04-24;0;1
MDY6Q29tbWl0MjMyNTI5ODozNWFlODM0ZmEwMmJhODljZmJkNGE4MDg5MmMwZTQ1OGZkNmQ1YzBi;[PATCH] oom fix: prevent oom from killing a process with children/sibling unkillable;Ankita Garg;2007-03-16;1;1
MDY6Q29tbWl0MjMyNTI5ODozNWFlODM0ZmEwMmJhODljZmJkNGE4MDg5MmMwZTQ1OGZkNmQ1YzBi;"Looking at oom_kill.c, found that the intention to not kill the selected
process if any of its children/siblings has OOM_DISABLE set, is not being
met.";Ankita Garg;2007-03-16;0;0
MDY6Q29tbWl0MjMyNTI5ODo3YmEzNDg1OTQ3ZWU3YmM4OWExN2Y4NjI1MGZlOWI2OTJhNjE1ZGZm;[PATCH] fix OOM killing of swapoff;Hugh Dickins;2007-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo3YmEzNDg1OTQ3ZWU3YmM4OWExN2Y4NjI1MGZlOWI2OTJhNjE1ZGZm;"These days, if you swapoff when there isn't enough memory, OOM killer gives
""BUG: scheduling while atomic"" and the machine hangs: badness() needs to do
its PF_SWAPOFF return after the task_unlock (tasklist_lock is also held
here, so p isn't going to be freed: PF_SWAPOFF might get turned off at any
moment, but that doesn't really matter).";Hugh Dickins;2007-01-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;[PATCH] fix oom killer kills current every time if there is memory-less-node take2;KAMEZAWA Hiroyuki;2006-12-30;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;"constrained_alloc(), which is called to detect where oom is from, checks
passed zone_list()";KAMEZAWA Hiroyuki;2006-12-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;" If zone_list doesn't include all nodes, it thinks oom
is from mempolicy";KAMEZAWA Hiroyuki;2006-12-30;1;0
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;But there is memory-less-node;KAMEZAWA Hiroyuki;2006-12-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;" memory-less-node's zones are never included
in zonelist[]";KAMEZAWA Hiroyuki;2006-12-30;0;0
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;contstrained_alloc() should get memory_less_node into count;KAMEZAWA Hiroyuki;2006-12-30;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;" Otherwise, it
always thinks 'oom is from mempolicy'";KAMEZAWA Hiroyuki;2006-12-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh;" This means that current process
dies at any time";KAMEZAWA Hiroyuki;2006-12-30;0;1
MDY6Q29tbWl0MjMyNTI5ODo5NmFjNTkxM2Y0ZTQ1YzZhMWI5ODM1MGYyYzBhOGJiM2FiZTI2NDZh; This patch fix it.;KAMEZAWA Hiroyuki;2006-12-30;1;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;[PATCH] cpuset: rework cpuset_zone_allowed api;Paul Jackson;2006-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"Elaborate the API for calling cpuset_zone_allowed(), so that users have to
explicitly choose between the two variants";Paul Jackson;2006-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"  cpuset_zone_allowed_hardwall()
  cpuset_zone_allowed_softwall()
Until now, whether or not you got the hardwall flavor depended solely on
whether or not you or'd in the __GFP_HARDWALL gfp flag to the gfp_mask
argument";Paul Jackson;2006-12-13;0;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"If you didn't specify __GFP_HARDWALL, you implicitly got the softwall
version";Paul Jackson;2006-12-13;0;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"Unfortunately, this meant that users would end up with the softwall version
without thinking about it";Paul Jackson;2006-12-13;0;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;" Since only the softwall version might sleep,
this led to bugs with possible sleeping in interrupt context on more than
one occassion";Paul Jackson;2006-12-13;0;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"The hardwall version requires that the current tasks mems_allowed allows
the node of the specified zone (or that you're in interrupt or that
__GFP_THISNODE is set or that you're on a one cpuset system.)
The softwall version, depending on the gfp_mask, might allow a node if it
was allowed in the nearest enclusing cpuset marked mem_exclusive (which
requires taking the cpuset lock 'callback_mutex' to evaluate.)
This patch removes the cpuset_zone_allowed() call, and forces the caller to
explicitly choose between the hardwall and the softwall case";Paul Jackson;2006-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"If the caller wants the gfp_mask to determine this choice, they should (1)
be sure they can sleep or that __GFP_HARDWALL is set, and (2) invoke the
cpuset_zone_allowed_softwall() routine";Paul Jackson;2006-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"This adds another 100 or 200 bytes to the kernel text space, due to the few
lines of nearly duplicate code at the top of both cpuset_zone_allowed_*
routines";Paul Jackson;2006-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;" It should save a few instructions executed for the calls that
turned into calls of cpuset_zone_allowed_hardwall, thanks to not having to
set (before the call) then check (within the call) the __GFP_HARDWALL flag";Paul Jackson;2006-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"For the most critical call, from get_page_from_freelist(), the same
instructions are executed as before -- the old cpuset_zone_allowed()
routine it used to call is the same code as the
cpuset_zone_allowed_softwall() routine that it calls now";Paul Jackson;2006-12-13;1;0
MDY6Q29tbWl0MjMyNTI5ODowMmEwZTUzZDgyMjdhZmY1ZTYyZTA0MzNmODJjMTJjMWMyODA1ZmQ2;"Not a perfect win, but seems worth it, to reduce this chance of hitting a
sleeping with irq off complaint again.";Paul Jackson;2006-12-13;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMmEyYTcxMDhhYTAwMzliYTdhNWZlN2EwZDJlY2VmMjIxOWE3NTg0;[PATCH] oom: less memdie;Nick Piggin;2006-12-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpmMmEyYTcxMDhhYTAwMzliYTdhNWZlN2EwZDJlY2VmMjIxOWE3NTg0;"Don't cause all threads in all other thread groups to gain TIF_MEMDIE
otherwise we'll get a thundering herd eating our memory reserve";Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmMmEyYTcxMDhhYTAwMzliYTdhNWZlN2EwZDJlY2VmMjIxOWE3NTg0;" This may not
be the optimal scheme, but it fits our policy of allowing just one TIF_MEMDIE
in the system at once.";Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmM2FmMzhkMzBjMTg1MzhkMDY5YTk1ZTYyNGEzZGI3YzNkNDg2YTFl;[PATCH] oom: cleanup messages;Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpmM2FmMzhkMzBjMTg1MzhkMDY5YTk1ZTYyNGEzZGI3YzNkNDg2YTFl;Clean up the OOM killer messages to be more consistent.;Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzNlMGZjYTM1MDhmMGFhMzg3YjFjMTBkMGVmMTU4MTAyZGViMTQw;[PATCH] oom: don't kill unkillable children or siblings;Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzNlMGZjYTM1MDhmMGFhMzg3YjFjMTBkMGVmMTU4MTAyZGViMTQw;Abort the kill if any of our threads have OOM_DISABLE set;Nick Piggin;2006-12-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzNlMGZjYTM1MDhmMGFhMzg3YjFjMTBkMGVmMTU4MTAyZGViMTQw;" Having this
test here also prevents any OOM_DISABLE child of the ""selected"" process
from being killed.";Nick Piggin;2006-12-07;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YWM3NzNiNGY3M2FmYTZmZDY2Njk1MTMxMTAzOTQ0Yjk3NWQ1ZDVj;[PATCH] OOM killer meets userspace headers;Alexey Dobriyan;2006-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YWM3NzNiNGY3M2FmYTZmZDY2Njk1MTMxMTAzOTQ0Yjk3NWQ1ZDVj;"Despite mm.h is not being exported header, it does contain one thing
which is part of userspace ABI -- value disabling OOM killer for given
process";Alexey Dobriyan;2006-10-20;0;1
MDY6Q29tbWl0MjMyNTI5ODo4YWM3NzNiNGY3M2FmYTZmZDY2Njk1MTMxMTAzOTQ0Yjk3NWQ1ZDVj;"So,
a) create and export include/linux/oom.h
b) move OOM_DISABLE define there";Alexey Dobriyan;2006-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YWM3NzNiNGY3M2FmYTZmZDY2Njk1MTMxMTAzOTQ0Yjk3NWQ1ZDVj;"c) turn bounding values of /proc/$PID/oom_adj into defines and export
   them too";Alexey Dobriyan;2006-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YWM3NzNiNGY3M2FmYTZmZDY2Njk1MTMxMTAzOTQ0Yjk3NWQ1ZDVj;Note: mass __KERNEL__ removal will be done later.;Alexey Dobriyan;2006-10-20;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNzg0ODNhNGJhNjBkNWQ5MDkzMDI2MmE1MzNhNzg0ZTFkOWRmNjYw;[PATCH] oom: don't kill current when another OOM in progress;Nick Piggin;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNzg0ODNhNGJhNjBkNWQ5MDkzMDI2MmE1MzNhNzg0ZTFkOWRmNjYw;"A previous patch to allow an exiting task to OOM kill itself (and thereby
avoid a little deadlock) introduced a problem";Nick Piggin;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODpiNzg0ODNhNGJhNjBkNWQ5MDkzMDI2MmE1MzNhNzg0ZTFkOWRmNjYw;" We don't want the
PF_EXITING task, even if it is 'current', to access mem reserves if there
is already a TIF_MEMDIE process in the system sucking up reserves";Nick Piggin;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNzg0ODNhNGJhNjBkNWQ5MDkzMDI2MmE1MzNhNzg0ZTFkOWRmNjYw;"Also make the commenting a little bit clearer, and note that our current
scheme of effectively single threading the OOM killer is not itself
perfect.";Nick Piggin;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODowMTAxN2EyMjcwNDRkNjRmYWNlMjU4OGZhYjk0MjdhMWRhMWJkYjlm;[PATCH] oom_kill_task(): cleanup ->mm checks;Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODowMTAxN2EyMjcwNDRkNjRmYWNlMjU4OGZhYjk0MjdhMWRhMWJkYjlm;- It is not possible to have task->mm == &init_mm;Oleg Nesterov;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODowMTAxN2EyMjcwNDRkNjRmYWNlMjU4OGZhYjk0MjdhMWRhMWJkYjlm;- task_lock() buys nothing for 'if (!p->mm)' check.;Oleg Nesterov;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODo5NzJjNGVhNTljOWRiZjgyNjQ3ZWU5NjY1ZDllOTQ1MjQxOTExYTUx;[PATCH] select_bad_process(): cleanup 'releasing' check;Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODo5NzJjNGVhNTljOWRiZjgyNjQ3ZWU5NjY1ZDllOTQ1MjQxOTExYTUx;No logic changes, but imho easier to read.;Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODoyODMyNGQxZGY2NDY1MjEyNTZlODMzODkyNDRhZGNjZTk4ZTg5ZmYy;[PATCH] select_bad_process(): kill a bogus PF_DEAD/TASK_DEAD check;Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODoyODMyNGQxZGY2NDY1MjEyNTZlODMzODkyNDRhZGNjZTk4ZTg5ZmYy;"The only one usage of TASK_DEAD outside of last schedule path,
select_bad_process";Oleg Nesterov;2006-09-29;0;0
MDY6Q29tbWl0MjMyNTI5ODoyODMyNGQxZGY2NDY1MjEyNTZlODMzODkyNDRhZGNjZTk4ZTg5ZmYy;"TASK_DEAD state is set at the end of do_exit(), this means that p->mm
was already set == NULL by exit_mm(), so this task was already rejected
by 'if (!p->mm)' above";Oleg Nesterov;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODoyODMyNGQxZGY2NDY1MjEyNTZlODMzODkyNDRhZGNjZTk4ZTg5ZmYy;"Note also that the caller holds tasklist_lock, this means that p can't
pass exit_notify() and then set TASK_DEAD when p->mm != NULL";Oleg Nesterov;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODoyODMyNGQxZGY2NDY1MjEyNTZlODMzODkyNDRhZGNjZTk4ZTg5ZmYy;Also, remove open-coded is_init().;Oleg Nesterov;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzk0Y2M5ZmJiMzY3Zjg3ZmFhMjIyOGVjMmVhYmFjZDJkNDcwMWM2;[PATCH] introduce TASK_DEAD state;Oleg Nesterov;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzk0Y2M5ZmJiMzY3Zjg3ZmFhMjIyOGVjMmVhYmFjZDJkNDcwMWM2;I am not sure about this patch, I am asking Ingo to take a decision;Oleg Nesterov;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpjMzk0Y2M5ZmJiMzY3Zjg3ZmFhMjIyOGVjMmVhYmFjZDJkNDcwMWM2;"task_struct->state == EXIT_DEAD is a very special case, to avoid a confusion
it makes sense to introduce a new state, TASK_DEAD, while EXIT_DEAD should
live only in ->exit_state as documented in sched.h";Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODpjMzk0Y2M5ZmJiMzY3Zjg3ZmFhMjIyOGVjMmVhYmFjZDJkNDcwMWM2;"Note that this state is not visible to user-space, get_task_state() masks off
unsuitable states.";Oleg Nesterov;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NWExMDFmOGY3MWEzZDNkYmRhN2I1Yzc3MDgzZmZlNDc1NTJmODMx;[PATCH] kill PF_DEAD flag;Oleg Nesterov;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NWExMDFmOGY3MWEzZDNkYmRhN2I1Yzc3MDgzZmZlNDc1NTJmODMx;"After the previous change (->flags & PF_DEAD) <=> (->state == EXIT_DEAD), we
don't need PF_DEAD any longer.";Oleg Nesterov;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;[PATCH] pidspace: is_init();Sukadev Bhattiprolu;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;This is an updated version of Eric Biederman's is_init() patch;Sukadev Bhattiprolu;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;"( It applies cleanly to 2.6.18-rc3 and
replaces a few more instances of ->pid == 1 with is_init()";Sukadev Bhattiprolu;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;"Further, is_init() checks pid and thus removes dependency on Eric's other
patches for now";Sukadev Bhattiprolu;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;Eric's original description;Sukadev Bhattiprolu;2006-09-29;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;"	There are a lot of places in the kernel where we test for init
	because we give it special properties";Sukadev Bhattiprolu;2006-09-29;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;" Most  significantly init
	must not die";Sukadev Bhattiprolu;2006-09-29;0;0
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;" This results in code all over the kernel test
	->pid == 1";Sukadev Bhattiprolu;2006-09-29;0;1
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;	Introduce is_init to capture this case;Sukadev Bhattiprolu;2006-09-29;1;1
MDY6Q29tbWl0MjMyNTI5ODpmNDAwZTE5OGIyZWQyNmNlNTViMjJhMTQxMmRlZDA4OTZlNzUxNmFj;"	With multiple pid spaces for all of the cases affected we are
	looking for only the first process on the system, not some other
	process that has pid == 1.";Sukadev Bhattiprolu;2006-09-29;1;0
MDY6Q29tbWl0MjMyNTI5ODo4OWZhMzAyNDJmYWNjYTI0OWFlYWQyYWFjMDNjNGM2OTc2NGY5MTFj;[PATCH] NUMA: Add zone_to_nid function;Christoph Lameter;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo4OWZhMzAyNDJmYWNjYTI0OWFlYWQyYWFjMDNjNGM2OTc2NGY5MTFj;There are many places where we need to determine the node of a zone;Christoph Lameter;2006-09-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo4OWZhMzAyNDJmYWNjYTI0OWFlYWQyYWFjMDNjNGM2OTc2NGY5MTFj;Currently we use a difficult to read sequence of pointer dereferencing;Christoph Lameter;2006-09-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo4OWZhMzAyNDJmYWNjYTI0OWFlYWQyYWFjMDNjNGM2OTc2NGY5MTFj;Put that into an inline function and use throughout VM;Christoph Lameter;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo4OWZhMzAyNDJmYWNjYTI0OWFlYWQyYWFjMDNjNGM2OTc2NGY5MTFj;" Maybe we can find
a way to optimize the lookup in the future.";Christoph Lameter;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTI5MWI5OGIyMTE2ZDY2OTQ0OTg4NWFiZWYzMDAwZjc0NzUwNGIz;[PATCH] oom-kill: update comments to reflect current code;Ram Gupta;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1YTI5MWI5OGIyMTE2ZDY2OTQ0OTg4NWFiZWYzMDAwZjc0NzUwNGIz;Update the comments for __oom_kill_task() to reflect the code changes.;Ram Gupta;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNzJmMTYwNDQzY2I3OGIyZjhhZGRhZTZlMzMxZDJhZGFhNzBmODY5;[PATCH] oom: more printk;Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODpiNzJmMTYwNDQzY2I3OGIyZjhhZGRhZTZlMzMxZDJhZGFhNzBmODY5;Print the name of the task invoking the OOM killer;Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODpiNzJmMTYwNDQzY2I3OGIyZjhhZGRhZTZlMzMxZDJhZGFhNzBmODY5;" Could make debugging
easier.";Nick Piggin;2006-09-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MDgxZGRlMzNmN2E2MWQyOGQ5YjE4NWNjMzg2ZjEyY2I4MzdjN2E0;[PATCH] oom: kthread infinite loop fix;Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MDgxZGRlMzNmN2E2MWQyOGQ5YjE4NWNjMzg2ZjEyY2I4MzdjN2E0;Skip kernel threads, rather than having them return 0 from badness;Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo1MDgxZGRlMzNmN2E2MWQyOGQ5YjE4NWNjMzg2ZjEyY2I4MzdjN2E0;"Theoretically, badness might truncate all results to 0, thus a kernel thread
might be picked first, causing an infinite loop.";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODphZjViOTEyNDM1ZGUzMmZiZWRlMDhjZWU5NDk0Mjk4MjNlZDQ5Nzgx;[PATCH] oom: swapoff tasks tweak;Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODphZjViOTEyNDM1ZGUzMmZiZWRlMDhjZWU5NDk0Mjk4MjNlZDQ5Nzgx;"PF_SWAPOFF processes currently cause select_bad_process to return straight
away";Nick Piggin;2006-09-26;0;0
MDY6Q29tbWl0MjMyNTI5ODphZjViOTEyNDM1ZGUzMmZiZWRlMDhjZWU5NDk0Mjk4MjNlZDQ5Nzgx;" Instead, give them high priority, so we will kill them first, however
we also first ensure no parallel OOM kills are happening at the same time.";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YTNlZGUxMDdlNDIyYTBjNTNkMjgwMjRiMGFhOTAyY2EyMmE4NzY4;[PATCH] oom: handle oom_disable exiting;Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YTNlZGUxMDdlNDIyYTBjNTNkMjgwMjRiMGFhOTAyY2EyMmE4NzY4;"Having the oomkilladj == OOM_DISABLE check before the releasing check means
that oomkilladj == OOM_DISABLE tasks exiting will not stop the OOM killer";Nick Piggin;2006-09-26;0;0
MDY6Q29tbWl0MjMyNTI5ODo0YTNlZGUxMDdlNDIyYTBjNTNkMjgwMjRiMGFhOTAyY2EyMmE4NzY4;Moving the test down will give the desired behaviour;Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YTNlZGUxMDdlNDIyYTBjNTNkMjgwMjRiMGFhOTAyY2EyMmE4NzY4;" Also: it will allow
them to ""OOM-kill"" themselves if they are exiting";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo0YTNlZGUxMDdlNDIyYTBjNTNkMjgwMjRiMGFhOTAyY2EyMmE4NzY4;" As per the previous patch,
this is required to prevent OOM killer deadlocks (and they don't actually get
killed, because they're already exiting -- they're simply allowed access to
memory reserves).";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;[PATCH] oom: handle current exiting;Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;"If current *is* exiting, it should actually be allowed to access reserved
memory rather than OOM kill something else";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;" Can't do this via a straight
check in page_alloc.c because that would allow multiple tasks to use up
reserves";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;" Instead cause current to OOM-kill itself which will mark it as
TIF_MEMDIE";Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;"The current procedure of simply aborting the OOM-kill if a task is exiting can
lead to OOM deadlocks";Nick Piggin;2006-09-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;In the case of killing a PF_EXITING task, don't make a lot of noise about it;Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo1MGVjM2JiZmZiZThhOTYzNDdjNTQ4MzJkNDgxMTBhNWJjOWU5ZmY4;"This becomes more important in future patches, where we can ""kill"" OOM_DISABLE
tasks.";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo3ODg3YTNkYTc1M2UxYmE4MjQ0NTU2Y2M5YTJiMzhjODE1YmZlMjU2;[PATCH] oom: cpuset hint;Nick Piggin;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo3ODg3YTNkYTc1M2UxYmE4MjQ0NTU2Y2M5YTJiMzhjODE1YmZlMjU2;"cpuset_excl_nodes_overlap does not always indicate that killing a task will
not free any memory we for us";Nick Piggin;2006-09-26;0;1
MDY6Q29tbWl0MjMyNTI5ODo3ODg3YTNkYTc1M2UxYmE4MjQ0NTU2Y2M5YTJiMzhjODE1YmZlMjU2;" For example, we may be asking for an
allocation from _anywhere_ in the machine, or the task in question may be
pinning memory that is outside its cpuset";Nick Piggin;2006-09-26;0;0
MDY6Q29tbWl0MjMyNTI5ODo3ODg3YTNkYTc1M2UxYmE4MjQ0NTU2Y2M5YTJiMzhjODE1YmZlMjU2;" Fix this by just causing
cpuset_excl_nodes_overlap to reduce the badness rather than disallow it.";Nick Piggin;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;[PATCH] out of memory notifier;Martin Schwidefsky;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;Add a notifer chain to the out of memory killer;Martin Schwidefsky;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;" If one of the registered
callbacks could release some memory, do not kill the process but return and
retry the allocation that forced the oom killer to run";Martin Schwidefsky;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;"The purpose of the notifier is to add a safety net in the presence of
memory ballooners";Martin Schwidefsky;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;" If the resource manager inflated the balloon to a size
where memory allocations can not be satisfied anymore, it is better to
deflate the balloon a bit instead of killing processes";Martin Schwidefsky;2006-09-26;1;1
MDY6Q29tbWl0MjMyNTI5ODo4YmM3MTlkM2NhYjg0MTQ5MzhmOWVhNmUzM2I1OGQ4ODEwZDE4MDY4;The implementation for the s390 ballooner is included.;Martin Schwidefsky;2006-09-26;1;0
MDY6Q29tbWl0MjMyNTI5ODozNmM4YjU4Njg5NmY2MGNiOTFhNGZkNTI2MjMzMTkwYjM0MzE2YmFm;[PATCH] sched: cleanup, remove task_t, convert to struct task_struct;Ingo Molnar;2006-07-03;1;1
MDY6Q29tbWl0MjMyNTI5ODozNmM4YjU4Njg5NmY2MGNiOTFhNGZkNTI2MjMzMTkwYjM0MzE2YmFm;cleanup: remove task_t and convert all the uses to struct task_struct;Ingo Molnar;2006-07-03;1;1
MDY6Q29tbWl0MjMyNTI5ODozNmM4YjU4Njg5NmY2MGNiOTFhNGZkNTI2MjMzMTkwYjM0MzE2YmFm;"I
introduced it for the scheduler anno and it was a mistake";Ingo Molnar;2006-07-03;0;1
MDY6Q29tbWl0MjMyNTI5ODozNmM4YjU4Njg5NmY2MGNiOTFhNGZkNTI2MjMzMTkwYjM0MzE2YmFm;"Conversion was mostly scripted, the result was reviewed and all
secondary whitespace and style impact (if any) was fixed up by hand.";Ingo Molnar;2006-07-03;1;0
MDY6Q29tbWl0MjMyNTI5ODo2OTM3YTI1Y2ZmODE4ZDMyZDBmOWZmNThhNTE4YzlhYjk2NzYwYWVi;[PATCH] mm: fix typos in comments in mm/oom_kill.c;Dave Peterson;2006-06-23;1;1
MDY6Q29tbWl0MjMyNTI5ODo2OTM3YTI1Y2ZmODE4ZDMyZDBmOWZmNThhNTE4YzlhYjk2NzYwYWVi;This fixes a few typos in the comments in mm/oom_kill.c.;Dave Peterson;2006-06-23;1;1
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;[PATCH] support for panic at OOM;KAMEZAWA Hiroyuki;2006-06-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;This patch adds panic_on_oom sysctl under sys.vm;KAMEZAWA Hiroyuki;2006-06-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;"When sysctl vm.panic_on_oom = 1, the kernel panics intead of killing rogue
processes";KAMEZAWA Hiroyuki;2006-06-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;" And if vm.panic_on_oom is 0 the kernel will do oom_kill() in
the same way as it does today";KAMEZAWA Hiroyuki;2006-06-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;" Of course, the default value is 0 and only
root can modifies it";KAMEZAWA Hiroyuki;2006-06-23;1;0
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;In general, oom_killer works well and kill rogue processes;KAMEZAWA Hiroyuki;2006-06-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;" So the whole
system can survive";KAMEZAWA Hiroyuki;2006-06-23;0;1
MDY6Q29tbWl0MjMyNTI5ODpmYWRkOGZiZDE1M2MxMjk2M2Y4ZmUzYzllZjdmODk2N2YyODZmOThi;" But there are environments where panic is preferable
rather than kill some processes.";KAMEZAWA Hiroyuki;2006-06-23;1;1
MDY6Q29tbWl0MjMyNTI5ODowMTMxNTkyMjdiODQwZGZkNDQxYmQyZTRjOGI0ZDc3ZmZiM2NjNDJl;[PATCH] mm: fix mm_struct reference counting bugs in mm/oom_kill.c;Dave Peterson;2006-04-19;1;1
MDY6Q29tbWl0MjMyNTI5ODowMTMxNTkyMjdiODQwZGZkNDQxYmQyZTRjOGI0ZDc3ZmZiM2NjNDJl;"Fix oom_kill_task() so it doesn't call mmput() (which may sleep) while
holding tasklist_lock.";Dave Peterson;2006-04-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2MyYzliODRkMGMxZWRmNDkyNmIxMzY2MWQ1YWYzZjBlZGNjYmNl;[PATCH] oom-kill: mm locking fix;Andrew Morton;2006-04-19;1;1
MDY6Q29tbWl0MjMyNTI5ODo5N2MyYzliODRkMGMxZWRmNDkyNmIxMzY2MWQ1YWYzZjBlZGNjYmNl;"Dave Peterson <dsp@llnl.gov> points out that badness() is playing with
mm_structs without taking a reference on them";Andrew Morton;2006-04-19;0;0
MDY6Q29tbWl0MjMyNTI5ODo5N2MyYzliODRkMGMxZWRmNDkyNmIxMzY2MWQ1YWYzZjBlZGNjYmNl;"mmput() can sleep, so taking a reference here (inside tasklist_lock) is
hard";Andrew Morton;2006-04-19;0;1
MDY6Q29tbWl0MjMyNTI5ODo5N2MyYzliODRkMGMxZWRmNDkyNmIxMzY2MWQ1YWYzZjBlZGNjYmNl; Fix it up via task_lock() instead.;Andrew Morton;2006-04-19;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNDBmZmNlYzRkZWYzZWUzYWY3NTY1YjJjZjFkM2IyNTgwZjdlMTgw;[PATCH] out_of_memory() locking fix;Andrew Morton;2006-03-02;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNDBmZmNlYzRkZWYzZWUzYWY3NTY1YjJjZjFkM2IyNTgwZjdlMTgw;I seem to have lost this read_unlock();Andrew Morton;2006-03-02;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNDBmZmNlYzRkZWYzZWUzYWY3NTY1YjJjZjFkM2IyNTgwZjdlMTgw;"While we're there, let's turn that interruptible sleep unto uninterruptible,
so we don't get a busywait if signal_pending()";Andrew Morton;2006-03-02;1;1
MDY6Q29tbWl0MjMyNTI5ODoxNDBmZmNlYzRkZWYzZWUzYWY3NTY1YjJjZjFkM2IyNTgwZjdlMTgw; (Again;Andrew Morton;2006-03-02;0;0
MDY6Q29tbWl0MjMyNTI5ODoxNDBmZmNlYzRkZWYzZWUzYWY3NTY1YjJjZjFkM2IyNTgwZjdlMTgw;" We seem to have a
habit of doing this).";Andrew Morton;2006-03-02;0;0
MDY6Q29tbWl0MjMyNTI5ODpkNjcxM2UwNDYzMzZmZmE5ODA2MDQxOGM0ZDJjNjUyNDM2MzllMTA3;[PATCH] out_of_memory(): use of uninitialised;Andrew Morton;2006-03-01;1;1
MDY6Q29tbWl0MjMyNTI5ODpkNjcxM2UwNDYzMzZmZmE5ODA2MDQxOGM0ZDJjNjUyNDM2MzllMTA3;Under some circumstances `points' can get printed before it's initialised;Andrew Morton;2006-03-01;0;1
MDY6Q29tbWl0MjMyNTI5ODpkNjcxM2UwNDYzMzZmZmE5ODA2MDQxOGM0ZDJjNjUyNDM2MzllMTA3;Spotted by Carlos Martin <carlos@cmartin.tk>.;Andrew Morton;2006-03-01;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;[PATCH] Terminate process that fails on a constrained allocation;Christoph Lameter;2006-02-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;"Some allocations are restricted to a limited set of nodes (due to memory
policies or cpuset constraints)";Christoph Lameter;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;" If the page allocator is not able to find
enough memory then that does not mean that overall system memory is low";Christoph Lameter;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;"In particular going postal and more or less randomly shooting at processes
is not likely going to help the situation but may just lead to suicide (the
whole system coming down)";Christoph Lameter;2006-02-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;"It is better to signal to the process that no memory exists given the
constraints that the process (or the configuration of the process) has
placed on the allocation behavior";Christoph Lameter;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;" The process may be killed but then the
sysadmin or developer can investigate the situation";Christoph Lameter;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;" The solution is
similar to what we do when running out of hugepages";Christoph Lameter;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;This patch adds a check before we kill processes;Christoph Lameter;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;" At that point
performance considerations do not matter much so we just scan the zonelist
and reconstruct a list of nodes";Christoph Lameter;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5YjBmOGIwNDBhY2Q4ZGZkMjM4NjA3NTRjMGQwOWZmNGY0NGUyY2Jj;" If the list of nodes does not contain all
online nodes then this is a constrained allocation and we should kill the
current process.";Christoph Lameter;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;[PATCH] OOM kill: children accounting;Kurt Garloff;2006-02-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;In the badness() calculation, there's currently this piece of code;Kurt Garloff;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"The intention is clear: If some server (apache) keeps spawning new children
and we run OOM, we want to kill the father rather than picking a child";Kurt Garloff;2006-02-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"This -- to some degree -- also helps a bit with getting fork bombs under
control, though I'd consider this a desirable side-effect rather than a
feature";Kurt Garloff;2006-02-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"There's one problem with this: No matter how many or few children there are,
if just one of them misbehaves, and all others (including the father) do
everything right, we still always kill the whole family";Kurt Garloff;2006-02-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;" This hits in real
life; whether it's javascript in konqueror resulting in kdeinit (and thus the
whole KDE session) being hit or just a classical server that spawns children";Kurt Garloff;2006-02-21;0;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"Sidenote: The killer does kill all direct children as well, not only the
selected father, see oom_kill_process()";Kurt Garloff;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"The idea in attached patch is that we do want to account the memory
consumption of the (direct) children to the father -- however not fully";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"This maintains the property that fathers with too many children will still
very likely be picked, whereas a single misbehaving child has the chance to
be picked by the OOM killer";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"In the patch I account only half (rounded up) of the children's vm_size to
the parent";Kurt Garloff;2006-02-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;" This means that if one child eats more mem than the rest of
the family, it will be picked, otherwise it's still the father and thus the
whole family that gets selected";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"This is heuristics -- we could debate whether accounting for a fourth would
be better than for half of it";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;" Or -- if people would consider it worth the
trouble -- make it a sysctl";Kurt Garloff;2006-02-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;" For now I sticked to accounting for half,
which should IMHO be a significant improvement";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"The patch does one more thing: As users tend to be irritated by the choice
of killed processes (mainly because the children are killed first, despite
some of them having a very low OOM score), I added some more output: The
selected (father) process will be reported first and it's oom_score printed
to syslog";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;Description;Kurt Garloff;2006-02-21;0;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;"Only account for half of children's vm size in oom score calculation
This should still give the parent enough point in case of fork bombs";Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;" If
any child however has more than 50% of the vm size of all children
together, it'll get a higher score and be elected";Kurt Garloff;2006-02-21;1;0
MDY6Q29tbWl0MjMyNTI5ODo5ODI3Yjc4MWYyMDgyOGU1Y2ViOTExYjg3OWYyNjhmNzhmZTkwODE1;This patch also makes the kernel display the oom_score.;Kurt Garloff;2006-02-21;1;1
MDY6Q29tbWl0MjMyNTI5ODpiOTU4ZjdkOWYzNWJmYjYxNjI1ZjIwMWNkOTJhM2ZjMzk1MDRhZjdh;[PATCH] dump_stack() in oom handler;Andrew Morton;2006-02-01;1;0
MDY6Q29tbWl0MjMyNTI5ODpiOTU4ZjdkOWYzNWJmYjYxNjI1ZjIwMWNkOTJhM2ZjMzk1MDRhZjdh;Sometimes it's nice to know who's calling.;Andrew Morton;2006-02-01;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;[PATCH] cpuset oom lock fix;Paul Jackson;2006-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;The problem, reported in;Paul Jackson;2006-01-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;"and by various other email messages and lkml posts is that the cpuset hook
in the oom (out of memory) code can try to take a cpuset semaphore while
holding the tasklist_lock (a spinlock)";Paul Jackson;2006-01-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;One must not sleep while holding a spinlock;Paul Jackson;2006-01-14;0;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;"The fix seems easy enough - move the cpuset semaphore region outside the
tasklist_lock region";Paul Jackson;2006-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;This required a few lines of mechanism to implement;Paul Jackson;2006-01-14;1;0
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;" The oom code where
the locking needs to be changed does not have access to the cpuset locks,
which are internal to kernel/cpuset.c only";Paul Jackson;2006-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODo1MDU5NzBiOTZlM2I3ZDIyMTc3YzM4ZTAzNDM1YTY4Mzc2NjI4ZTdh;" So I provided a couple more
cpuset interface routines, available to the rest of the kernel, which
simple take and drop the lock needed here (cpusets callback_sem).";Paul Jackson;2006-01-14;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZjY1OWY0NjJkMmFiNTE5MDY4ZDBlMmJiNjc3ZDdhNzAwZGVjYjhk;[PATCH] Optimise oom kill of current task;Kirill Korotaev;2006-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODoyZjY1OWY0NjJkMmFiNTE5MDY4ZDBlMmJiNjc3ZDdhNzAwZGVjYjhk;"When oom_killer kills current there's no need to call
schedule_timeout_interruptible() since task must die ASAP.";Kirill Korotaev;2006-01-08;1;1
MDY6Q29tbWl0MjMyNTI5ODpkZDBmYzY2ZmIzM2NkNjEwYmMxYTVkYjhhNWUyMzJkMzQ4NzliNGQ3;[PATCH] gfp flags annotations - part 1;Al Viro;2005-10-07;1;0
MDY6Q29tbWl0MjMyNTI5ODpkZDBmYzY2ZmIzM2NkNjEwYmMxYTVkYjhhNWUyMzJkMzQ4NzliNGQ3;" - replaced __nocast uses for gfp flags with gfp_t - it gives exactly
   the same warnings as far as sparse is concerned, doesn't change
   generated code (from gcc point of view we replaced unsigned int with
   typedef) and documents what's going on far better.";Al Viro;2005-10-07;1;1
MDY6Q29tbWl0MjMyNTI5ODoxM2U0YjU3ZjZhNGUyM2NlYjk5Nzk0YTY1MGQ3NzdlNzQ4MzFmNGE2;[PATCH] mm: fix-up schedule_timeout() usage;Nishanth Aravamudan;2005-09-10;1;1
MDY6Q29tbWl0MjMyNTI5ODoxM2U0YjU3ZjZhNGUyM2NlYjk5Nzk0YTY1MGQ3NzdlNzQ4MzFmNGE2;set_current_state()/schedule_timeout() to reduce kernel size.;Nishanth Aravamudan;2005-09-10;1;1
MDY6Q29tbWl0MjMyNTI5ODplZjA4ZTNiNDk4MWFlYmYyYmE5YmQ3MDI1ZWY3MjEwZThlZWMwN2Nl;[PATCH] cpusets: confine oom_killer to mem_exclusive cpuset;Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODplZjA4ZTNiNDk4MWFlYmYyYmE5YmQ3MDI1ZWY3MjEwZThlZWMwN2Nl;"Now the real motivation for this cpuset mem_exclusive patch series seems
trivial";Paul Jackson;2005-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODplZjA4ZTNiNDk4MWFlYmYyYmE5YmQ3MDI1ZWY3MjEwZThlZWMwN2Nl;"This patch keeps a task in or under one mem_exclusive cpuset from provoking an
oom kill of a task under a non-overlapping mem_exclusive cpuset";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODplZjA4ZTNiNDk4MWFlYmYyYmE5YmQ3MDI1ZWY3MjEwZThlZWMwN2Nl;" Since only
interrupt and GFP_ATOMIC allocations are allowed to escape mem_exclusive
containment, there is little to gain from oom killing a task under a
non-overlapping mem_exclusive cpuset, as almost all kernel and user memory
allocation must come from disjoint memory nodes";Paul Jackson;2005-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODplZjA4ZTNiNDk4MWFlYmYyYmE5YmQ3MDI1ZWY3MjEwZThlZWMwN2Nl;"This patch enables configuring a system so that a runaway job under one
mem_exclusive cpuset cannot cause the killing of a job in another such cpuset
that might be using very high compute and memory resources for a prolonged
time.";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;[PATCH] cpusets: oom_kill tweaks;Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"This patch series extends the use of the cpuset attribute 'mem_exclusive'
to support cpuset configurations that";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" 1) allow GFP_KERNEL allocations to come from a potentially larger
    set of memory nodes than GFP_USER allocations, and
 2) can constrain the oom killer to tasks running in cpusets in
    a specified subtree of the cpuset hierarchy";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;Here's an example usage scenario;Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" For a few hours or more, a large NUMA
system at a University is to be divided in two halves, with a bunch of student
jobs running in half the system under some form of batch manager, and with a
big research project running in the other half";Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" Each of the student jobs is
placed in a small cpuset, but should share the classic Unix time share
facilities, such as buffered pages of files in /bin and /usr/lib";Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" The big
research project wants no interference whatsoever from the student jobs, and
has highly tuned, unusual memory and i/o patterns that intend to make full use
of all the main memory on the nodes available to it";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"In this example, we have two big sibling cpusets, one of which is further
divided into a more dynamic set of child cpusets";Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"We want kernel memory allocations constrained by the two big cpusets, and user
allocations constrained by the smaller child cpusets where present";Paul Jackson;2005-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" And we
require that the oom killer not operate across the two halves of this system,
or else the first time a student job runs amuck, the big research project will
likely be first inline to get shot";Paul Jackson;2005-09-06;0;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"Tweaking /proc/<pid>/oom_adj is not ideal -- if the big research project
really does run amuck allocating memory, it should be shot, not some other
task outside the research projects mem_exclusive cpuset";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"I propose to extend the use of the 'mem_exclusive' flag of cpusets to manage
such scenarios";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" Let memory allocations for user space (GFP_USER) be
constrained by a tasks current cpuset, but memory allocations for kernel space
(GFP_KERNEL) by constrained by the nearest mem_exclusive ancestor of the
current cpuset, even though kernel space allocations will still _prefer_ to
remain within the current tasks cpuset, if memory is easily available";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"Let the oom killer be constrained to consider only tasks that are in
overlapping mem_exclusive cpusets (it won't help much to kill a task that
normally cannot allocate memory on any of the same nodes as the ones on which
the current task can allocate.)
The current constraints imposed on setting mem_exclusive are unchanged";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" A
cpuset may only be mem_exclusive if its parent is also mem_exclusive, and a
mem_exclusive cpuset may not overlap any of its siblings memory nodes";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"This patch was presented on linux-mm in early July 2005, though did not
generate much feedback at that time";Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" It has been built for a variety of
arch's using cross tools, and built, booted and tested for function on SN2
(ia64)";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;There are 4 patches in this set;Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"  1) Some minor cleanup, and some improvements to the code layout
     of one routine to make subsequent patches cleaner";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;  2) Add another GFP flag - __GFP_HARDWALL;Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" It marks memory
     requests for USER space, which are tightly confined by the
     current tasks cpuset";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"  3) Now memory requests (such as KERNEL) that not marked HARDWALL can
     if short on memory, look in the potentially larger pool of memory
     defined by the nearest mem_exclusive ancestor cpuset of the current
     tasks cpuset";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"  4) Finally, modify the oom killer to skip any task whose mem_exclusive
     cpuset doesn't overlap ours";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"Patch (1), the one time I looked on an SN2 (ia64) build, actually saved 32
bytes of kernel text space";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" Patch (2) has no affect on the size of kernel
text space (it just adds a preprocessor flag)";Paul Jackson;2005-09-06;1;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" Patches (3) and (4) added
about 600 bytes each of kernel text space, mostly in kernel/cpuset.c, which
matters only if CONFIG_CPUSET is enabled";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;This patch;Paul Jackson;2005-09-06;0;0
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;"This patch applies a few comment and code cleanups to mm/oom_kill.c prior to
applying a few small patches to improve cpuset management of memory placement";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;The comment changed in oom_kill.c was seriously misleading;Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;" The code layout
change in select_bad_process() makes room for adding another condition on
which a process can be spared the oom killer (see the subsequent
cpuset_nodes_overlap patch for this addition)";Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;Also a couple typos and spellos that bugged me, while I was here;Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODphNDkzMzVjY2VhYjhhZmI2NjAzMTUyZmNjM2Y3ZDNiNjY3NzM2NmNh;This patch should have no material affect.;Paul Jackson;2005-09-06;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjYzOTI2OWY5Y2U0YWFjMmU2YzIwYmNiY2EzMGI1ZGE4YjlhODk5;[PATCH] mm: quieten OOM killer noise;Anton Blanchard;2005-07-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo0MjYzOTI2OWY5Y2U0YWFjMmU2YzIwYmNiY2EzMGI1ZGE4YjlhODk5;"We now print statistics when invoking the OOM killer, however this
information is not rate limited and you can get into situations where the
console is continually spammed";Anton Blanchard;2005-07-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjYzOTI2OWY5Y2U0YWFjMmU2YzIwYmNiY2EzMGI1ZGE4YjlhODk5;"For example, when a task is exiting the OOM killer will simply return
(waiting for that task to exit and clear up memory)";Anton Blanchard;2005-07-08;0;0
MDY6Q29tbWl0MjMyNTI5ODo0MjYzOTI2OWY5Y2U0YWFjMmU2YzIwYmNiY2EzMGI1ZGE4YjlhODk5;" If the VM continually
calls back into the OOM killer we get thousands of copies of show_mem() on
the console";Anton Blanchard;2005-07-08;0;1
MDY6Q29tbWl0MjMyNTI5ODo0MjYzOTI2OWY5Y2U0YWFjMmU2YzIwYmNiY2EzMGI1ZGE4YjlhODk5;Use printk_ratelimit() to quieten it.;Anton Blanchard;2005-07-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OWI5Y2UzMTFlMTkyZTlhMzFmZDlmM2NmMWVlNGE0ZWRmOWUyNjUw;[PATCH] print order information when OOM killing;Marcelo Tosatti;2005-07-08;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OWI5Y2UzMTFlMTkyZTlhMzFmZDlmM2NmMWVlNGE0ZWRmOWUyNjUw;Dump the current allocation order when OOM killing.;Marcelo Tosatti;2005-07-08;1;0
MDY6Q29tbWl0MjMyNTI5ODo1NzhjMmZkNmE3ZjM3ODQzNDY1NWU1YzQ4MGUyMzE1MmEzOTk0NDA0;[PATCH] add OOM debug;Janet Morgan;2005-06-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NzhjMmZkNmE3ZjM3ODQzNDY1NWU1YzQ4MGUyMzE1MmEzOTk0NDA0;This patch provides more debug info when the system is OOM;Janet Morgan;2005-06-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NzhjMmZkNmE3ZjM3ODQzNDY1NWU1YzQ4MGUyMzE1MmEzOTk0NDA0;" It displays
memory stats (basically sysrq-m info) from __alloc_pages() when page
allocation fails and during OOM kill";Janet Morgan;2005-06-22;1;1
MDY6Q29tbWl0MjMyNTI5ODo1NzhjMmZkNmE3ZjM3ODQzNDY1NWU1YzQ4MGUyMzE1MmEzOTk0NDA0;Thanks to Dave Jones for coming up with the idea.;Janet Morgan;2005-06-22;0;0
MDY6Q29tbWl0MjMyNTI5ODo3OWJlZmQwYzA4YzQ3NjZmOGZhMjdlMzdhYzJhNzBlNDA4NDBhNTZh;[PATCH] oom-killer disable for iscsi/lvm2/multipath userland critical sections;Andrea Arcangeli;2005-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODo3OWJlZmQwYzA4YzQ3NjZmOGZhMjdlMzdhYzJhNzBlNDA4NDBhNTZh;"iscsi/lvm2/multipath needs guaranteed protection from the oom-killer, so
make the magical value of -17 in /proc/<pid>/oom_adj defeat the oom-killer
altogether";Andrea Arcangeli;2005-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODo3OWJlZmQwYzA4YzQ3NjZmOGZhMjdlMzdhYzJhNzBlNDA4NDBhNTZh;"(akpm: we still need to document oom_adj and friends in
Documentation/filesystems/proc.txt!)";Andrea Arcangeli;2005-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGExNzdlNGMzZjQxNTI0ZTg4NmI3ZjFiOGEwYzFmYzczMjFjYWMy;Linux-2.6.12-rc2;Linus Torvalds;2005-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGExNzdlNGMzZjQxNTI0ZTg4NmI3ZjFiOGEwYzFmYzczMjFjYWMy;Initial git repository build;Linus Torvalds;2005-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGExNzdlNGMzZjQxNTI0ZTg4NmI3ZjFiOGEwYzFmYzczMjFjYWMy;"I'm not bothering with the full history,
even though we have it";Linus Torvalds;2005-04-16;1;0
MDY6Q29tbWl0MjMyNTI5ODoxZGExNzdlNGMzZjQxNTI0ZTg4NmI3ZjFiOGEwYzFmYzczMjFjYWMy;"We can create a separate ""historical"" git
archive of that later if we want to, and in the meantime it's about
3.2GB when imported into git - space that would just make the early
git days unnecessarily complicated, when we don't have a lot of good
infrastructure for it";Linus Torvalds;2005-04-16;1;1
MDY6Q29tbWl0MjMyNTI5ODoxZGExNzdlNGMzZjQxNTI0ZTg4NmI3ZjFiOGEwYzFmYzczMjFjYWMy;Let it rip!;Linus Torvalds;2005-04-16;1;0
